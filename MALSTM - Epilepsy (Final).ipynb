{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('MLSTM-FCN/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsFilename='results_data_FINAL.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/paperspace/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/paperspace/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/paperspace/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/paperspace/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/paperspace/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/paperspace/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM, multiply, concatenate, Activation, Masking, Reshape\n",
    "from keras.layers import Conv1D, BatchNormalization, GlobalAveragePooling1D, Permute, Dropout\n",
    "\n",
    "from utils.constants import MAX_NB_VARIABLES, NB_CLASSES_LIST, MAX_TIMESTEPS_LIST\n",
    "from utils.keras_utils import train_model, evaluate_model, set_trainable\n",
    "from utils.layer_utils import AttentionLSTM\n",
    "\n",
    "DATASET_INDEX_0 = 52\n",
    "DATASET_INDEX_1 = 53\n",
    "DATASET_INDEX_2 = 54\n",
    "DATASET_INDEX_3 = 55\n",
    "\n",
    "\n",
    "MAX_TIMESTEPS = MAX_TIMESTEPS_LIST[DATASET_INDEX_0]\n",
    "MAX_NB_VARIABLES = MAX_NB_VARIABLES[DATASET_INDEX_0]\n",
    "NB_CLASS = NB_CLASSES_LIST[DATASET_INDEX_0]\n",
    "\n",
    "TRAINABLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "    ip = Input(shape=(MAX_NB_VARIABLES, MAX_TIMESTEPS))\n",
    "\n",
    "    x = Masking()(ip)\n",
    "    x = LSTM(8)(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "\n",
    "    y = Permute((2, 1))(ip)\n",
    "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "\n",
    "    x = concatenate([x, y])\n",
    "\n",
    "    out = Dense(NB_CLASS, activation='softmax')(x)\n",
    "\n",
    "    model = Model(ip, out)\n",
    "    model.summary()\n",
    "\n",
    "    # add load model code here to fine-tune\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_2():\n",
    "    ip = Input(shape=(MAX_NB_VARIABLES, MAX_TIMESTEPS))\n",
    "    # stride = 10\n",
    "\n",
    "    # x = Permute((2, 1))(ip)\n",
    "    # x = Conv1D(MAX_NB_VARIABLES // stride, 8, strides=stride, padding='same', activation='relu', use_bias=False,\n",
    "    #            kernel_initializer='he_uniform')(x)  # (None, variables / stride, timesteps)\n",
    "    # x = Permute((2, 1))(x)\n",
    "\n",
    "    #ip1 = K.reshape(ip,shape=(MAX_TIMESTEPS,MAX_NB_VARIABLES))\n",
    "    #x = Permute((2, 1))(ip)\n",
    "    x = Masking()(ip)\n",
    "    x = AttentionLSTM(8)(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "\n",
    "    y = Permute((2, 1))(ip)\n",
    "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "\n",
    "    x = concatenate([x, y])\n",
    "\n",
    "    out = Dense(NB_CLASS, activation='softmax')(x)\n",
    "\n",
    "    model = Model(ip, out)\n",
    "    model.summary()\n",
    "\n",
    "    # add load model code here to fine-tune\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_3():\n",
    "    ip = Input(shape=(MAX_NB_VARIABLES, MAX_TIMESTEPS))\n",
    "\n",
    "    x = Masking()(ip)\n",
    "    x = LSTM(8)(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "\n",
    "    y = Permute((2, 1))(ip)\n",
    "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    #y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    #y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "\n",
    "    x = concatenate([x, y])\n",
    "\n",
    "    out = Dense(NB_CLASS, activation='softmax')(x)\n",
    "\n",
    "    model = Model(ip, out)\n",
    "    model.summary()\n",
    "\n",
    "    # add load model code here to fine-tune\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_4():\n",
    "    ip = Input(shape=(MAX_NB_VARIABLES, MAX_TIMESTEPS))\n",
    "    # stride = 3\n",
    "    #\n",
    "    # x = Permute((2, 1))(ip)\n",
    "    # x = Conv1D(MAX_NB_VARIABLES // stride, 8, strides=stride, padding='same', activation='relu', use_bias=False,\n",
    "    #            kernel_initializer='he_uniform')(x)  # (None, variables / stride, timesteps)\n",
    "    # x = Permute((2, 1))(x)\n",
    "\n",
    "    x = Masking()(ip)\n",
    "    x = AttentionLSTM(8)(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "\n",
    "    y = Permute((2, 1))(ip)\n",
    "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    #y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    #y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "\n",
    "    x = concatenate([x, y])\n",
    "\n",
    "    out = Dense(NB_CLASS, activation='softmax')(x)\n",
    "\n",
    "    model = Model(ip, out)\n",
    "    model.summary()\n",
    "\n",
    "    # add load model code here to fine-tune\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_excite_block(input):\n",
    "    ''' Create a squeeze-excite block\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "        k: width factor\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    filters = input._keras_shape[-1] # channel_axis = -1 for TF\n",
    "\n",
    "    se = GlobalAveragePooling1D()(input)\n",
    "    se = Reshape((1, filters))(se)\n",
    "    se = Dense(filters // 16,  activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = multiply([input, se])\n",
    "    return se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1, 4096)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 4096, 1)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 4096, 128)    1152        permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 4096, 128)    512         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 4096, 128)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 128)       0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 8)         1024        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 128)       1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 4096, 128)    0           activation_1[0][0]               \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 4096, 256)    164096      multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 4096, 256)    1024        conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 4096, 256)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 256)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 256)       0           global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 16)        4096        reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1, 256)       4096        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 4096, 256)    0           activation_2[0][0]               \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 4096, 128)    98432       multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 1, 4096)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 4096, 128)    512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_lstm_1 (AttentionLSTM (None, 8)            295280      masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 4096, 128)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 8)            0           attention_lstm_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 128)          0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 136)          0           dropout_1[0][0]                  \n",
      "                                                                 global_average_pooling1d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            274         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 571,522\n",
      "Trainable params: 570,498\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "Loading train / test dataset :  ../data/eeg_seizure_0/ ../data/eeg_seizure_0/\n",
      "x_train_path: ../data/eeg_seizure_0/X_train.npy\n",
      "Finished processing train dataset..\n",
      "Finished loading test dataset..\n",
      "\n",
      "Number of train samples :  160 Number of test samples :  100\n",
      "Number of classes :  2\n",
      "Sequence length :  4096\n",
      "Class weights :  [1. 1.]\n",
      "y_true - 1 Tensor(\"metrics/tn_m/sub:0\", shape=(?, ?), dtype=float32)\n",
      "Train on 160 samples, validate on 100 samples\n",
      "Epoch 1/250\n",
      "epoch time start: 1578292116.2637386\n",
      " - 22s - loss: 0.5126 - acc: 0.8125 - f1_m: 0.8125 - precision_m: 0.8125 - recall_m: 0.8125 - tp_m: 87.2000 - fp_m: 21.6000 - tn_m: 87.2000 - fn_m: 21.6000 - val_loss: 0.3713 - val_acc: 0.9100 - val_f1_m: 0.9100 - val_precision_m: 0.9100 - val_recall_m: 0.9100 - val_tp_m: 91.0000 - val_fp_m: 9.0000 - val_tn_m: 91.0000 - val_fn_m: 9.0000\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.51256, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 22.70144772529602\n",
      "Epoch 2/250\n",
      "epoch time start: 1578292138.9654057\n",
      " - 21s - loss: 0.2127 - acc: 0.8937 - f1_m: 0.8937 - precision_m: 0.8937 - recall_m: 0.8937 - tp_m: 95.8000 - fp_m: 13.0000 - tn_m: 95.8000 - fn_m: 13.0000 - val_loss: 0.2072 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00002: loss improved from 0.51256 to 0.21267, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.153026342391968\n",
      "Epoch 3/250\n",
      "epoch time start: 1578292160.1185544\n",
      " - 23s - loss: 0.1686 - acc: 0.9062 - f1_m: 0.9062 - precision_m: 0.9062 - recall_m: 0.9062 - tp_m: 98.6000 - fp_m: 10.2000 - tn_m: 98.6000 - fn_m: 10.2000 - val_loss: 0.1488 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00003: loss improved from 0.21267 to 0.16857, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 22.870086669921875\n",
      "Epoch 4/250\n",
      "epoch time start: 1578292182.9888191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 23s - loss: 0.1140 - acc: 0.9562 - f1_m: 0.9562 - precision_m: 0.9562 - recall_m: 0.9562 - tp_m: 103.2000 - fp_m: 5.6000 - tn_m: 103.2000 - fn_m: 5.6000 - val_loss: 0.1284 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "\n",
      "Epoch 00004: loss improved from 0.16857 to 0.11397, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.285250902175903\n",
      "Epoch 5/250\n",
      "epoch time start: 1578292206.2745423\n",
      " - 23s - loss: 0.1112 - acc: 0.9437 - f1_m: 0.9437 - precision_m: 0.9437 - recall_m: 0.9437 - tp_m: 103.4000 - fp_m: 5.4000 - tn_m: 103.4000 - fn_m: 5.4000 - val_loss: 0.1279 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "\n",
      "Epoch 00005: loss improved from 0.11397 to 0.11123, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.119024991989136\n",
      "Epoch 6/250\n",
      "epoch time start: 1578292229.3938026\n",
      " - 23s - loss: 0.0782 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1346 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00006: loss improved from 0.11123 to 0.07821, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.089268445968628\n",
      "Epoch 7/250\n",
      "epoch time start: 1578292252.4832842\n",
      " - 23s - loss: 0.0750 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 106.4000 - fp_m: 2.4000 - tn_m: 106.4000 - fn_m: 2.4000 - val_loss: 0.1438 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00007: loss improved from 0.07821 to 0.07495, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.319932460784912\n",
      "Epoch 8/250\n",
      "epoch time start: 1578292275.803416\n",
      " - 24s - loss: 0.0756 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 107.6000 - fp_m: 1.2000 - tn_m: 107.6000 - fn_m: 1.2000 - val_loss: 0.1470 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00008: loss did not improve\n",
      "epoch time measured: 23.977898359298706\n",
      "Epoch 9/250\n",
      "epoch time start: 1578292299.781421\n",
      " - 23s - loss: 0.0660 - acc: 0.9750 - f1_m: 0.9750 - precision_m: 0.9750 - recall_m: 0.9750 - tp_m: 106.2000 - fp_m: 2.6000 - tn_m: 106.2000 - fn_m: 2.6000 - val_loss: 0.1495 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00009: loss improved from 0.07495 to 0.06601, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 22.988502979278564\n",
      "Epoch 10/250\n",
      "epoch time start: 1578292322.7702153\n",
      " - 24s - loss: 0.0488 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.1547 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00010: loss improved from 0.06601 to 0.04882, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.665141344070435\n",
      "Epoch 11/250\n",
      "epoch time start: 1578292346.4355955\n",
      " - 24s - loss: 0.0489 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1627 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00011: loss did not improve\n",
      "epoch time measured: 23.636510133743286\n",
      "Epoch 12/250\n",
      "epoch time start: 1578292370.0722356\n",
      " - 23s - loss: 0.0626 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 106.4000 - fp_m: 2.4000 - tn_m: 106.4000 - fn_m: 2.4000 - val_loss: 0.1742 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00012: loss did not improve\n",
      "epoch time measured: 23.381641149520874\n",
      "Epoch 13/250\n",
      "epoch time start: 1578292393.4539998\n",
      " - 23s - loss: 0.0516 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.1892 - val_acc: 0.9500 - val_f1_m: 0.9500 - val_precision_m: 0.9500 - val_recall_m: 0.9500 - val_tp_m: 95.0000 - val_fp_m: 5.0000 - val_tn_m: 95.0000 - val_fn_m: 5.0000\n",
      "\n",
      "Epoch 00013: loss did not improve\n",
      "epoch time measured: 22.774718523025513\n",
      "Epoch 14/250\n",
      "epoch time start: 1578292416.2288404\n",
      " - 23s - loss: 0.0722 - acc: 0.9750 - f1_m: 0.9750 - precision_m: 0.9750 - recall_m: 0.9750 - tp_m: 107.4000 - fp_m: 1.4000 - tn_m: 107.4000 - fn_m: 1.4000 - val_loss: 0.2246 - val_acc: 0.9400 - val_f1_m: 0.9400 - val_precision_m: 0.9400 - val_recall_m: 0.9400 - val_tp_m: 94.0000 - val_fp_m: 6.0000 - val_tn_m: 94.0000 - val_fn_m: 6.0000\n",
      "\n",
      "Epoch 00014: loss did not improve\n",
      "epoch time measured: 23.05108642578125\n",
      "Epoch 15/250\n",
      "epoch time start: 1578292439.2800546\n",
      " - 23s - loss: 0.0392 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.2604 - val_acc: 0.9400 - val_f1_m: 0.9400 - val_precision_m: 0.9400 - val_recall_m: 0.9400 - val_tp_m: 94.0000 - val_fp_m: 6.0000 - val_tn_m: 94.0000 - val_fn_m: 6.0000\n",
      "\n",
      "Epoch 00015: loss improved from 0.04882 to 0.03918, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.324385166168213\n",
      "Epoch 16/250\n",
      "epoch time start: 1578292462.6046379\n",
      " - 23s - loss: 0.0526 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 108.4000 - fp_m: 0.4000 - tn_m: 108.4000 - fn_m: 0.4000 - val_loss: 0.2732 - val_acc: 0.9400 - val_f1_m: 0.9400 - val_precision_m: 0.9400 - val_recall_m: 0.9400 - val_tp_m: 94.0000 - val_fp_m: 6.0000 - val_tn_m: 94.0000 - val_fn_m: 6.0000\n",
      "\n",
      "Epoch 00016: loss did not improve\n",
      "epoch time measured: 22.69649577140808\n",
      "Epoch 17/250\n",
      "epoch time start: 1578292485.301283\n",
      " - 24s - loss: 0.0543 - acc: 0.9688 - f1_m: 0.9687 - precision_m: 0.9688 - recall_m: 0.9688 - tp_m: 105.4000 - fp_m: 3.4000 - tn_m: 105.4000 - fn_m: 3.4000 - val_loss: 0.2722 - val_acc: 0.9400 - val_f1_m: 0.9400 - val_precision_m: 0.9400 - val_recall_m: 0.9400 - val_tp_m: 94.0000 - val_fp_m: 6.0000 - val_tn_m: 94.0000 - val_fn_m: 6.0000\n",
      "\n",
      "Epoch 00017: loss did not improve\n",
      "epoch time measured: 23.91650414466858\n",
      "Epoch 18/250\n",
      "epoch time start: 1578292509.217941\n",
      " - 23s - loss: 0.0536 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 108.4000 - fp_m: 0.4000 - tn_m: 108.4000 - fn_m: 0.4000 - val_loss: 0.2566 - val_acc: 0.9400 - val_f1_m: 0.9400 - val_precision_m: 0.9400 - val_recall_m: 0.9400 - val_tp_m: 94.0000 - val_fp_m: 6.0000 - val_tn_m: 94.0000 - val_fn_m: 6.0000\n",
      "\n",
      "Epoch 00018: loss did not improve\n",
      "epoch time measured: 23.083147764205933\n",
      "Epoch 19/250\n",
      "epoch time start: 1578292532.3013136\n",
      " - 23s - loss: 0.0463 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.2298 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00019: loss did not improve\n",
      "epoch time measured: 23.13667130470276\n",
      "Epoch 20/250\n",
      "epoch time start: 1578292555.438104\n",
      " - 23s - loss: 0.0450 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.2000 - fp_m: 1.6000 - tn_m: 107.2000 - fn_m: 1.6000 - val_loss: 0.2076 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00020: loss did not improve\n",
      "epoch time measured: 23.148372173309326\n",
      "Epoch 21/250\n",
      "epoch time start: 1578292578.5866103\n",
      " - 23s - loss: 0.0407 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.2000 - fp_m: 1.6000 - tn_m: 107.2000 - fn_m: 1.6000 - val_loss: 0.1903 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00021: loss did not improve\n",
      "epoch time measured: 23.278563737869263\n",
      "Epoch 22/250\n",
      "epoch time start: 1578292601.8655028\n",
      " - 23s - loss: 0.0339 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1790 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00022: loss improved from 0.03918 to 0.03393, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.44849181175232\n",
      "Epoch 23/250\n",
      "epoch time start: 1578292625.3142023\n",
      " - 24s - loss: 0.0308 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1712 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00023: loss improved from 0.03393 to 0.03083, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.810673713684082\n",
      "Epoch 24/250\n",
      "epoch time start: 1578292649.1250422\n",
      " - 23s - loss: 0.0328 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.1675 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00024: loss did not improve\n",
      "epoch time measured: 23.28911781311035\n",
      "Epoch 25/250\n",
      "epoch time start: 1578292672.414271\n",
      " - 23s - loss: 0.0669 - acc: 0.9688 - f1_m: 0.9687 - precision_m: 0.9688 - recall_m: 0.9688 - tp_m: 107.2000 - fp_m: 1.6000 - tn_m: 107.2000 - fn_m: 1.6000 - val_loss: 0.1723 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00025: loss did not improve\n",
      "epoch time measured: 23.417012691497803\n",
      "Epoch 26/250\n",
      "epoch time start: 1578292695.8313994\n",
      " - 23s - loss: 0.0387 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1803 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00026: loss did not improve\n",
      "epoch time measured: 23.198015689849854\n",
      "Epoch 27/250\n",
      "epoch time start: 1578292719.0295703\n",
      " - 23s - loss: 0.0328 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1842 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00027: loss did not improve\n",
      "epoch time measured: 23.034454822540283\n",
      "Epoch 28/250\n",
      "epoch time start: 1578292742.06416\n",
      " - 23s - loss: 0.0389 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 106.4000 - fp_m: 2.4000 - tn_m: 106.4000 - fn_m: 2.4000 - val_loss: 0.1870 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00028: loss did not improve\n",
      "epoch time measured: 23.31278347969055\n",
      "Epoch 29/250\n",
      "epoch time start: 1578292765.3770652\n",
      " - 23s - loss: 0.0894 - acc: 0.9688 - f1_m: 0.9687 - precision_m: 0.9688 - recall_m: 0.9688 - tp_m: 107.2000 - fp_m: 1.6000 - tn_m: 107.2000 - fn_m: 1.6000 - val_loss: 0.1848 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00029: loss did not improve\n",
      "epoch time measured: 22.642162561416626\n",
      "Epoch 30/250\n",
      "epoch time start: 1578292788.0193346\n",
      " - 23s - loss: 0.0484 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 106.4000 - fp_m: 2.4000 - tn_m: 106.4000 - fn_m: 2.4000 - val_loss: 0.1834 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00030: loss did not improve\n",
      "epoch time measured: 22.955225944519043\n",
      "Epoch 31/250\n",
      "epoch time start: 1578292810.974787\n",
      " - 23s - loss: 0.0464 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.1787 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00031: loss did not improve\n",
      "epoch time measured: 23.19759774208069\n",
      "Epoch 32/250\n",
      "epoch time start: 1578292834.1725264\n",
      " - 23s - loss: 0.0391 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.1763 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00032: loss did not improve\n",
      "epoch time measured: 22.981512308120728\n",
      "Epoch 33/250\n",
      "epoch time start: 1578292857.1541898\n",
      " - 23s - loss: 0.0451 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 107.0000 - fp_m: 1.8000 - tn_m: 107.0000 - fn_m: 1.8000 - val_loss: 0.1800 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00033: loss did not improve\n",
      "epoch time measured: 22.916791200637817\n",
      "Epoch 34/250\n",
      "epoch time start: 1578292880.0711234\n",
      " - 23s - loss: 0.0300 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1867 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00034: loss improved from 0.03083 to 0.03004, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.084155082702637\n",
      "Epoch 35/250\n",
      "epoch time start: 1578292903.1554601\n",
      " - 23s - loss: 0.0334 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.2000 - fp_m: 1.6000 - tn_m: 107.2000 - fn_m: 1.6000 - val_loss: 0.1953 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00035: loss did not improve\n",
      "epoch time measured: 22.968331336975098\n",
      "Epoch 36/250\n",
      "epoch time start: 1578292926.1240017\n",
      " - 23s - loss: 0.0320 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 108.4000 - fp_m: 0.4000 - tn_m: 108.4000 - fn_m: 0.4000 - val_loss: 0.1999 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00036: loss did not improve\n",
      "epoch time measured: 22.93074607849121\n",
      "Epoch 37/250\n",
      "epoch time start: 1578292949.0549302\n",
      " - 23s - loss: 0.0441 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.2097 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00037: loss did not improve\n",
      "epoch time measured: 23.204326152801514\n",
      "Epoch 38/250\n",
      "epoch time start: 1578292972.2594144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 25s - loss: 0.0635 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 106.4000 - fp_m: 2.4000 - tn_m: 106.4000 - fn_m: 2.4000 - val_loss: 0.2227 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00038: loss did not improve\n",
      "epoch time measured: 24.619789600372314\n",
      "Epoch 39/250\n",
      "epoch time start: 1578292996.8793314\n",
      " - 23s - loss: 0.0655 - acc: 0.9688 - f1_m: 0.9687 - precision_m: 0.9688 - recall_m: 0.9688 - tp_m: 105.4000 - fp_m: 3.4000 - tn_m: 105.4000 - fn_m: 3.4000 - val_loss: 0.2265 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00039: loss did not improve\n",
      "epoch time measured: 23.088053703308105\n",
      "Epoch 40/250\n",
      "epoch time start: 1578293019.9675915\n",
      " - 23s - loss: 0.0622 - acc: 0.9625 - f1_m: 0.9625 - precision_m: 0.9625 - recall_m: 0.9625 - tp_m: 106.4000 - fp_m: 2.4000 - tn_m: 106.4000 - fn_m: 2.4000 - val_loss: 0.2262 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00040: loss did not improve\n",
      "epoch time measured: 23.13715147972107\n",
      "Epoch 41/250\n",
      "epoch time start: 1578293043.1048615\n",
      " - 24s - loss: 0.0492 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.2000 - fp_m: 1.6000 - tn_m: 107.2000 - fn_m: 1.6000 - val_loss: 0.2259 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00041: loss did not improve\n",
      "epoch time measured: 23.819504737854004\n",
      "Epoch 42/250\n",
      "epoch time start: 1578293066.9244723\n",
      " - 23s - loss: 0.0376 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 106.4000 - fp_m: 2.4000 - tn_m: 106.4000 - fn_m: 2.4000 - val_loss: 0.2243 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00042: loss did not improve\n",
      "epoch time measured: 22.941349506378174\n",
      "Epoch 43/250\n",
      "epoch time start: 1578293089.8659663\n",
      " - 23s - loss: 0.0408 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.2000 - fp_m: 1.6000 - tn_m: 107.2000 - fn_m: 1.6000 - val_loss: 0.2225 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00043: loss did not improve\n",
      "epoch time measured: 22.977117776870728\n",
      "Epoch 44/250\n",
      "epoch time start: 1578293112.8433115\n",
      " - 23s - loss: 0.0308 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.2232 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00044: loss did not improve\n",
      "epoch time measured: 23.327319860458374\n",
      "Epoch 45/250\n",
      "epoch time start: 1578293136.1708326\n",
      " - 23s - loss: 0.0232 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.2254 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00045: loss improved from 0.03004 to 0.02324, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 22.917529106140137\n",
      "Epoch 46/250\n",
      "epoch time start: 1578293159.0886364\n",
      " - 23s - loss: 0.0303 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.2281 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00046: loss did not improve\n",
      "epoch time measured: 23.29322910308838\n",
      "Epoch 47/250\n",
      "epoch time start: 1578293182.3821564\n",
      " - 24s - loss: 0.0239 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.2311 - val_acc: 0.9500 - val_f1_m: 0.9500 - val_precision_m: 0.9500 - val_recall_m: 0.9500 - val_tp_m: 95.0000 - val_fp_m: 5.0000 - val_tn_m: 95.0000 - val_fn_m: 5.0000\n",
      "\n",
      "Epoch 00047: loss did not improve\n",
      "epoch time measured: 23.634816646575928\n",
      "Epoch 48/250\n",
      "epoch time start: 1578293206.0170906\n",
      " - 23s - loss: 0.0270 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.2311 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00048: loss did not improve\n",
      "epoch time measured: 23.074421405792236\n",
      "Epoch 49/250\n",
      "epoch time start: 1578293229.0917509\n",
      " - 23s - loss: 0.0336 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.2288 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00049: loss did not improve\n",
      "epoch time measured: 23.18057680130005\n",
      "Epoch 50/250\n",
      "epoch time start: 1578293252.2724395\n",
      " - 24s - loss: 0.0301 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.2266 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00050: loss did not improve\n",
      "epoch time measured: 23.78639316558838\n",
      "Epoch 51/250\n",
      "epoch time start: 1578293276.0589354\n",
      " - 24s - loss: 0.0227 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.2248 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00051: loss improved from 0.02324 to 0.02266, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.560994148254395\n",
      "Epoch 52/250\n",
      "epoch time start: 1578293299.6201484\n",
      " - 23s - loss: 0.0356 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.2231 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00052: loss did not improve\n",
      "epoch time measured: 22.871468544006348\n",
      "Epoch 53/250\n",
      "epoch time start: 1578293322.491777\n",
      " - 23s - loss: 0.0618 - acc: 0.9625 - f1_m: 0.9625 - precision_m: 0.9625 - recall_m: 0.9625 - tp_m: 106.4000 - fp_m: 2.4000 - tn_m: 106.4000 - fn_m: 2.4000 - val_loss: 0.2287 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00053: loss did not improve\n",
      "epoch time measured: 22.949116945266724\n",
      "Epoch 54/250\n",
      "epoch time start: 1578293345.4410799\n",
      " - 24s - loss: 0.0169 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.2371 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00054: loss improved from 0.02266 to 0.01691, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.65364694595337\n",
      "Epoch 55/250\n",
      "epoch time start: 1578293369.094936\n",
      " - 23s - loss: 0.0300 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.2408 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00055: loss did not improve\n",
      "epoch time measured: 23.324622869491577\n",
      "Epoch 56/250\n",
      "epoch time start: 1578293392.4196951\n",
      " - 23s - loss: 0.0572 - acc: 0.9750 - f1_m: 0.9750 - precision_m: 0.9750 - recall_m: 0.9750 - tp_m: 106.8000 - fp_m: 2.0000 - tn_m: 106.8000 - fn_m: 2.0000 - val_loss: 0.2317 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00056: loss did not improve\n",
      "epoch time measured: 22.865705013275146\n",
      "Epoch 57/250\n",
      "epoch time start: 1578293415.2855084\n",
      " - 23s - loss: 0.0325 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.2163 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00057: loss did not improve\n",
      "epoch time measured: 22.787285089492798\n",
      "Epoch 58/250\n",
      "epoch time start: 1578293438.0728936\n",
      " - 23s - loss: 0.0275 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.2024 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00058: loss did not improve\n",
      "epoch time measured: 23.294168710708618\n",
      "Epoch 59/250\n",
      "epoch time start: 1578293461.3674035\n",
      " - 23s - loss: 0.0226 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1903 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00059: loss did not improve\n",
      "epoch time measured: 23.40822458267212\n",
      "Epoch 60/250\n",
      "epoch time start: 1578293484.7758403\n",
      " - 23s - loss: 0.0240 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.2000 - fp_m: 1.6000 - tn_m: 107.2000 - fn_m: 1.6000 - val_loss: 0.1815 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00060: loss did not improve\n",
      "epoch time measured: 22.942957401275635\n",
      "Epoch 61/250\n",
      "epoch time start: 1578293507.7189116\n",
      " - 23s - loss: 0.0503 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 107.6000 - fp_m: 1.2000 - tn_m: 107.6000 - fn_m: 1.2000 - val_loss: 0.1774 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00061: loss did not improve\n",
      "epoch time measured: 23.32584261894226\n",
      "Epoch 62/250\n",
      "epoch time start: 1578293531.0449653\n",
      " - 23s - loss: 0.0156 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1765 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00062: loss improved from 0.01691 to 0.01562, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 22.91487979888916\n",
      "Epoch 63/250\n",
      "epoch time start: 1578293553.9600394\n",
      " - 23s - loss: 0.0185 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1795 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00063: loss did not improve\n",
      "epoch time measured: 23.355977535247803\n",
      "Epoch 64/250\n",
      "epoch time start: 1578293577.316288\n",
      " - 24s - loss: 0.0395 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.1854 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00064: loss did not improve\n",
      "epoch time measured: 23.780899047851562\n",
      "Epoch 65/250\n",
      "epoch time start: 1578293601.0973856\n",
      " - 23s - loss: 0.0287 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1935 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00065: loss did not improve\n",
      "epoch time measured: 23.271722555160522\n",
      "Epoch 66/250\n",
      "epoch time start: 1578293624.3692203\n",
      " - 23s - loss: 0.0420 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 107.0000 - fp_m: 1.8000 - tn_m: 107.0000 - fn_m: 1.8000 - val_loss: 0.2000 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00066: loss did not improve\n",
      "epoch time measured: 22.935147285461426\n",
      "Epoch 67/250\n",
      "epoch time start: 1578293647.3046799\n",
      " - 23s - loss: 0.0149 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.2031 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00067: loss improved from 0.01562 to 0.01487, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.305968523025513\n",
      "Epoch 68/250\n",
      "epoch time start: 1578293670.610836\n",
      " - 24s - loss: 0.0232 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.2025 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00068: loss did not improve\n",
      "epoch time measured: 23.65574359893799\n",
      "Epoch 69/250\n",
      "epoch time start: 1578293694.2667563\n",
      " - 23s - loss: 0.0267 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1953 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00069: loss did not improve\n",
      "epoch time measured: 23.13890027999878\n",
      "Epoch 70/250\n",
      "epoch time start: 1578293717.4057982\n",
      " - 23s - loss: 0.0215 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1815 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00070: loss did not improve\n",
      "epoch time measured: 22.904170751571655\n",
      "Epoch 71/250\n",
      "epoch time start: 1578293740.3100984\n",
      " - 23s - loss: 0.0319 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1749 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00071: loss did not improve\n",
      "epoch time measured: 23.278100967407227\n",
      "Epoch 72/250\n",
      "epoch time start: 1578293763.5883167\n",
      " - 23s - loss: 0.0332 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.1801 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00072: loss did not improve\n",
      "epoch time measured: 22.995286464691162\n",
      "Epoch 73/250\n",
      "epoch time start: 1578293786.5838528\n",
      " - 22s - loss: 0.0163 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1860 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00073: loss did not improve\n",
      "epoch time measured: 22.454419374465942\n",
      "Epoch 74/250\n",
      "epoch time start: 1578293809.0384314\n",
      " - 23s - loss: 0.0313 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.1889 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00074: loss did not improve\n",
      "epoch time measured: 23.097373485565186\n",
      "Epoch 75/250\n",
      "epoch time start: 1578293832.135928\n",
      " - 23s - loss: 0.0180 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1896 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00075: loss did not improve\n",
      "epoch time measured: 23.010291814804077\n",
      "Epoch 76/250\n",
      "epoch time start: 1578293855.1463425\n",
      " - 23s - loss: 0.0219 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1907 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00076: loss did not improve\n",
      "epoch time measured: 22.822425842285156\n",
      "Epoch 77/250\n",
      "epoch time start: 1578293877.9690454\n",
      " - 23s - loss: 0.0441 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.1902 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00077: loss did not improve\n",
      "epoch time measured: 22.781946182250977\n",
      "Epoch 78/250\n",
      "epoch time start: 1578293900.7511\n",
      " - 23s - loss: 0.0186 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1852 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00078: loss did not improve\n",
      "epoch time measured: 23.03692889213562\n",
      "Epoch 79/250\n",
      "epoch time start: 1578293923.788134\n",
      " - 23s - loss: 0.0207 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1805 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00079: loss did not improve\n",
      "epoch time measured: 23.2942636013031\n",
      "Epoch 80/250\n",
      "epoch time start: 1578293947.0825083\n",
      " - 23s - loss: 0.0177 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1757 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00080: loss did not improve\n",
      "epoch time measured: 23.15290641784668\n",
      "Epoch 81/250\n",
      "epoch time start: 1578293970.2355332\n",
      " - 23s - loss: 0.0150 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1731 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00081: loss did not improve\n",
      "epoch time measured: 23.156047105789185\n",
      "Epoch 82/250\n",
      "epoch time start: 1578293993.3917158\n",
      " - 23s - loss: 0.0859 - acc: 0.9750 - f1_m: 0.9750 - precision_m: 0.9750 - recall_m: 0.9750 - tp_m: 107.4000 - fp_m: 1.4000 - tn_m: 107.4000 - fn_m: 1.4000 - val_loss: 0.1621 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00082: loss did not improve\n",
      "epoch time measured: 23.452352285385132\n",
      "Epoch 83/250\n",
      "epoch time start: 1578294016.8442001\n",
      " - 23s - loss: 0.0493 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 108.4000 - fp_m: 0.4000 - tn_m: 108.4000 - fn_m: 0.4000 - val_loss: 0.1529 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00083: loss did not improve\n",
      "epoch time measured: 23.004923820495605\n",
      "Epoch 84/250\n",
      "epoch time start: 1578294039.8493152\n",
      " - 23s - loss: 0.0271 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1562 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00084: loss did not improve\n",
      "epoch time measured: 23.33016872406006\n",
      "Epoch 85/250\n",
      "epoch time start: 1578294063.1796343\n",
      " - 23s - loss: 0.0338 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 107.0000 - fp_m: 1.8000 - tn_m: 107.0000 - fn_m: 1.8000 - val_loss: 0.1628 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00085: loss did not improve\n",
      "epoch time measured: 22.989643573760986\n",
      "Epoch 86/250\n",
      "epoch time start: 1578294086.1694882\n",
      " - 23s - loss: 0.0367 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.2000 - fp_m: 1.6000 - tn_m: 107.2000 - fn_m: 1.6000 - val_loss: 0.1674 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00086: loss did not improve\n",
      "epoch time measured: 23.109781742095947\n",
      "Epoch 87/250\n",
      "epoch time start: 1578294109.279375\n",
      " - 23s - loss: 0.0317 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1699 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00087: loss did not improve\n",
      "epoch time measured: 23.304744958877563\n",
      "Epoch 88/250\n",
      "epoch time start: 1578294132.5842814\n",
      " - 23s - loss: 0.0249 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.2000 - fp_m: 1.6000 - tn_m: 107.2000 - fn_m: 1.6000 - val_loss: 0.1717 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00088: loss did not improve\n",
      "epoch time measured: 23.038954496383667\n",
      "Epoch 89/250\n",
      "epoch time start: 1578294155.62336\n",
      " - 24s - loss: 0.0259 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1735 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00089: loss did not improve\n",
      "epoch time measured: 23.508713245391846\n",
      "Epoch 90/250\n",
      "epoch time start: 1578294179.1322205\n",
      " - 23s - loss: 0.0215 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1757 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00090: loss did not improve\n",
      "epoch time measured: 23.266077518463135\n",
      "Epoch 91/250\n",
      "epoch time start: 1578294202.3984268\n",
      " - 23s - loss: 0.0407 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 107.6000 - fp_m: 1.2000 - tn_m: 107.6000 - fn_m: 1.2000 - val_loss: 0.1810 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00091: loss did not improve\n",
      "epoch time measured: 22.820062160491943\n",
      "Epoch 92/250\n",
      "epoch time start: 1578294225.2185967\n",
      " - 23s - loss: 0.0289 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1921 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00092: loss did not improve\n",
      "epoch time measured: 22.771987438201904\n",
      "Epoch 93/250\n",
      "epoch time start: 1578294247.990717\n",
      " - 23s - loss: 0.0195 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.2036 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00093: loss did not improve\n",
      "epoch time measured: 23.305943965911865\n",
      "Epoch 94/250\n",
      "epoch time start: 1578294271.2969415\n",
      " - 23s - loss: 0.0230 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.2098 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00094: loss did not improve\n",
      "epoch time measured: 22.78201174736023\n",
      "Epoch 95/250\n",
      "epoch time start: 1578294294.079065\n",
      " - 23s - loss: 0.0223 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.2140 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00095: loss did not improve\n",
      "epoch time measured: 23.007233381271362\n",
      "Epoch 96/250\n",
      "epoch time start: 1578294317.0864317\n",
      " - 24s - loss: 0.0261 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.2160 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00096: loss did not improve\n",
      "epoch time measured: 23.525571823120117\n",
      "Epoch 97/250\n",
      "epoch time start: 1578294340.612115\n",
      " - 23s - loss: 0.0221 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.2138 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00097: loss did not improve\n",
      "epoch time measured: 23.25746774673462\n",
      "Epoch 98/250\n",
      "epoch time start: 1578294363.8696916\n",
      " - 23s - loss: 0.0242 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.2057 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00098: loss did not improve\n",
      "epoch time measured: 22.879719734191895\n",
      "Epoch 99/250\n",
      "epoch time start: 1578294386.7495308\n",
      " - 23s - loss: 0.0242 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1935 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00099: loss did not improve\n",
      "epoch time measured: 22.849420070648193\n",
      "Epoch 100/250\n",
      "epoch time start: 1578294409.5990906\n",
      " - 24s - loss: 0.0279 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1866 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00100: loss did not improve\n",
      "epoch time measured: 23.888566970825195\n",
      "Epoch 101/250\n",
      "epoch time start: 1578294433.4877696\n",
      " - 23s - loss: 0.0236 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1897 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00101: loss did not improve\n",
      "epoch time measured: 22.97511100769043\n",
      "Epoch 102/250\n",
      "epoch time start: 1578294456.4633405\n",
      " - 23s - loss: 0.0660 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 107.6000 - fp_m: 1.2000 - tn_m: 107.6000 - fn_m: 1.2000 - val_loss: 0.1939 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00102: loss did not improve\n",
      "epoch time measured: 22.982519149780273\n",
      "Epoch 103/250\n",
      "epoch time start: 1578294479.4459774\n",
      " - 23s - loss: 0.0225 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1985 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00103: loss did not improve\n",
      "epoch time measured: 23.32437515258789\n",
      "Epoch 104/250\n",
      "epoch time start: 1578294502.7704647\n",
      " - 23s - loss: 0.0166 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1992 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00104: loss did not improve\n",
      "epoch time measured: 23.016525983810425\n",
      "Epoch 105/250\n",
      "epoch time start: 1578294525.7873344\n",
      " - 24s - loss: 0.0173 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1958 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00105: loss did not improve\n",
      "epoch time measured: 23.520498991012573\n",
      "Epoch 106/250\n",
      "epoch time start: 1578294549.308015\n",
      " - 24s - loss: 0.0204 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1902 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00106: loss did not improve\n",
      "epoch time measured: 23.713537216186523\n",
      "Epoch 107/250\n",
      "epoch time start: 1578294573.021689\n",
      " - 23s - loss: 0.0305 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.1815 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00107: loss did not improve\n",
      "epoch time measured: 22.965967655181885\n",
      "Epoch 108/250\n",
      "epoch time start: 1578294595.9878051\n",
      " - 23s - loss: 0.0287 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1723 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00108: loss did not improve\n",
      "epoch time measured: 22.824609994888306\n",
      "Epoch 109/250\n",
      "epoch time start: 1578294618.8125293\n",
      " - 23s - loss: 0.0248 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1652 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00109: loss did not improve\n",
      "epoch time measured: 23.09906005859375\n",
      "Epoch 110/250\n",
      "epoch time start: 1578294641.9117053\n",
      " - 23s - loss: 0.0211 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1603 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00110: loss did not improve\n",
      "epoch time measured: 23.062360763549805\n",
      "Epoch 111/250\n",
      "epoch time start: 1578294664.974395\n",
      " - 23s - loss: 0.0258 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.1593 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00111: loss did not improve\n",
      "epoch time measured: 23.11612606048584\n",
      "Epoch 112/250\n",
      "epoch time start: 1578294688.0906343\n",
      " - 23s - loss: 0.0169 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1628 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00112: loss did not improve\n",
      "epoch time measured: 23.130653142929077\n",
      "Epoch 113/250\n",
      "epoch time start: 1578294711.221453\n",
      " - 23s - loss: 0.0134 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1680 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00113: loss improved from 0.01487 to 0.01342, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 22.952468395233154\n",
      "Epoch 114/250\n",
      "epoch time start: 1578294734.1740894\n",
      " - 23s - loss: 0.0241 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1736 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00114: loss did not improve\n",
      "epoch time measured: 23.099217414855957\n",
      "Epoch 115/250\n",
      "epoch time start: 1578294757.2735884\n",
      " - 23s - loss: 0.0178 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1789 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00115: loss did not improve\n",
      "epoch time measured: 22.893788814544678\n",
      "Epoch 116/250\n",
      "epoch time start: 1578294780.167484\n",
      " - 23s - loss: 0.0156 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1832 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00116: loss did not improve\n",
      "epoch time measured: 23.16756820678711\n",
      "Epoch 117/250\n",
      "epoch time start: 1578294803.3351696\n",
      " - 23s - loss: 0.0176 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1881 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00117: loss did not improve\n",
      "epoch time measured: 23.4735267162323\n",
      "Epoch 118/250\n",
      "epoch time start: 1578294826.8088183\n",
      " - 23s - loss: 0.0180 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1920 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00118: loss did not improve\n",
      "epoch time measured: 23.16209053993225\n",
      "Epoch 119/250\n",
      "epoch time start: 1578294849.9711983\n",
      " - 23s - loss: 0.0201 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1900 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00119: loss did not improve\n",
      "epoch time measured: 23.2270770072937\n",
      "Epoch 120/250\n",
      "epoch time start: 1578294873.1983805\n",
      " - 23s - loss: 0.0209 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1823 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00120: loss did not improve\n",
      "epoch time measured: 23.06670093536377\n",
      "Epoch 121/250\n",
      "epoch time start: 1578294896.265197\n",
      " - 23s - loss: 0.0186 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1719 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00121: loss did not improve\n",
      "epoch time measured: 23.353126049041748\n",
      "Epoch 122/250\n",
      "epoch time start: 1578294919.618474\n",
      " - 24s - loss: 0.0196 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1647 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00122: loss did not improve\n",
      "epoch time measured: 24.094696521759033\n",
      "Epoch 123/250\n",
      "epoch time start: 1578294943.713283\n",
      " - 23s - loss: 0.0220 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1681 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00123: loss did not improve\n",
      "epoch time measured: 22.800620079040527\n",
      "Epoch 124/250\n",
      "epoch time start: 1578294966.5140839\n",
      " - 23s - loss: 0.0131 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1765 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00124: loss improved from 0.01342 to 0.01309, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.13106870651245\n",
      "Epoch 125/250\n",
      "epoch time start: 1578294989.645322\n",
      " - 23s - loss: 0.0166 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1826 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00125: loss did not improve\n",
      "epoch time measured: 23.114346981048584\n",
      "Epoch 126/250\n",
      "epoch time start: 1578295012.7597804\n",
      " - 23s - loss: 0.0135 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1822 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00126: loss did not improve\n",
      "epoch time measured: 23.258736610412598\n",
      "Epoch 127/250\n",
      "epoch time start: 1578295036.0186305\n",
      " - 23s - loss: 0.0186 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1761 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00127: loss did not improve\n",
      "epoch time measured: 22.87309741973877\n",
      "Epoch 128/250\n",
      "epoch time start: 1578295058.8921692\n",
      " - 23s - loss: 0.0195 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1680 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00128: loss did not improve\n",
      "epoch time measured: 22.936344861984253\n",
      "Epoch 129/250\n",
      "epoch time start: 1578295081.8286934\n",
      " - 23s - loss: 0.0107 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1615 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00129: loss improved from 0.01309 to 0.01071, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.415907859802246\n",
      "Epoch 130/250\n",
      "epoch time start: 1578295105.2447875\n",
      " - 23s - loss: 0.0108 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1581 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00130: loss did not improve\n",
      "epoch time measured: 23.416425466537476\n",
      "Epoch 131/250\n",
      "epoch time start: 1578295128.6613443\n",
      " - 23s - loss: 0.0151 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1578 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00131: loss did not improve\n",
      "epoch time measured: 22.818629264831543\n",
      "Epoch 132/250\n",
      "epoch time start: 1578295151.480293\n",
      " - 23s - loss: 0.0498 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 108.4000 - fp_m: 0.4000 - tn_m: 108.4000 - fn_m: 0.4000 - val_loss: 0.1538 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00132: loss did not improve\n",
      "epoch time measured: 23.066406965255737\n",
      "Epoch 133/250\n",
      "epoch time start: 1578295174.5468156\n",
      " - 24s - loss: 0.0174 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1513 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00133: loss did not improve\n",
      "epoch time measured: 23.650240182876587\n",
      "Epoch 134/250\n",
      "epoch time start: 1578295198.1971922\n",
      " - 23s - loss: 0.0291 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1526 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00134: loss did not improve\n",
      "epoch time measured: 23.457774877548218\n",
      "Epoch 135/250\n",
      "epoch time start: 1578295221.6550906\n",
      " - 23s - loss: 0.0257 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1540 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00135: loss did not improve\n",
      "epoch time measured: 22.693183422088623\n",
      "Epoch 136/250\n",
      "epoch time start: 1578295244.3485713\n",
      " - 23s - loss: 0.0247 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1558 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00136: loss did not improve\n",
      "epoch time measured: 23.317026615142822\n",
      "Epoch 137/250\n",
      "epoch time start: 1578295267.6657672\n",
      " - 23s - loss: 0.0143 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1585 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00137: loss did not improve\n",
      "epoch time measured: 23.029924869537354\n",
      "Epoch 138/250\n",
      "epoch time start: 1578295290.6958141\n",
      " - 23s - loss: 0.0242 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 107.0000 - fp_m: 1.8000 - tn_m: 107.0000 - fn_m: 1.8000 - val_loss: 0.1675 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00138: loss did not improve\n",
      "epoch time measured: 23.208508014678955\n",
      "Epoch 139/250\n",
      "epoch time start: 1578295313.9044635\n",
      " - 23s - loss: 0.0200 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.1811 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00139: loss did not improve\n",
      "epoch time measured: 23.417008638381958\n",
      "Epoch 140/250\n",
      "epoch time start: 1578295337.3216019\n",
      " - 23s - loss: 0.0212 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1922 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00140: loss did not improve\n",
      "epoch time measured: 22.953508138656616\n",
      "Epoch 141/250\n",
      "epoch time start: 1578295360.2752645\n",
      " - 23s - loss: 0.0275 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.2020 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00141: loss did not improve\n",
      "epoch time measured: 23.10350227355957\n",
      "Epoch 142/250\n",
      "epoch time start: 1578295383.3790536\n",
      " - 23s - loss: 0.0156 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.2070 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00142: loss did not improve\n",
      "epoch time measured: 22.800269842147827\n",
      "Epoch 143/250\n",
      "epoch time start: 1578295406.1794395\n",
      " - 23s - loss: 0.0284 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.2021 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00143: loss did not improve\n",
      "epoch time measured: 23.182454109191895\n",
      "Epoch 144/250\n",
      "epoch time start: 1578295429.3620005\n",
      " - 23s - loss: 0.0098 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1961 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00144: loss improved from 0.01071 to 0.00977, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.513118982315063\n",
      "Epoch 145/250\n",
      "epoch time start: 1578295452.875287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 23s - loss: 0.0117 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1952 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00145: loss did not improve\n",
      "epoch time measured: 22.762709140777588\n",
      "Epoch 146/250\n",
      "epoch time start: 1578295475.6381195\n",
      " - 24s - loss: 0.0079 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1947 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00146: loss improved from 0.00977 to 0.00786, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.853421688079834\n",
      "Epoch 147/250\n",
      "epoch time start: 1578295499.4917815\n",
      " - 23s - loss: 0.0120 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1956 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00147: loss did not improve\n",
      "epoch time measured: 23.112759113311768\n",
      "Epoch 148/250\n",
      "epoch time start: 1578295522.6046789\n",
      " - 24s - loss: 0.0190 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1997 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00148: loss did not improve\n",
      "epoch time measured: 23.502493381500244\n",
      "Epoch 149/250\n",
      "epoch time start: 1578295546.1072993\n",
      " - 23s - loss: 0.0544 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 107.6000 - fp_m: 1.2000 - tn_m: 107.6000 - fn_m: 1.2000 - val_loss: 0.2011 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00149: loss did not improve\n",
      "epoch time measured: 23.281814575195312\n",
      "Epoch 150/250\n",
      "epoch time start: 1578295569.3894296\n",
      " - 23s - loss: 0.0182 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.2002 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00150: loss did not improve\n",
      "epoch time measured: 22.944213151931763\n",
      "Epoch 151/250\n",
      "epoch time start: 1578295592.333753\n",
      " - 23s - loss: 0.0105 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1978 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00151: loss did not improve\n",
      "epoch time measured: 23.098755359649658\n",
      "Epoch 152/250\n",
      "epoch time start: 1578295615.4326155\n",
      " - 23s - loss: 0.0121 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1953 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00152: loss did not improve\n",
      "epoch time measured: 23.48224663734436\n",
      "Epoch 153/250\n",
      "epoch time start: 1578295638.9149878\n",
      " - 23s - loss: 0.0202 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.1946 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00153: loss did not improve\n",
      "epoch time measured: 23.408928155899048\n",
      "Epoch 154/250\n",
      "epoch time start: 1578295662.3240547\n",
      " - 23s - loss: 0.0163 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1941 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00154: loss did not improve\n",
      "epoch time measured: 23.223241090774536\n",
      "Epoch 155/250\n",
      "epoch time start: 1578295685.5474167\n",
      " - 23s - loss: 0.0194 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1900 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00155: loss did not improve\n",
      "epoch time measured: 23.454376220703125\n",
      "Epoch 156/250\n",
      "epoch time start: 1578295709.001983\n",
      " - 23s - loss: 0.0193 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1805 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00156: loss did not improve\n",
      "epoch time measured: 23.051836252212524\n",
      "Epoch 157/250\n",
      "epoch time start: 1578295732.053931\n",
      " - 24s - loss: 0.0115 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1710 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00157: loss did not improve\n",
      "epoch time measured: 24.030900478363037\n",
      "Epoch 158/250\n",
      "epoch time start: 1578295756.0849597\n",
      " - 23s - loss: 0.0150 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1652 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00158: loss did not improve\n",
      "epoch time measured: 23.494237184524536\n",
      "Epoch 159/250\n",
      "epoch time start: 1578295779.5793154\n",
      " - 24s - loss: 0.0088 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1631 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00159: loss did not improve\n",
      "epoch time measured: 23.777909994125366\n",
      "Epoch 160/250\n",
      "epoch time start: 1578295803.357355\n",
      " - 23s - loss: 0.0087 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1650 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00160: loss did not improve\n",
      "epoch time measured: 22.9593825340271\n",
      "Epoch 161/250\n",
      "epoch time start: 1578295826.3168573\n",
      " - 23s - loss: 0.0305 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.1569 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00161: loss did not improve\n",
      "epoch time measured: 22.73138666152954\n",
      "Epoch 162/250\n",
      "epoch time start: 1578295849.0484602\n",
      " - 24s - loss: 0.0120 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1472 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00162: loss did not improve\n",
      "epoch time measured: 23.636309146881104\n",
      "Epoch 163/250\n",
      "epoch time start: 1578295872.6849642\n",
      " - 23s - loss: 0.0280 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 108.4000 - fp_m: 0.4000 - tn_m: 108.4000 - fn_m: 0.4000 - val_loss: 0.1395 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00163: loss did not improve\n",
      "epoch time measured: 23.495036840438843\n",
      "Epoch 164/250\n",
      "epoch time start: 1578295896.1801527\n",
      " - 23s - loss: 0.0140 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1330 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00164: loss did not improve\n",
      "epoch time measured: 22.673469066619873\n",
      "Epoch 165/250\n",
      "epoch time start: 1578295918.8537233\n",
      " - 24s - loss: 0.0097 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1311 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00165: loss did not improve\n",
      "epoch time measured: 23.530983209609985\n",
      "Epoch 166/250\n",
      "epoch time start: 1578295942.384825\n",
      " - 23s - loss: 0.0167 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1326 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00166: loss did not improve\n",
      "epoch time measured: 22.891587495803833\n",
      "Epoch 167/250\n",
      "epoch time start: 1578295965.2765353\n",
      " - 23s - loss: 0.0150 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1366 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00167: loss did not improve\n",
      "epoch time measured: 23.483591556549072\n",
      "Epoch 168/250\n",
      "epoch time start: 1578295988.7602391\n",
      " - 23s - loss: 0.0139 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1421 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00168: loss did not improve\n",
      "epoch time measured: 23.368748426437378\n",
      "Epoch 169/250\n",
      "epoch time start: 1578296012.1290972\n",
      " - 23s - loss: 0.0230 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1514 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00169: loss did not improve\n",
      "epoch time measured: 22.899885892868042\n",
      "Epoch 170/250\n",
      "epoch time start: 1578296035.029117\n",
      " - 24s - loss: 0.0141 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1624 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00170: loss did not improve\n",
      "epoch time measured: 23.515978574752808\n",
      "Epoch 171/250\n",
      "epoch time start: 1578296058.5452166\n",
      " - 23s - loss: 0.0124 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1711 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00171: loss did not improve\n",
      "epoch time measured: 22.957839250564575\n",
      "Epoch 172/250\n",
      "epoch time start: 1578296081.5031757\n",
      " - 23s - loss: 0.0157 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1767 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00172: loss did not improve\n",
      "epoch time measured: 23.151314735412598\n",
      "Epoch 173/250\n",
      "epoch time start: 1578296104.6546266\n",
      " - 23s - loss: 0.0166 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1799 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00173: loss did not improve\n",
      "epoch time measured: 23.058065176010132\n",
      "Epoch 174/250\n",
      "epoch time start: 1578296127.7129714\n",
      " - 23s - loss: 0.0241 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.1835 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00174: loss did not improve\n",
      "epoch time measured: 23.040663957595825\n",
      "Epoch 175/250\n",
      "epoch time start: 1578296150.753757\n",
      " - 23s - loss: 0.0064 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1879 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00175: loss improved from 0.00786 to 0.00645, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.144026517868042\n",
      "Epoch 176/250\n",
      "epoch time start: 1578296173.8979473\n",
      " - 23s - loss: 0.0069 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1902 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00176: loss did not improve\n",
      "epoch time measured: 23.118381023406982\n",
      "Epoch 177/250\n",
      "epoch time start: 1578296197.0164478\n",
      " - 23s - loss: 0.0095 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1913 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00177: loss did not improve\n",
      "epoch time measured: 23.440418004989624\n",
      "Epoch 178/250\n",
      "epoch time start: 1578296220.456977\n",
      " - 23s - loss: 0.0147 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1868 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00178: loss did not improve\n",
      "epoch time measured: 22.933833837509155\n",
      "Epoch 179/250\n",
      "epoch time start: 1578296243.3909934\n",
      " - 23s - loss: 0.0238 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1749 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00179: loss did not improve\n",
      "epoch time measured: 22.773714780807495\n",
      "Epoch 180/250\n",
      "epoch time start: 1578296266.1648824\n",
      " - 23s - loss: 0.0107 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1630 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00180: loss did not improve\n",
      "epoch time measured: 23.346367597579956\n",
      "Epoch 181/250\n",
      "epoch time start: 1578296289.5114906\n",
      " - 24s - loss: 0.0114 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1560 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00181: loss did not improve\n",
      "epoch time measured: 24.213454008102417\n",
      "Epoch 182/250\n",
      "epoch time start: 1578296313.7250786\n",
      " - 23s - loss: 0.0135 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1512 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00182: loss did not improve\n",
      "epoch time measured: 22.905292510986328\n",
      "Epoch 183/250\n",
      "epoch time start: 1578296336.6304924\n",
      " - 24s - loss: 0.0116 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1485 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00183: loss did not improve\n",
      "epoch time measured: 23.545422315597534\n",
      "Epoch 184/250\n",
      "epoch time start: 1578296360.17605\n",
      " - 23s - loss: 0.0098 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1467 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00184: loss did not improve\n",
      "epoch time measured: 22.727675914764404\n",
      "Epoch 185/250\n",
      "epoch time start: 1578296382.9038372\n",
      " - 23s - loss: 0.0127 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1456 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00185: loss did not improve\n",
      "epoch time measured: 23.059261083602905\n",
      "Epoch 186/250\n",
      "epoch time start: 1578296405.963239\n",
      " - 23s - loss: 0.0100 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1446 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00186: loss did not improve\n",
      "epoch time measured: 23.06871771812439\n",
      "Epoch 187/250\n",
      "epoch time start: 1578296429.0320797\n",
      " - 23s - loss: 0.0086 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1435 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00187: loss did not improve\n",
      "epoch time measured: 23.40735101699829\n",
      "Epoch 188/250\n",
      "epoch time start: 1578296452.4395752\n",
      " - 23s - loss: 0.0108 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1428 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00188: loss did not improve\n",
      "epoch time measured: 23.06986165046692\n",
      "Epoch 189/250\n",
      "epoch time start: 1578296475.5095475\n",
      " - 23s - loss: 0.0090 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1427 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00189: loss did not improve\n",
      "epoch time measured: 22.98720121383667\n",
      "Epoch 190/250\n",
      "epoch time start: 1578296498.4968636\n",
      " - 23s - loss: 0.0200 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1425 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00190: loss did not improve\n",
      "epoch time measured: 23.270657777786255\n",
      "Epoch 191/250\n",
      "epoch time start: 1578296521.7676558\n",
      " - 23s - loss: 0.0102 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1433 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00191: loss did not improve\n",
      "epoch time measured: 23.211971759796143\n",
      "Epoch 192/250\n",
      "epoch time start: 1578296544.9798894\n",
      " - 23s - loss: 0.0114 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1441 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00192: loss did not improve\n",
      "epoch time measured: 23.432520151138306\n",
      "Epoch 193/250\n",
      "epoch time start: 1578296568.4125156\n",
      " - 24s - loss: 0.0107 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1462 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00193: loss did not improve\n",
      "epoch time measured: 23.58447027206421\n",
      "Epoch 194/250\n",
      "epoch time start: 1578296591.9970996\n",
      " - 23s - loss: 0.0112 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1478 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00194: loss did not improve\n",
      "epoch time measured: 23.14061665534973\n",
      "Epoch 195/250\n",
      "epoch time start: 1578296615.1378329\n",
      " - 23s - loss: 0.0185 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1475 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00195: loss did not improve\n",
      "epoch time measured: 23.282435417175293\n",
      "Epoch 196/250\n",
      "epoch time start: 1578296638.4203796\n",
      " - 23s - loss: 0.0104 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1462 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00196: loss did not improve\n",
      "epoch time measured: 23.18127727508545\n",
      "Epoch 197/250\n",
      "epoch time start: 1578296661.6017892\n",
      " - 23s - loss: 0.0082 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1478 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00197: loss did not improve\n",
      "epoch time measured: 22.871877670288086\n",
      "Epoch 198/250\n",
      "epoch time start: 1578296684.4737782\n",
      " - 23s - loss: 0.0183 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1508 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00198: loss did not improve\n",
      "epoch time measured: 23.386629581451416\n",
      "Epoch 199/250\n",
      "epoch time start: 1578296707.86052\n",
      " - 23s - loss: 0.0165 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1513 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00199: loss did not improve\n",
      "epoch time measured: 22.839173078536987\n",
      "Epoch 200/250\n",
      "epoch time start: 1578296730.6999702\n",
      " - 23s - loss: 0.0254 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1515 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00200: loss did not improve\n",
      "epoch time measured: 23.262062549591064\n",
      "Epoch 201/250\n",
      "epoch time start: 1578296753.9621365\n",
      " - 23s - loss: 0.0225 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 108.4000 - fp_m: 0.4000 - tn_m: 108.4000 - fn_m: 0.4000 - val_loss: 0.1557 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00201: loss did not improve\n",
      "epoch time measured: 23.068499326705933\n",
      "Epoch 202/250\n",
      "epoch time start: 1578296777.0307393\n",
      " - 23s - loss: 0.0066 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1600 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00202: loss did not improve\n",
      "epoch time measured: 22.952552318572998\n",
      "Epoch 203/250\n",
      "epoch time start: 1578296799.9834332\n",
      " - 23s - loss: 0.0073 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1653 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00203: loss did not improve\n",
      "epoch time measured: 23.165944576263428\n",
      "Epoch 204/250\n",
      "epoch time start: 1578296823.1494958\n",
      " - 23s - loss: 0.0066 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1708 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00204: loss did not improve\n",
      "epoch time measured: 23.240478038787842\n",
      "Epoch 205/250\n",
      "epoch time start: 1578296846.3901079\n",
      " - 23s - loss: 0.0441 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 108.4000 - fp_m: 0.4000 - tn_m: 108.4000 - fn_m: 0.4000 - val_loss: 0.1642 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00205: loss did not improve\n",
      "epoch time measured: 22.584023237228394\n",
      "Epoch 206/250\n",
      "epoch time start: 1578296868.9742439\n",
      " - 23s - loss: 0.0173 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1504 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00206: loss did not improve\n",
      "epoch time measured: 22.860496759414673\n",
      "Epoch 207/250\n",
      "epoch time start: 1578296891.834848\n",
      " - 23s - loss: 0.0154 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1435 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00207: loss did not improve\n",
      "epoch time measured: 22.990753889083862\n",
      "Epoch 208/250\n",
      "epoch time start: 1578296914.8257194\n",
      " - 23s - loss: 0.0238 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1408 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00208: loss did not improve\n",
      "epoch time measured: 23.05361771583557\n",
      "Epoch 209/250\n",
      "epoch time start: 1578296937.879481\n",
      " - 23s - loss: 0.0297 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1405 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00209: loss did not improve\n",
      "epoch time measured: 23.457005977630615\n",
      "Epoch 210/250\n",
      "epoch time start: 1578296961.3366237\n",
      " - 23s - loss: 0.0189 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1420 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00210: loss did not improve\n",
      "epoch time measured: 22.747413873672485\n",
      "Epoch 211/250\n",
      "epoch time start: 1578296984.084253\n",
      " - 23s - loss: 0.0187 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1460 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00211: loss did not improve\n",
      "epoch time measured: 23.079975128173828\n",
      "Epoch 212/250\n",
      "epoch time start: 1578297007.1643555\n",
      " - 24s - loss: 0.0114 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1494 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00212: loss did not improve\n",
      "epoch time measured: 23.758130073547363\n",
      "Epoch 213/250\n",
      "epoch time start: 1578297030.9226048\n",
      " - 24s - loss: 0.0116 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1526 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00213: loss did not improve\n",
      "epoch time measured: 23.575559616088867\n",
      "Epoch 214/250\n",
      "epoch time start: 1578297054.4982734\n",
      " - 23s - loss: 0.0112 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1554 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00214: loss did not improve\n",
      "epoch time measured: 23.051291465759277\n",
      "Epoch 215/250\n",
      "epoch time start: 1578297077.5497348\n",
      " - 23s - loss: 0.0207 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 107.6000 - fp_m: 1.2000 - tn_m: 107.6000 - fn_m: 1.2000 - val_loss: 0.1594 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00215: loss did not improve\n",
      "epoch time measured: 23.18954610824585\n",
      "Epoch 216/250\n",
      "epoch time start: 1578297100.7394242\n",
      " - 23s - loss: 0.0061 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1642 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00216: loss improved from 0.00645 to 0.00614, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.253303289413452\n",
      "Epoch 217/250\n",
      "epoch time start: 1578297123.9929152\n",
      " - 23s - loss: 0.0129 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1720 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600 - val_tp_m: 96.0000 - val_fp_m: 4.0000 - val_tn_m: 96.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00217: loss did not improve\n",
      "epoch time measured: 23.47736883163452\n",
      "Epoch 218/250\n",
      "epoch time start: 1578297147.4703956\n",
      " - 23s - loss: 0.0183 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1828 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00218: loss did not improve\n",
      "epoch time measured: 22.944000244140625\n",
      "Epoch 219/250\n",
      "epoch time start: 1578297170.4147637\n",
      " - 23s - loss: 0.0093 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1891 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00219: loss did not improve\n",
      "epoch time measured: 23.08899211883545\n",
      "Epoch 220/250\n",
      "epoch time start: 1578297193.503872\n",
      " - 23s - loss: 0.0114 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1939 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00220: loss did not improve\n",
      "epoch time measured: 22.761168241500854\n",
      "Epoch 221/250\n",
      "epoch time start: 1578297216.2652788\n",
      " - 23s - loss: 0.0099 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1980 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00221: loss did not improve\n",
      "epoch time measured: 22.89853024482727\n",
      "Epoch 222/250\n",
      "epoch time start: 1578297239.163931\n",
      " - 23s - loss: 0.0105 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1980 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00222: loss did not improve\n",
      "epoch time measured: 23.30952787399292\n",
      "Epoch 223/250\n",
      "epoch time start: 1578297262.4735882\n",
      " - 23s - loss: 0.0073 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1968 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00223: loss did not improve\n",
      "epoch time measured: 22.59252429008484\n",
      "Epoch 224/250\n",
      "epoch time start: 1578297285.0662239\n",
      " - 23s - loss: 0.0103 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1937 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00224: loss did not improve\n",
      "epoch time measured: 22.966996669769287\n",
      "Epoch 225/250\n",
      "epoch time start: 1578297308.03334\n",
      " - 23s - loss: 0.0110 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1897 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00225: loss did not improve\n",
      "epoch time measured: 23.19876480102539\n",
      "Epoch 226/250\n",
      "epoch time start: 1578297331.2322206\n",
      " - 23s - loss: 0.0105 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1896 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00226: loss did not improve\n",
      "epoch time measured: 23.141746282577515\n",
      "Epoch 227/250\n",
      "epoch time start: 1578297354.374089\n",
      " - 23s - loss: 0.0144 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1926 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00227: loss did not improve\n",
      "epoch time measured: 22.761993169784546\n",
      "Epoch 228/250\n",
      "epoch time start: 1578297377.1362119\n",
      " - 23s - loss: 0.0236 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.1930 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00228: loss did not improve\n",
      "epoch time measured: 23.164339065551758\n",
      "Epoch 229/250\n",
      "epoch time start: 1578297400.3006637\n",
      " - 23s - loss: 0.0107 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1909 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00229: loss did not improve\n",
      "epoch time measured: 23.419453620910645\n",
      "Epoch 230/250\n",
      "epoch time start: 1578297423.7202637\n",
      " - 23s - loss: 0.0070 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1909 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00230: loss did not improve\n",
      "epoch time measured: 22.897046327590942\n",
      "Epoch 231/250\n",
      "epoch time start: 1578297446.6174304\n",
      " - 24s - loss: 0.0070 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1910 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00231: loss did not improve\n",
      "epoch time measured: 23.871442079544067\n",
      "Epoch 232/250\n",
      "epoch time start: 1578297470.4889822\n",
      " - 23s - loss: 0.0259 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1881 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00232: loss did not improve\n",
      "epoch time measured: 23.237494707107544\n",
      "Epoch 233/250\n",
      "epoch time start: 1578297493.7265906\n",
      " - 23s - loss: 0.0079 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1823 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00233: loss did not improve\n",
      "epoch time measured: 23.201817274093628\n",
      "Epoch 234/250\n",
      "epoch time start: 1578297516.9286168\n",
      " - 23s - loss: 0.0048 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1777 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00234: loss improved from 0.00614 to 0.00479, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.019993543624878\n",
      "Epoch 235/250\n",
      "epoch time start: 1578297539.948825\n",
      " - 24s - loss: 0.0151 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1744 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00235: loss did not improve\n",
      "epoch time measured: 23.504876375198364\n",
      "Epoch 236/250\n",
      "epoch time start: 1578297563.453832\n",
      " - 23s - loss: 0.0104 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1720 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00236: loss did not improve\n",
      "epoch time measured: 23.273375988006592\n",
      "Epoch 237/250\n",
      "epoch time start: 1578297586.7273195\n",
      " - 23s - loss: 0.0076 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1725 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00237: loss did not improve\n",
      "epoch time measured: 22.796382904052734\n",
      "Epoch 238/250\n",
      "epoch time start: 1578297609.5240676\n",
      " - 23s - loss: 0.0116 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1723 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00238: loss did not improve\n",
      "epoch time measured: 23.347445964813232\n",
      "Epoch 239/250\n",
      "epoch time start: 1578297632.871662\n",
      " - 24s - loss: 0.0051 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1709 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00239: loss did not improve\n",
      "epoch time measured: 23.76770830154419\n",
      "Epoch 240/250\n",
      "epoch time start: 1578297656.6395156\n",
      " - 23s - loss: 0.0085 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.1758 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00240: loss did not improve\n",
      "epoch time measured: 22.617839574813843\n",
      "Epoch 241/250\n",
      "epoch time start: 1578297679.2574666\n",
      " - 23s - loss: 0.0066 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1850 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00241: loss did not improve\n",
      "epoch time measured: 22.79902672767639\n",
      "Epoch 242/250\n",
      "epoch time start: 1578297702.056612\n",
      " - 23s - loss: 0.0068 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1937 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00242: loss did not improve\n",
      "epoch time measured: 23.014495134353638\n",
      "Epoch 243/250\n",
      "epoch time start: 1578297725.0712216\n",
      " - 23s - loss: 0.0063 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1981 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00243: loss did not improve\n",
      "epoch time measured: 23.264981269836426\n",
      "Epoch 244/250\n",
      "epoch time start: 1578297748.3363342\n",
      " - 23s - loss: 0.0087 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.1979 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00244: loss did not improve\n",
      "epoch time measured: 23.32511568069458\n",
      "Epoch 245/250\n",
      "epoch time start: 1578297771.6615827\n",
      " - 23s - loss: 0.0066 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1935 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00245: loss did not improve\n",
      "epoch time measured: 23.013551235198975\n",
      "Epoch 246/250\n",
      "epoch time start: 1578297794.6752589\n",
      " - 24s - loss: 0.0079 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1892 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00246: loss did not improve\n",
      "epoch time measured: 23.733760833740234\n",
      "Epoch 247/250\n",
      "epoch time start: 1578297818.4091308\n",
      " - 23s - loss: 0.0095 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1841 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00247: loss did not improve\n",
      "epoch time measured: 23.313793659210205\n",
      "Epoch 248/250\n",
      "epoch time start: 1578297841.7230632\n",
      " - 24s - loss: 0.0081 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1815 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00248: loss did not improve\n",
      "epoch time measured: 23.610100746154785\n",
      "Epoch 249/250\n",
      "epoch time start: 1578297865.3332996\n",
      " - 23s - loss: 0.0033 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1782 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00249: loss improved from 0.00479 to 0.00331, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.074946880340576\n",
      "Epoch 250/250\n",
      "epoch time start: 1578297888.408445\n",
      " - 23s - loss: 0.0058 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.1741 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00250: loss did not improve\n",
      "epoch time measured: 23.433242559432983\n",
      "type(totalTrainingTime): <class 'numpy.float64'>\n",
      "type(convergenceEpochs): <class 'str'>\n",
      "Loading train / test dataset :  ../data/eeg_seizure_0/ ../data/eeg_seizure_0/\n",
      "x_train_path: ../data/eeg_seizure_0/X_train.npy\n",
      "Finished processing train dataset..\n",
      "Finished loading test dataset..\n",
      "\n",
      "Number of train samples :  160 Number of test samples :  100\n",
      "Number of classes :  2\n",
      "Sequence length :  4096\n",
      "y_true - 1 Tensor(\"metrics_1/tn_m/sub:0\", shape=(?, ?), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating : \n",
      "100/100 [==============================] - 4s 45ms/step\n",
      "predictions: [ True  True  True  True  True  True  True  True  True  True  True False\n",
      "  True False False False False  True  True  True  True  True  True  True\n",
      "  True False  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True False  True  True False False False  True\n",
      "  True  True False  True  True  True  True  True  True  True  True  True\n",
      " False  True False  True False  True False  True False  True  True  True\n",
      "  True  True  True False  True False  True  True  True False  True False\n",
      "  True  True  True  True False False  True  True  True  True  True  True\n",
      " False  True  True  True]\n",
      "truelabels: [ True  True  True  True  True  True  True  True  True  True  True False\n",
      "  True False False False  True  True  True  True  True  True  True  True\n",
      "  True False  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True False  True  True False False False  True\n",
      "  True  True False  True  True  True  True  True  True  True  True  True\n",
      " False  True  True  True False  True False  True False  True  True  True\n",
      "  True  True  True False  True False  True  True  True False  True  True\n",
      "  True  True  True  True False False  True  True  True  True  True  True\n",
      " False  True  True  True]\n",
      "TP: 77\n",
      "TN: 20\n",
      "FP: 0\n",
      "FN: 3\n",
      "\n",
      "Accuracy: 0.97\n",
      "Precision: 1.0\n",
      "Recall: 0.9625\n",
      "F1: 0.980891719745223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    with open(resultsFilename, \"a\") as text_file:\n",
    "        print(f\"Current Fold: 0\", file=text_file)\n",
    "    model = generate_model_2()\n",
    "    train_model(model, DATASET_INDEX_0, dataset_prefix='eeg2_attention', epochs=n_epochs, batch_size=128)\n",
    "    evaluate_model(model, DATASET_INDEX_0, dataset_prefix='eeg2_attention', batch_size=128)\n",
    "    with open(resultsFilename, \"a\") as text_file:\n",
    "        print(f\"Current Fold: 1\", file=text_file)\n",
    "    model = generate_model_2()\n",
    "    train_model(model, DATASET_INDEX_1, dataset_prefix='eeg2_attention', epochs=n_epochs, batch_size=128)\n",
    "    evaluate_model(model, DATASET_INDEX_1, dataset_prefix='eeg2_attention', batch_size=128)\n",
    "    with open(resultsFilename, \"a\") as text_file:\n",
    "        print(f\"Current Fold: 2\", file=text_file)\n",
    "    model = generate_model_2()\n",
    "    train_model(model, DATASET_INDEX_2, dataset_prefix='eeg2_attention', epochs=n_epochs, batch_size=128)\n",
    "    evaluate_model(model, DATASET_INDEX_2, dataset_prefix='eeg2_attention', batch_size=128)\n",
    "    with open(resultsFilename, \"a\") as text_file:\n",
    "        print(f\"Current Fold: 3\", file=text_file)\n",
    "    model = generate_model_2()\n",
    "    train_model(model, DATASET_INDEX_3, dataset_prefix='eeg2_attention', epochs=n_epochs, batch_size=128)\n",
    "    evaluate_model(model, DATASET_INDEX_3, dataset_prefix='eeg2_attention', batch_size=128)\n",
    "\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'results_data_FINAL.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(filepath)\n",
    "accList=list()\n",
    "precisionList=list()\n",
    "recallList=list()\n",
    "f1List=list()\n",
    "\n",
    "for line in f:\n",
    "    if(str(line[0:13])=='Fold Accuracy'):\n",
    "        listStart1=line.find('[')\n",
    "        listEnd1=line.find(']')\n",
    "        list1=ast.literal_eval(line[listStart1:listEnd1+1])\n",
    "        accList.append(list1)\n",
    "    if(str(line[0:14])=='Fold Precision'):\n",
    "        listStart2=line.find('[')\n",
    "        listEnd2=line.find(']')\n",
    "        list2=ast.literal_eval(line[listStart2:listEnd2+1])\n",
    "        precisionList.append(list2)\n",
    "    if(str(line[0:11])=='Fold Recall'):\n",
    "        listStart3=line.find('[')\n",
    "        listEnd3=line.find(']')\n",
    "        list3=ast.literal_eval(line[listStart3:listEnd3+1])\n",
    "        recallList.append(list3)\n",
    "    if(str(line[0:7])=='Fold F1'):\n",
    "        listStart4=line.find('[')\n",
    "        listEnd4=line.find(']')\n",
    "        list4=ast.literal_eval(line[listStart4:listEnd4+1])\n",
    "        f1List.append(list4)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allAccuracies=np.array(accList)\n",
    "averageAccuracy=np.average(allAccuracies, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allPrecisions=np.array(precisionList)\n",
    "averagePrecisions=np.average(allPrecisions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRecall=np.array(recallList)\n",
    "averageRecall=np.average(allRecall, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allF1s=np.array(f1List)\n",
    "averageF1s=np.average(allF1s, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(resultsFilename, \"a\") as text_file:\n",
    "    print(f\"Average Accuracies List: {str(averageAccuracy)}\", file=text_file)\n",
    "    print(f\"Average Precisions List: {str(averagePrecisions)}\", file=text_file)\n",
    "    print(f\"Average Recalls List: {str(averageRecall)}\", file=text_file)\n",
    "    print(f\"Average F1 List: {str(averageF1s)}\", file=text_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
