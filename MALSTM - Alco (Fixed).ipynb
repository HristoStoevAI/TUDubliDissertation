{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('MLSTM-FCN/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/paperspace/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/paperspace/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/paperspace/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/paperspace/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/paperspace/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/paperspace/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM, multiply, concatenate, Activation, Masking, Reshape\n",
    "from keras.layers import Conv1D, BatchNormalization, GlobalAveragePooling1D, Permute, Dropout\n",
    "\n",
    "from utils.constants import MAX_NB_VARIABLES, NB_CLASSES_LIST, MAX_TIMESTEPS_LIST\n",
    "from utils.keras_utils import train_model, evaluate_model, set_trainable\n",
    "from utils.layer_utils import AttentionLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsFilename='results_data_FINAL.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_INDEX = 60\n",
    "\n",
    "MAX_TIMESTEPS = MAX_TIMESTEPS_LIST[DATASET_INDEX]\n",
    "MAX_NB_VARIABLES = MAX_NB_VARIABLES[DATASET_INDEX]\n",
    "NB_CLASS = NB_CLASSES_LIST[DATASET_INDEX]\n",
    "\n",
    "TRAINABLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_2():\n",
    "    ip = Input(shape=(MAX_NB_VARIABLES, MAX_TIMESTEPS))\n",
    "    # stride = 10\n",
    "\n",
    "    # x = Permute((2, 1))(ip)\n",
    "    # x = Conv1D(MAX_NB_VARIABLES // stride, 8, strides=stride, padding='same', activation='relu', use_bias=False,\n",
    "    #            kernel_initializer='he_uniform')(x)  # (None, variables / stride, timesteps)\n",
    "    # x = Permute((2, 1))(x)\n",
    "\n",
    "    #ip1 = K.reshape(ip,shape=(MAX_TIMESTEPS,MAX_NB_VARIABLES))\n",
    "    #x = Permute((2, 1))(ip)\n",
    "    x = Masking()(ip)\n",
    "    x = AttentionLSTM(8)(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "\n",
    "    y = Permute((2, 1))(ip)\n",
    "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "\n",
    "    x = concatenate([x, y])\n",
    "\n",
    "    out = Dense(NB_CLASS, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(ip, out)\n",
    "    model.summary()\n",
    "\n",
    "    # add load model code here to fine-tune\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_excite_block(input):\n",
    "    ''' Create a squeeze-excite block\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "        k: width factor\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    filters = input._keras_shape[-1] # channel_axis = -1 for TF\n",
    "\n",
    "    se = GlobalAveragePooling1D()(input)\n",
    "    se = Reshape((1, filters))(se)\n",
    "    se = Dense(filters // 16,  activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = multiply([input, se])\n",
    "    return se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 255)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 255, 64)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 255, 128)     65664       permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 255, 128)     512         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 255, 128)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 128)       0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 8)         1024        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 128)       1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 255, 128)     0           activation_1[0][0]               \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 255, 256)     164096      multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 255, 256)     1024        conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 255, 256)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 256)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 256)       0           global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 16)        4096        reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1, 256)       4096        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 255, 256)     0           activation_2[0][0]               \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 255, 128)     98432       multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 64, 255)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 255, 128)     512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_lstm_1 (AttentionLSTM (None, 8)            18728       masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 255, 128)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 8)            0           attention_lstm_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 128)          0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 136)          0           dropout_1[0][0]                  \n",
      "                                                                 global_average_pooling1d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            274         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 359,482\n",
      "Trainable params: 358,458\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "Loading train / test dataset :  ../data/eeg_alco_large/ ../data/eeg_alco_large/\n",
      "x_train_path: ../data/eeg_alco_large/X_train.npy\n",
      "Finished processing train dataset..\n",
      "Finished loading test dataset..\n",
      "\n",
      "Number of train samples :  600 Number of test samples :  600\n",
      "Number of classes :  2\n",
      "Sequence length :  255\n",
      "Class weights :  [1. 1.]\n",
      "y_true - 1 Tensor(\"metrics/tn_m/sub:0\", shape=(?, ?), dtype=float32)\n",
      "Train on 600 samples, validate on 600 samples\n",
      "Epoch 1/250\n",
      "epoch time start: 1578299916.865005\n",
      " - 22s - loss: 0.6379 - acc: 0.6333 - f1_m: 0.6588 - precision_m: 0.6205 - recall_m: 0.7033 - tp_m: 85.9600 - fp_m: 53.8133 - tn_m: 68.3200 - fn_m: 36.1733 - val_loss: 0.7248 - val_acc: 0.5950 - val_f1_m: 0.6365 - val_precision_m: 0.5473 - val_recall_m: 0.7617 - val_tp_m: 93.0933 - val_fp_m: 76.8800 - val_tn_m: 45.2533 - val_fn_m: 29.0400\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.63787, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 22.597870349884033\n",
      "Epoch 2/250\n",
      "epoch time start: 1578299939.4630878\n",
      " - 21s - loss: 0.5011 - acc: 0.7533 - f1_m: 0.7296 - precision_m: 0.7290 - recall_m: 0.7317 - tp_m: 89.3867 - fp_m: 34.1333 - tn_m: 88.0000 - fn_m: 32.7467 - val_loss: 0.6343 - val_acc: 0.6833 - val_f1_m: 0.6732 - val_precision_m: 0.6318 - val_recall_m: 0.7233 - val_tp_m: 88.3867 - val_fp_m: 49.7333 - val_tn_m: 72.4000 - val_fn_m: 33.7467\n",
      "\n",
      "Epoch 00002: loss improved from 0.63787 to 0.50114, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.22189474105835\n",
      "Epoch 3/250\n",
      "epoch time start: 1578299960.685108\n",
      " - 21s - loss: 0.4240 - acc: 0.8033 - f1_m: 0.7521 - precision_m: 0.7451 - recall_m: 0.7600 - tp_m: 92.4133 - fp_m: 32.0133 - tn_m: 90.1200 - fn_m: 29.7200 - val_loss: 0.6687 - val_acc: 0.6600 - val_f1_m: 0.6284 - val_precision_m: 0.6544 - val_recall_m: 0.6067 - val_tp_m: 75.0533 - val_fp_m: 35.6933 - val_tn_m: 86.4400 - val_fn_m: 47.0800\n",
      "\n",
      "Epoch 00003: loss improved from 0.50114 to 0.42398, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.422935724258423\n",
      "Epoch 4/250\n",
      "epoch time start: 1578299982.1082702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 21s - loss: 0.3575 - acc: 0.8417 - f1_m: 0.8262 - precision_m: 0.8325 - recall_m: 0.8200 - tp_m: 100.1600 - fp_m: 20.1867 - tn_m: 101.9467 - fn_m: 21.9733 - val_loss: 0.6699 - val_acc: 0.7083 - val_f1_m: 0.6520 - val_precision_m: 0.7022 - val_recall_m: 0.6100 - val_tp_m: 74.9467 - val_fp_m: 29.8400 - val_tn_m: 92.2933 - val_fn_m: 47.1867\n",
      "\n",
      "Epoch 00004: loss improved from 0.42398 to 0.35751, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.199344396591187\n",
      "Epoch 5/250\n",
      "epoch time start: 1578300003.3078496\n",
      " - 21s - loss: 0.3030 - acc: 0.8717 - f1_m: 0.8597 - precision_m: 0.8614 - recall_m: 0.8583 - tp_m: 104.9333 - fp_m: 17.0400 - tn_m: 105.0933 - fn_m: 17.2000 - val_loss: 0.5223 - val_acc: 0.7533 - val_f1_m: 0.6853 - val_precision_m: 0.7578 - val_recall_m: 0.6283 - val_tp_m: 77.6933 - val_fp_m: 23.7600 - val_tn_m: 98.3733 - val_fn_m: 44.4400\n",
      "\n",
      "Epoch 00005: loss improved from 0.35751 to 0.30296, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.33191466331482\n",
      "Epoch 6/250\n",
      "epoch time start: 1578300024.639896\n",
      " - 21s - loss: 0.2478 - acc: 0.9050 - f1_m: 0.8821 - precision_m: 0.8793 - recall_m: 0.8850 - tp_m: 108.0800 - fp_m: 14.7733 - tn_m: 107.3600 - fn_m: 14.0533 - val_loss: 0.4683 - val_acc: 0.7733 - val_f1_m: 0.7387 - val_precision_m: 0.8035 - val_recall_m: 0.6850 - val_tp_m: 84.4800 - val_fp_m: 19.8533 - val_tn_m: 102.2800 - val_fn_m: 37.6533\n",
      "\n",
      "Epoch 00006: loss improved from 0.30296 to 0.24782, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.191362857818604\n",
      "Epoch 7/250\n",
      "epoch time start: 1578300045.8314838\n",
      " - 21s - loss: 0.2149 - acc: 0.9117 - f1_m: 0.8853 - precision_m: 0.9104 - recall_m: 0.8617 - tp_m: 105.0267 - fp_m: 10.6133 - tn_m: 111.5200 - fn_m: 17.1067 - val_loss: 0.4699 - val_acc: 0.7700 - val_f1_m: 0.7451 - val_precision_m: 0.7813 - val_recall_m: 0.7133 - val_tp_m: 87.0400 - val_fp_m: 24.8800 - val_tn_m: 97.2533 - val_fn_m: 35.0933\n",
      "\n",
      "Epoch 00007: loss improved from 0.24782 to 0.21492, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.47911548614502\n",
      "Epoch 8/250\n",
      "epoch time start: 1578300067.3108087\n",
      " - 21s - loss: 0.1636 - acc: 0.9467 - f1_m: 0.9195 - precision_m: 0.9455 - recall_m: 0.8950 - tp_m: 109.2933 - fp_m: 6.4133 - tn_m: 115.7200 - fn_m: 12.8400 - val_loss: 0.3986 - val_acc: 0.8083 - val_f1_m: 0.7908 - val_precision_m: 0.8371 - val_recall_m: 0.7500 - val_tp_m: 91.2667 - val_fp_m: 18.1733 - val_tn_m: 103.9600 - val_fn_m: 30.8667\n",
      "\n",
      "Epoch 00008: loss improved from 0.21492 to 0.16363, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.180908203125\n",
      "Epoch 9/250\n",
      "epoch time start: 1578300088.4919317\n",
      " - 21s - loss: 0.1358 - acc: 0.9617 - f1_m: 0.9266 - precision_m: 0.9590 - recall_m: 0.8967 - tp_m: 109.5733 - fp_m: 4.7733 - tn_m: 117.3600 - fn_m: 12.5600 - val_loss: 0.4071 - val_acc: 0.8083 - val_f1_m: 0.7796 - val_precision_m: 0.8391 - val_recall_m: 0.7300 - val_tp_m: 88.9733 - val_fp_m: 17.1733 - val_tn_m: 104.9600 - val_fn_m: 33.1600\n",
      "\n",
      "Epoch 00009: loss improved from 0.16363 to 0.13581, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.16098690032959\n",
      "Epoch 10/250\n",
      "epoch time start: 1578300109.653155\n",
      " - 21s - loss: 0.1111 - acc: 0.9667 - f1_m: 0.9389 - precision_m: 0.9700 - recall_m: 0.9100 - tp_m: 111.2133 - fp_m: 3.2933 - tn_m: 118.8400 - fn_m: 10.9200 - val_loss: 0.3399 - val_acc: 0.8367 - val_f1_m: 0.8038 - val_precision_m: 0.8757 - val_recall_m: 0.7450 - val_tp_m: 90.8933 - val_fp_m: 13.2000 - val_tn_m: 108.9333 - val_fn_m: 31.2400\n",
      "\n",
      "Epoch 00010: loss improved from 0.13581 to 0.11111, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.205564975738525\n",
      "Epoch 11/250\n",
      "epoch time start: 1578300130.8589242\n",
      " - 21s - loss: 0.0867 - acc: 0.9783 - f1_m: 0.9502 - precision_m: 0.9770 - recall_m: 0.9250 - tp_m: 112.8667 - fp_m: 2.6400 - tn_m: 119.4933 - fn_m: 9.2667 - val_loss: 0.3712 - val_acc: 0.8483 - val_f1_m: 0.8000 - val_precision_m: 0.8689 - val_recall_m: 0.7433 - val_tp_m: 90.8800 - val_fp_m: 14.1200 - val_tn_m: 108.0133 - val_fn_m: 31.2533\n",
      "\n",
      "Epoch 00011: loss improved from 0.11111 to 0.08673, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.48808979988098\n",
      "Epoch 12/250\n",
      "epoch time start: 1578300152.3472767\n",
      " - 21s - loss: 0.0696 - acc: 0.9833 - f1_m: 0.9541 - precision_m: 0.9892 - recall_m: 0.9217 - tp_m: 112.4400 - fp_m: 1.2800 - tn_m: 120.8533 - fn_m: 9.6933 - val_loss: 0.3979 - val_acc: 0.8250 - val_f1_m: 0.7753 - val_precision_m: 0.8590 - val_recall_m: 0.7083 - val_tp_m: 86.2000 - val_fp_m: 13.9600 - val_tn_m: 108.1733 - val_fn_m: 35.9333\n",
      "\n",
      "Epoch 00012: loss improved from 0.08673 to 0.06964, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.500823974609375\n",
      "Epoch 13/250\n",
      "epoch time start: 1578300173.8482423\n",
      " - 21s - loss: 0.0646 - acc: 0.9850 - f1_m: 0.9574 - precision_m: 0.9946 - recall_m: 0.9233 - tp_m: 112.8533 - fp_m: 0.5733 - tn_m: 121.5600 - fn_m: 9.2800 - val_loss: 0.3877 - val_acc: 0.8250 - val_f1_m: 0.7922 - val_precision_m: 0.9091 - val_recall_m: 0.7033 - val_tp_m: 85.5600 - val_fp_m: 8.7733 - val_tn_m: 113.3600 - val_fn_m: 36.5733\n",
      "\n",
      "Epoch 00013: loss improved from 0.06964 to 0.06456, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.382115125656128\n",
      "Epoch 14/250\n",
      "epoch time start: 1578300195.2306979\n",
      " - 21s - loss: 0.0946 - acc: 0.9617 - f1_m: 0.9277 - precision_m: 0.9792 - recall_m: 0.8817 - tp_m: 107.9200 - fp_m: 2.0800 - tn_m: 120.0533 - fn_m: 14.2133 - val_loss: 0.4050 - val_acc: 0.8400 - val_f1_m: 0.7867 - val_precision_m: 0.8876 - val_recall_m: 0.7083 - val_tp_m: 87.1333 - val_fp_m: 10.9200 - val_tn_m: 111.2133 - val_fn_m: 35.0000\n",
      "\n",
      "Epoch 00014: loss did not improve\n",
      "epoch time measured: 21.32556176185608\n",
      "Epoch 15/250\n",
      "epoch time start: 1578300216.5563633\n",
      " - 21s - loss: 0.0696 - acc: 0.9767 - f1_m: 0.9419 - precision_m: 0.9906 - recall_m: 0.8983 - tp_m: 109.5867 - fp_m: 1.0000 - tn_m: 121.1333 - fn_m: 12.5467 - val_loss: 0.4342 - val_acc: 0.8133 - val_f1_m: 0.7595 - val_precision_m: 0.8621 - val_recall_m: 0.6817 - val_tp_m: 82.7200 - val_fp_m: 12.6800 - val_tn_m: 109.4533 - val_fn_m: 39.4133\n",
      "\n",
      "Epoch 00015: loss did not improve\n",
      "epoch time measured: 21.190882921218872\n",
      "Epoch 16/250\n",
      "epoch time start: 1578300237.747361\n",
      " - 21s - loss: 0.0514 - acc: 0.9900 - f1_m: 0.9483 - precision_m: 0.9981 - recall_m: 0.9033 - tp_m: 110.0933 - fp_m: 0.2133 - tn_m: 121.9200 - fn_m: 12.0400 - val_loss: 0.4067 - val_acc: 0.8333 - val_f1_m: 0.7790 - val_precision_m: 0.8833 - val_recall_m: 0.6983 - val_tp_m: 85.1867 - val_fp_m: 11.4800 - val_tn_m: 110.6533 - val_fn_m: 36.9467\n",
      "\n",
      "Epoch 00016: loss improved from 0.06456 to 0.05140, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.055853366851807\n",
      "Epoch 17/250\n",
      "epoch time start: 1578300258.8034596\n",
      " - 21s - loss: 0.0423 - acc: 0.9883 - f1_m: 0.9619 - precision_m: 0.9982 - recall_m: 0.9283 - tp_m: 113.3600 - fp_m: 0.2133 - tn_m: 121.9200 - fn_m: 8.7733 - val_loss: 0.4496 - val_acc: 0.8217 - val_f1_m: 0.7672 - val_precision_m: 0.8800 - val_recall_m: 0.6850 - val_tp_m: 84.2800 - val_fp_m: 10.8533 - val_tn_m: 111.2800 - val_fn_m: 37.8533\n",
      "\n",
      "Epoch 00017: loss improved from 0.05140 to 0.04227, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.429010152816772\n",
      "Epoch 18/250\n",
      "epoch time start: 1578300280.2326133\n",
      " - 21s - loss: 0.0309 - acc: 0.9950 - f1_m: 0.9628 - precision_m: 1.0000 - recall_m: 0.9283 - tp_m: 113.3600 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 8.7733 - val_loss: 0.4200 - val_acc: 0.8267 - val_f1_m: 0.7761 - val_precision_m: 0.8921 - val_recall_m: 0.6883 - val_tp_m: 83.8400 - val_fp_m: 10.4133 - val_tn_m: 111.7200 - val_fn_m: 38.2933\n",
      "\n",
      "Epoch 00018: loss improved from 0.04227 to 0.03090, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.19341254234314\n",
      "Epoch 19/250\n",
      "epoch time start: 1578300301.4261456\n",
      " - 21s - loss: 0.0210 - acc: 0.9983 - f1_m: 0.9768 - precision_m: 1.0000 - recall_m: 0.9550 - tp_m: 116.8400 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 5.2933 - val_loss: 0.3575 - val_acc: 0.8533 - val_f1_m: 0.7952 - val_precision_m: 0.9248 - val_recall_m: 0.7000 - val_tp_m: 85.2667 - val_fp_m: 7.2133 - val_tn_m: 114.9200 - val_fn_m: 36.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00019: loss improved from 0.03090 to 0.02101, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.21800136566162\n",
      "Epoch 20/250\n",
      "epoch time start: 1578300322.6443748\n",
      " - 22s - loss: 0.0171 - acc: 1.0000 - f1_m: 0.9822 - precision_m: 1.0000 - recall_m: 0.9650 - tp_m: 117.8533 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 4.2800 - val_loss: 0.3633 - val_acc: 0.8517 - val_f1_m: 0.7963 - val_precision_m: 0.9254 - val_recall_m: 0.7000 - val_tp_m: 85.3333 - val_fp_m: 7.0667 - val_tn_m: 115.0667 - val_fn_m: 36.8000\n",
      "\n",
      "Epoch 00020: loss improved from 0.02101 to 0.01707, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.61645197868347\n",
      "Epoch 21/250\n",
      "epoch time start: 1578300344.2610278\n",
      " - 21s - loss: 0.0129 - acc: 1.0000 - f1_m: 0.9890 - precision_m: 1.0000 - recall_m: 0.9783 - tp_m: 119.5600 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 2.5733 - val_loss: 0.3493 - val_acc: 0.8583 - val_f1_m: 0.7969 - val_precision_m: 0.9211 - val_recall_m: 0.7033 - val_tp_m: 86.0267 - val_fp_m: 7.6267 - val_tn_m: 114.5067 - val_fn_m: 36.1067\n",
      "\n",
      "Epoch 00021: loss improved from 0.01707 to 0.01291, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.215513706207275\n",
      "Epoch 22/250\n",
      "epoch time start: 1578300365.4767969\n",
      " - 21s - loss: 0.0107 - acc: 1.0000 - f1_m: 0.9848 - precision_m: 1.0000 - recall_m: 0.9700 - tp_m: 118.4267 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 3.7067 - val_loss: 0.3454 - val_acc: 0.8633 - val_f1_m: 0.8035 - val_precision_m: 0.9302 - val_recall_m: 0.7083 - val_tp_m: 86.2667 - val_fp_m: 6.7067 - val_tn_m: 115.4267 - val_fn_m: 35.8667\n",
      "\n",
      "Epoch 00022: loss improved from 0.01291 to 0.01068, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.22908353805542\n",
      "Epoch 23/250\n",
      "epoch time start: 1578300386.706209\n",
      " - 21s - loss: 0.0120 - acc: 0.9983 - f1_m: 0.9907 - precision_m: 1.0000 - recall_m: 0.9817 - tp_m: 120.1200 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 2.0133 - val_loss: 0.3194 - val_acc: 0.8683 - val_f1_m: 0.8066 - val_precision_m: 0.9327 - val_recall_m: 0.7117 - val_tp_m: 86.8933 - val_fp_m: 6.4133 - val_tn_m: 115.7200 - val_fn_m: 35.2400\n",
      "\n",
      "Epoch 00023: loss did not improve\n",
      "epoch time measured: 21.201308965682983\n",
      "Epoch 24/250\n",
      "epoch time start: 1578300407.907637\n",
      " - 21s - loss: 0.0126 - acc: 1.0000 - f1_m: 0.9774 - precision_m: 1.0000 - recall_m: 0.9567 - tp_m: 116.8533 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 5.2800 - val_loss: 0.3660 - val_acc: 0.8467 - val_f1_m: 0.7843 - val_precision_m: 0.9199 - val_recall_m: 0.6867 - val_tp_m: 83.4933 - val_fp_m: 7.4800 - val_tn_m: 114.6533 - val_fn_m: 38.6400\n",
      "\n",
      "Epoch 00024: loss did not improve\n",
      "epoch time measured: 21.164339780807495\n",
      "Epoch 25/250\n",
      "epoch time start: 1578300429.0720844\n",
      " - 21s - loss: 0.0075 - acc: 1.0000 - f1_m: 0.9907 - precision_m: 1.0000 - recall_m: 0.9817 - tp_m: 119.8533 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 2.2800 - val_loss: 0.3441 - val_acc: 0.8667 - val_f1_m: 0.8076 - val_precision_m: 0.9325 - val_recall_m: 0.7133 - val_tp_m: 86.9733 - val_fp_m: 6.4267 - val_tn_m: 115.7067 - val_fn_m: 35.1600\n",
      "\n",
      "Epoch 00025: loss improved from 0.01068 to 0.00746, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.266530513763428\n",
      "Epoch 26/250\n",
      "epoch time start: 1578300450.3388762\n",
      " - 21s - loss: 0.0057 - acc: 1.0000 - f1_m: 0.9966 - precision_m: 1.0000 - recall_m: 0.9933 - tp_m: 121.4133 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.7200 - val_loss: 0.3583 - val_acc: 0.8567 - val_f1_m: 0.8009 - val_precision_m: 0.9331 - val_recall_m: 0.7033 - val_tp_m: 85.6267 - val_fp_m: 6.3467 - val_tn_m: 115.7867 - val_fn_m: 36.5067\n",
      "\n",
      "Epoch 00026: loss improved from 0.00746 to 0.00569, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.135478734970093\n",
      "Epoch 27/250\n",
      "epoch time start: 1578300471.4745853\n",
      " - 21s - loss: 0.0053 - acc: 1.0000 - f1_m: 0.9906 - precision_m: 1.0000 - recall_m: 0.9817 - tp_m: 119.7867 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 2.3467 - val_loss: 0.3205 - val_acc: 0.8800 - val_f1_m: 0.8018 - val_precision_m: 0.9419 - val_recall_m: 0.7017 - val_tp_m: 85.4133 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 36.7200\n",
      "\n",
      "Epoch 00027: loss improved from 0.00569 to 0.00526, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.30317997932434\n",
      "Epoch 28/250\n",
      "epoch time start: 1578300492.777904\n",
      " - 21s - loss: 0.0037 - acc: 1.0000 - f1_m: 0.9975 - precision_m: 1.0000 - recall_m: 0.9950 - tp_m: 121.5600 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.5733 - val_loss: 0.3207 - val_acc: 0.8783 - val_f1_m: 0.7979 - val_precision_m: 0.9417 - val_recall_m: 0.6967 - val_tp_m: 84.7733 - val_fp_m: 5.2000 - val_tn_m: 116.9333 - val_fn_m: 37.3600\n",
      "\n",
      "Epoch 00028: loss improved from 0.00526 to 0.00370, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.263841152191162\n",
      "Epoch 29/250\n",
      "epoch time start: 1578300514.0418854\n",
      " - 21s - loss: 0.0032 - acc: 1.0000 - f1_m: 0.9992 - precision_m: 1.0000 - recall_m: 0.9983 - tp_m: 121.9867 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.1467 - val_loss: 0.3220 - val_acc: 0.8750 - val_f1_m: 0.8096 - val_precision_m: 0.9447 - val_recall_m: 0.7117 - val_tp_m: 86.6933 - val_fp_m: 5.2000 - val_tn_m: 116.9333 - val_fn_m: 35.4400\n",
      "\n",
      "Epoch 00029: loss improved from 0.00370 to 0.00324, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.266568183898926\n",
      "Epoch 30/250\n",
      "epoch time start: 1578300535.3086283\n",
      " - 21s - loss: 0.0041 - acc: 1.0000 - f1_m: 0.9950 - precision_m: 1.0000 - recall_m: 0.9900 - tp_m: 120.8533 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 1.2800 - val_loss: 0.3222 - val_acc: 0.8767 - val_f1_m: 0.8104 - val_precision_m: 0.9446 - val_recall_m: 0.7133 - val_tp_m: 86.8400 - val_fp_m: 5.2000 - val_tn_m: 116.9333 - val_fn_m: 35.2933\n",
      "\n",
      "Epoch 00030: loss did not improve\n",
      "epoch time measured: 21.16466975212097\n",
      "Epoch 31/250\n",
      "epoch time start: 1578300556.4734042\n",
      " - 21s - loss: 0.0030 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.3157 - val_acc: 0.8767 - val_f1_m: 0.8095 - val_precision_m: 0.9422 - val_recall_m: 0.7117 - val_tp_m: 86.6267 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 35.5067\n",
      "\n",
      "Epoch 00031: loss improved from 0.00324 to 0.00296, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.34749722480774\n",
      "Epoch 32/250\n",
      "epoch time start: 1578300577.8210464\n",
      " - 21s - loss: 0.0027 - acc: 1.0000 - f1_m: 0.9992 - precision_m: 1.0000 - recall_m: 0.9983 - tp_m: 121.9867 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.1467 - val_loss: 0.3512 - val_acc: 0.8617 - val_f1_m: 0.8072 - val_precision_m: 0.9416 - val_recall_m: 0.7100 - val_tp_m: 86.2800 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 35.8533\n",
      "\n",
      "Epoch 00032: loss improved from 0.00296 to 0.00272, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.23925280570984\n",
      "Epoch 33/250\n",
      "epoch time start: 1578300599.060437\n",
      " - 21s - loss: 0.0029 - acc: 1.0000 - f1_m: 0.9958 - precision_m: 1.0000 - recall_m: 0.9917 - tp_m: 121.0667 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 1.0667 - val_loss: 0.3230 - val_acc: 0.8800 - val_f1_m: 0.8108 - val_precision_m: 0.9397 - val_recall_m: 0.7150 - val_tp_m: 87.0533 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 35.0800\n",
      "\n",
      "Epoch 00033: loss did not improve\n",
      "epoch time measured: 21.45153260231018\n",
      "Epoch 34/250\n",
      "epoch time start: 1578300620.5120752\n",
      " - 22s - loss: 0.0034 - acc: 1.0000 - f1_m: 0.9958 - precision_m: 1.0000 - recall_m: 0.9917 - tp_m: 121.2667 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.8667 - val_loss: 0.3304 - val_acc: 0.8783 - val_f1_m: 0.8133 - val_precision_m: 0.9432 - val_recall_m: 0.7167 - val_tp_m: 87.2667 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 34.8667\n",
      "\n",
      "Epoch 00034: loss did not improve\n",
      "epoch time measured: 21.639963150024414\n",
      "Epoch 35/250\n",
      "epoch time start: 1578300642.152148\n",
      " - 22s - loss: 0.0029 - acc: 1.0000 - f1_m: 0.9923 - precision_m: 1.0000 - recall_m: 0.9850 - tp_m: 120.3467 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 1.7867 - val_loss: 0.3294 - val_acc: 0.8833 - val_f1_m: 0.8191 - val_precision_m: 0.9461 - val_recall_m: 0.7233 - val_tp_m: 88.1200 - val_fp_m: 5.2000 - val_tn_m: 116.9333 - val_fn_m: 34.0133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00035: loss did not improve\n",
      "epoch time measured: 21.858596324920654\n",
      "Epoch 36/250\n",
      "epoch time start: 1578300664.0108562\n",
      " - 21s - loss: 0.0028 - acc: 1.0000 - f1_m: 0.9975 - precision_m: 1.0000 - recall_m: 0.9950 - tp_m: 121.5600 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.5733 - val_loss: 0.3243 - val_acc: 0.8867 - val_f1_m: 0.8181 - val_precision_m: 0.9439 - val_recall_m: 0.7233 - val_tp_m: 88.0533 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 34.0800\n",
      "\n",
      "Epoch 00036: loss did not improve\n",
      "epoch time measured: 21.24206852912903\n",
      "Epoch 37/250\n",
      "epoch time start: 1578300685.2530398\n",
      " - 21s - loss: 0.0020 - acc: 1.0000 - f1_m: 0.9975 - precision_m: 1.0000 - recall_m: 0.9950 - tp_m: 121.4933 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.6400 - val_loss: 0.3699 - val_acc: 0.8617 - val_f1_m: 0.8093 - val_precision_m: 0.9404 - val_recall_m: 0.7133 - val_tp_m: 86.6400 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 35.4933\n",
      "\n",
      "Epoch 00037: loss improved from 0.00272 to 0.00205, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.353148937225342\n",
      "Epoch 38/250\n",
      "epoch time start: 1578300706.6063995\n",
      " - 21s - loss: 0.0024 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.3480 - val_acc: 0.8767 - val_f1_m: 0.8137 - val_precision_m: 0.9461 - val_recall_m: 0.7167 - val_tp_m: 87.1333 - val_fp_m: 4.9867 - val_tn_m: 117.1467 - val_fn_m: 35.0000\n",
      "\n",
      "Epoch 00038: loss did not improve\n",
      "epoch time measured: 21.22215986251831\n",
      "Epoch 39/250\n",
      "epoch time start: 1578300727.828996\n",
      " - 21s - loss: 0.0018 - acc: 1.0000 - f1_m: 0.9983 - precision_m: 1.0000 - recall_m: 0.9967 - tp_m: 121.7733 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.3600 - val_loss: 0.3356 - val_acc: 0.8833 - val_f1_m: 0.8212 - val_precision_m: 0.9377 - val_recall_m: 0.7317 - val_tp_m: 88.9867 - val_fp_m: 5.9867 - val_tn_m: 116.1467 - val_fn_m: 33.1467\n",
      "\n",
      "Epoch 00039: loss improved from 0.00205 to 0.00182, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.454270124435425\n",
      "Epoch 40/250\n",
      "epoch time start: 1578300749.2835014\n",
      " - 21s - loss: 0.0025 - acc: 1.0000 - f1_m: 0.9975 - precision_m: 1.0000 - recall_m: 0.9950 - tp_m: 121.4933 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.6400 - val_loss: 0.3737 - val_acc: 0.8700 - val_f1_m: 0.8193 - val_precision_m: 0.9454 - val_recall_m: 0.7267 - val_tp_m: 88.2800 - val_fp_m: 5.1333 - val_tn_m: 117.0000 - val_fn_m: 33.8533\n",
      "\n",
      "Epoch 00040: loss did not improve\n",
      "epoch time measured: 21.34452986717224\n",
      "Epoch 41/250\n",
      "epoch time start: 1578300770.628146\n",
      " - 21s - loss: 0.0019 - acc: 1.0000 - f1_m: 0.9983 - precision_m: 1.0000 - recall_m: 0.9967 - tp_m: 121.7067 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.4267 - val_loss: 0.3694 - val_acc: 0.8783 - val_f1_m: 0.8177 - val_precision_m: 0.9466 - val_recall_m: 0.7233 - val_tp_m: 87.8533 - val_fp_m: 4.9867 - val_tn_m: 117.1467 - val_fn_m: 34.2800\n",
      "\n",
      "Epoch 00041: loss did not improve\n",
      "epoch time measured: 21.09734869003296\n",
      "Epoch 42/250\n",
      "epoch time start: 1578300791.7255979\n",
      " - 21s - loss: 0.0019 - acc: 1.0000 - f1_m: 0.9992 - precision_m: 1.0000 - recall_m: 0.9983 - tp_m: 121.9200 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.2133 - val_loss: 0.3544 - val_acc: 0.8817 - val_f1_m: 0.8134 - val_precision_m: 0.9429 - val_recall_m: 0.7183 - val_tp_m: 87.2133 - val_fp_m: 5.2000 - val_tn_m: 116.9333 - val_fn_m: 34.9200\n",
      "\n",
      "Epoch 00042: loss did not improve\n",
      "epoch time measured: 21.400289058685303\n",
      "Epoch 43/250\n",
      "epoch time start: 1578300813.1259875\n",
      " - 21s - loss: 0.0020 - acc: 1.0000 - f1_m: 0.9949 - precision_m: 1.0000 - recall_m: 0.9900 - tp_m: 120.8533 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 1.2800 - val_loss: 0.3684 - val_acc: 0.8750 - val_f1_m: 0.8096 - val_precision_m: 0.9399 - val_recall_m: 0.7150 - val_tp_m: 86.7867 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 35.3467\n",
      "\n",
      "Epoch 00043: loss did not improve\n",
      "epoch time measured: 21.312240600585938\n",
      "Epoch 44/250\n",
      "epoch time start: 1578300834.4383373\n",
      " - 21s - loss: 0.0018 - acc: 1.0000 - f1_m: 0.9983 - precision_m: 1.0000 - recall_m: 0.9967 - tp_m: 121.7067 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.4267 - val_loss: 0.3631 - val_acc: 0.8783 - val_f1_m: 0.8194 - val_precision_m: 0.9474 - val_recall_m: 0.7250 - val_tp_m: 88.0000 - val_fp_m: 4.9867 - val_tn_m: 117.1467 - val_fn_m: 34.1333\n",
      "\n",
      "Epoch 00044: loss improved from 0.00182 to 0.00180, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.38875651359558\n",
      "Epoch 45/250\n",
      "epoch time start: 1578300855.8273249\n",
      " - 21s - loss: 0.0033 - acc: 1.0000 - f1_m: 0.9906 - precision_m: 1.0000 - recall_m: 0.9817 - tp_m: 120.1200 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 2.0133 - val_loss: 0.3603 - val_acc: 0.8800 - val_f1_m: 0.8104 - val_precision_m: 0.9367 - val_recall_m: 0.7167 - val_tp_m: 87.0000 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 35.1333\n",
      "\n",
      "Epoch 00045: loss did not improve\n",
      "epoch time measured: 21.309342622756958\n",
      "Epoch 46/250\n",
      "epoch time start: 1578300877.1367612\n",
      " - 21s - loss: 0.0021 - acc: 1.0000 - f1_m: 0.9949 - precision_m: 1.0000 - recall_m: 0.9900 - tp_m: 120.8533 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 1.2800 - val_loss: 0.4048 - val_acc: 0.8733 - val_f1_m: 0.8042 - val_precision_m: 0.9294 - val_recall_m: 0.7133 - val_tp_m: 86.5733 - val_fp_m: 6.2000 - val_tn_m: 115.9333 - val_fn_m: 35.5600\n",
      "\n",
      "Epoch 00046: loss did not improve\n",
      "epoch time measured: 21.346773624420166\n",
      "Epoch 47/250\n",
      "epoch time start: 1578300898.4836798\n",
      " - 21s - loss: 0.0013 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4070 - val_acc: 0.8783 - val_f1_m: 0.8035 - val_precision_m: 0.9272 - val_recall_m: 0.7133 - val_tp_m: 86.5733 - val_fp_m: 6.4133 - val_tn_m: 115.7200 - val_fn_m: 35.5600\n",
      "\n",
      "Epoch 00047: loss improved from 0.00180 to 0.00135, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.295281410217285\n",
      "Epoch 48/250\n",
      "epoch time start: 1578300919.7791724\n",
      " - 21s - loss: 0.0013 - acc: 1.0000 - f1_m: 0.9983 - precision_m: 1.0000 - recall_m: 0.9967 - tp_m: 121.7067 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.4267 - val_loss: 0.3810 - val_acc: 0.8817 - val_f1_m: 0.8135 - val_precision_m: 0.9368 - val_recall_m: 0.7217 - val_tp_m: 87.6400 - val_fp_m: 5.7733 - val_tn_m: 116.3600 - val_fn_m: 34.4933\n",
      "\n",
      "Epoch 00048: loss improved from 0.00135 to 0.00131, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.257356643676758\n",
      "Epoch 49/250\n",
      "epoch time start: 1578300941.0367734\n",
      " - 21s - loss: 0.0012 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.3637 - val_acc: 0.8750 - val_f1_m: 0.8121 - val_precision_m: 0.9355 - val_recall_m: 0.7200 - val_tp_m: 87.4267 - val_fp_m: 5.9867 - val_tn_m: 116.1467 - val_fn_m: 34.7067\n",
      "\n",
      "Epoch 00049: loss improved from 0.00131 to 0.00124, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.29562544822693\n",
      "Epoch 50/250\n",
      "epoch time start: 1578300962.332602\n",
      " - 21s - loss: 0.0011 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.3644 - val_acc: 0.8850 - val_f1_m: 0.8169 - val_precision_m: 0.9445 - val_recall_m: 0.7217 - val_tp_m: 87.5733 - val_fp_m: 5.2000 - val_tn_m: 116.9333 - val_fn_m: 34.5600\n",
      "\n",
      "Epoch 00050: loss improved from 0.00124 to 0.00110, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.204351663589478\n",
      "Epoch 51/250\n",
      "epoch time start: 1578300983.5371943\n",
      " - 21s - loss: 0.0010 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.3653 - val_acc: 0.8800 - val_f1_m: 0.8209 - val_precision_m: 0.9434 - val_recall_m: 0.7283 - val_tp_m: 88.4267 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 33.7067\n",
      "\n",
      "Epoch 00051: loss improved from 0.00110 to 0.00101, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.355783700942993\n",
      "Epoch 52/250\n",
      "epoch time start: 1578301004.8932471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 21s - loss: 0.0012 - acc: 1.0000 - f1_m: 0.9983 - precision_m: 1.0000 - recall_m: 0.9967 - tp_m: 121.7067 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.4267 - val_loss: 0.3777 - val_acc: 0.8750 - val_f1_m: 0.8214 - val_precision_m: 0.9477 - val_recall_m: 0.7267 - val_tp_m: 88.2133 - val_fp_m: 4.9867 - val_tn_m: 117.1467 - val_fn_m: 33.9200\n",
      "\n",
      "Epoch 00052: loss did not improve\n",
      "epoch time measured: 21.068852424621582\n",
      "Epoch 53/250\n",
      "epoch time start: 1578301025.9622111\n",
      " - 21s - loss: 0.0013 - acc: 1.0000 - f1_m: 0.9983 - precision_m: 1.0000 - recall_m: 0.9967 - tp_m: 121.7067 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.4267 - val_loss: 0.3936 - val_acc: 0.8733 - val_f1_m: 0.8217 - val_precision_m: 0.9454 - val_recall_m: 0.7283 - val_tp_m: 88.4267 - val_fp_m: 5.2000 - val_tn_m: 116.9333 - val_fn_m: 33.7067\n",
      "\n",
      "Epoch 00053: loss did not improve\n",
      "epoch time measured: 21.26231861114502\n",
      "Epoch 54/250\n",
      "epoch time start: 1578301047.2246482\n",
      " - 21s - loss: 0.0012 - acc: 1.0000 - f1_m: 0.9992 - precision_m: 1.0000 - recall_m: 0.9983 - tp_m: 121.9200 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.2133 - val_loss: 0.3720 - val_acc: 0.8800 - val_f1_m: 0.8222 - val_precision_m: 0.9434 - val_recall_m: 0.7300 - val_tp_m: 88.6400 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 33.4933\n",
      "\n",
      "Epoch 00054: loss did not improve\n",
      "epoch time measured: 21.26902151107788\n",
      "Epoch 55/250\n",
      "epoch time start: 1578301068.493771\n",
      " - 21s - loss: 0.0012 - acc: 1.0000 - f1_m: 0.9975 - precision_m: 1.0000 - recall_m: 0.9950 - tp_m: 121.4933 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.6400 - val_loss: 0.3738 - val_acc: 0.8783 - val_f1_m: 0.8199 - val_precision_m: 0.9407 - val_recall_m: 0.7283 - val_tp_m: 88.3600 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 33.7733\n",
      "\n",
      "Epoch 00055: loss did not improve\n",
      "epoch time measured: 21.208120822906494\n",
      "Epoch 56/250\n",
      "epoch time start: 1578301089.7020142\n",
      " - 21s - loss: 8.9414e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.3870 - val_acc: 0.8767 - val_f1_m: 0.8179 - val_precision_m: 0.9419 - val_recall_m: 0.7250 - val_tp_m: 88.0000 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 34.1333\n",
      "\n",
      "Epoch 00056: loss improved from 0.00101 to 0.00089, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.272921562194824\n",
      "Epoch 57/250\n",
      "epoch time start: 1578301110.9750524\n",
      " - 21s - loss: 9.7365e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.3881 - val_acc: 0.8817 - val_f1_m: 0.8200 - val_precision_m: 0.9446 - val_recall_m: 0.7267 - val_tp_m: 88.2133 - val_fp_m: 5.2000 - val_tn_m: 116.9333 - val_fn_m: 33.9200\n",
      "\n",
      "Epoch 00057: loss did not improve\n",
      "epoch time measured: 21.162230253219604\n",
      "Epoch 58/250\n",
      "epoch time start: 1578301132.1374006\n",
      " - 21s - loss: 8.6906e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.3857 - val_acc: 0.8767 - val_f1_m: 0.8252 - val_precision_m: 0.9432 - val_recall_m: 0.7350 - val_tp_m: 89.2800 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 32.8533\n",
      "\n",
      "Epoch 00058: loss improved from 0.00089 to 0.00087, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.217249631881714\n",
      "Epoch 59/250\n",
      "epoch time start: 1578301153.354994\n",
      " - 21s - loss: 8.5346e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.3864 - val_acc: 0.8767 - val_f1_m: 0.8231 - val_precision_m: 0.9431 - val_recall_m: 0.7317 - val_tp_m: 88.8533 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 33.2800\n",
      "\n",
      "Epoch 00059: loss improved from 0.00087 to 0.00085, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.309954404830933\n",
      "Epoch 60/250\n",
      "epoch time start: 1578301174.665183\n",
      " - 21s - loss: 8.4725e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.3889 - val_acc: 0.8733 - val_f1_m: 0.8241 - val_precision_m: 0.9431 - val_recall_m: 0.7333 - val_tp_m: 89.0667 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 33.0667\n",
      "\n",
      "Epoch 00060: loss improved from 0.00085 to 0.00085, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.243948936462402\n",
      "Epoch 61/250\n",
      "epoch time start: 1578301195.9092839\n",
      " - 21s - loss: 7.5413e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.3932 - val_acc: 0.8767 - val_f1_m: 0.8218 - val_precision_m: 0.9468 - val_recall_m: 0.7283 - val_tp_m: 88.4267 - val_fp_m: 4.9867 - val_tn_m: 117.1467 - val_fn_m: 33.7067\n",
      "\n",
      "Epoch 00061: loss improved from 0.00085 to 0.00075, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.06482243537903\n",
      "Epoch 62/250\n",
      "epoch time start: 1578301216.9744396\n",
      " - 21s - loss: 8.4995e-04 - acc: 1.0000 - f1_m: 0.9992 - precision_m: 1.0000 - recall_m: 0.9983 - tp_m: 121.9200 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.2133 - val_loss: 0.3927 - val_acc: 0.8750 - val_f1_m: 0.8232 - val_precision_m: 0.9474 - val_recall_m: 0.7300 - val_tp_m: 88.6400 - val_fp_m: 4.9867 - val_tn_m: 117.1467 - val_fn_m: 33.4933\n",
      "\n",
      "Epoch 00062: loss did not improve\n",
      "epoch time measured: 21.1233811378479\n",
      "Epoch 63/250\n",
      "epoch time start: 1578301238.0979233\n",
      " - 21s - loss: 6.8665e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.3917 - val_acc: 0.8733 - val_f1_m: 0.8255 - val_precision_m: 0.9476 - val_recall_m: 0.7333 - val_tp_m: 89.0000 - val_fp_m: 4.9867 - val_tn_m: 117.1467 - val_fn_m: 33.1333\n",
      "\n",
      "Epoch 00063: loss improved from 0.00075 to 0.00069, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.131338834762573\n",
      "Epoch 64/250\n",
      "epoch time start: 1578301259.2294624\n",
      " - 21s - loss: 6.8103e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.3958 - val_acc: 0.8783 - val_f1_m: 0.8247 - val_precision_m: 0.9458 - val_recall_m: 0.7333 - val_tp_m: 89.0667 - val_fp_m: 5.2000 - val_tn_m: 116.9333 - val_fn_m: 33.0667\n",
      "\n",
      "Epoch 00064: loss improved from 0.00069 to 0.00068, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.122517585754395\n",
      "Epoch 65/250\n",
      "epoch time start: 1578301280.3521028\n",
      " - 21s - loss: 7.6424e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.3973 - val_acc: 0.8783 - val_f1_m: 0.8272 - val_precision_m: 0.9461 - val_recall_m: 0.7367 - val_tp_m: 89.4933 - val_fp_m: 5.2000 - val_tn_m: 116.9333 - val_fn_m: 32.6400\n",
      "\n",
      "Epoch 00065: loss did not improve\n",
      "epoch time measured: 21.22157907485962\n",
      "Epoch 66/250\n",
      "epoch time start: 1578301301.5738974\n",
      " - 21s - loss: 6.2907e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4016 - val_acc: 0.8783 - val_f1_m: 0.8272 - val_precision_m: 0.9461 - val_recall_m: 0.7367 - val_tp_m: 89.4933 - val_fp_m: 5.2000 - val_tn_m: 116.9333 - val_fn_m: 32.6400\n",
      "\n",
      "Epoch 00066: loss improved from 0.00068 to 0.00063, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.12257695198059\n",
      "Epoch 67/250\n",
      "epoch time start: 1578301322.6966882\n",
      " - 21s - loss: 6.8164e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4018 - val_acc: 0.8783 - val_f1_m: 0.8261 - val_precision_m: 0.9460 - val_recall_m: 0.7350 - val_tp_m: 89.2800 - val_fp_m: 5.2000 - val_tn_m: 116.9333 - val_fn_m: 32.8533\n",
      "\n",
      "Epoch 00067: loss did not improve\n",
      "epoch time measured: 20.96029305458069\n",
      "Epoch 68/250\n",
      "epoch time start: 1578301343.6572444\n",
      " - 21s - loss: 7.1780e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4030 - val_acc: 0.8833 - val_f1_m: 0.8236 - val_precision_m: 0.9454 - val_recall_m: 0.7317 - val_tp_m: 88.7867 - val_fp_m: 5.2000 - val_tn_m: 116.9333 - val_fn_m: 33.3467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00068: loss did not improve\n",
      "epoch time measured: 21.226765871047974\n",
      "Epoch 69/250\n",
      "epoch time start: 1578301364.8841267\n",
      " - 21s - loss: 5.8009e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4066 - val_acc: 0.8833 - val_f1_m: 0.8240 - val_precision_m: 0.9476 - val_recall_m: 0.7317 - val_tp_m: 88.7867 - val_fp_m: 4.9867 - val_tn_m: 117.1467 - val_fn_m: 33.3467\n",
      "\n",
      "Epoch 00069: loss improved from 0.00063 to 0.00058, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.269288778305054\n",
      "Epoch 70/250\n",
      "epoch time start: 1578301386.1536736\n",
      " - 21s - loss: 5.5915e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4061 - val_acc: 0.8800 - val_f1_m: 0.8240 - val_precision_m: 0.9477 - val_recall_m: 0.7317 - val_tp_m: 88.7867 - val_fp_m: 4.9867 - val_tn_m: 117.1467 - val_fn_m: 33.3467\n",
      "\n",
      "Epoch 00070: loss improved from 0.00058 to 0.00056, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.37551236152649\n",
      "Epoch 71/250\n",
      "epoch time start: 1578301407.529554\n",
      " - 21s - loss: 5.7574e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4054 - val_acc: 0.8850 - val_f1_m: 0.8225 - val_precision_m: 0.9429 - val_recall_m: 0.7317 - val_tp_m: 88.7867 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 33.3467\n",
      "\n",
      "Epoch 00071: loss did not improve\n",
      "epoch time measured: 21.349469661712646\n",
      "Epoch 72/250\n",
      "epoch time start: 1578301428.8791256\n",
      " - 21s - loss: 5.7142e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4061 - val_acc: 0.8833 - val_f1_m: 0.8196 - val_precision_m: 0.9403 - val_recall_m: 0.7283 - val_tp_m: 88.3600 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 33.7733\n",
      "\n",
      "Epoch 00072: loss did not improve\n",
      "epoch time measured: 21.169057369232178\n",
      "Epoch 73/250\n",
      "epoch time start: 1578301450.0483763\n",
      " - 21s - loss: 5.4447e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4097 - val_acc: 0.8817 - val_f1_m: 0.8222 - val_precision_m: 0.9385 - val_recall_m: 0.7333 - val_tp_m: 89.0000 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 33.1333\n",
      "\n",
      "Epoch 00073: loss improved from 0.00056 to 0.00054, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.351558923721313\n",
      "Epoch 74/250\n",
      "epoch time start: 1578301471.4000978\n",
      " - 21s - loss: 4.9025e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4056 - val_acc: 0.8783 - val_f1_m: 0.8249 - val_precision_m: 0.9430 - val_recall_m: 0.7350 - val_tp_m: 89.2133 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 32.9200\n",
      "\n",
      "Epoch 00074: loss improved from 0.00054 to 0.00049, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.275727033615112\n",
      "Epoch 75/250\n",
      "epoch time start: 1578301492.6760461\n",
      " - 21s - loss: 5.0639e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4062 - val_acc: 0.8767 - val_f1_m: 0.8260 - val_precision_m: 0.9432 - val_recall_m: 0.7367 - val_tp_m: 89.4267 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 32.7067\n",
      "\n",
      "Epoch 00075: loss did not improve\n",
      "epoch time measured: 21.163496255874634\n",
      "Epoch 76/250\n",
      "epoch time start: 1578301513.8396528\n",
      " - 21s - loss: 7.7054e-04 - acc: 1.0000 - f1_m: 0.9992 - precision_m: 1.0000 - recall_m: 0.9983 - tp_m: 121.9200 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.2133 - val_loss: 0.4137 - val_acc: 0.8800 - val_f1_m: 0.8286 - val_precision_m: 0.9501 - val_recall_m: 0.7367 - val_tp_m: 89.4267 - val_fp_m: 4.7733 - val_tn_m: 117.3600 - val_fn_m: 32.7067\n",
      "\n",
      "Epoch 00076: loss did not improve\n",
      "epoch time measured: 21.21005916595459\n",
      "Epoch 77/250\n",
      "epoch time start: 1578301535.049847\n",
      " - 21s - loss: 5.9317e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4128 - val_acc: 0.8800 - val_f1_m: 0.8303 - val_precision_m: 0.9484 - val_recall_m: 0.7400 - val_tp_m: 89.8533 - val_fp_m: 4.9867 - val_tn_m: 117.1467 - val_fn_m: 32.2800\n",
      "\n",
      "Epoch 00077: loss did not improve\n",
      "epoch time measured: 21.201987981796265\n",
      "Epoch 78/250\n",
      "epoch time start: 1578301556.2519507\n",
      " - 21s - loss: 4.8913e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4128 - val_acc: 0.8783 - val_f1_m: 0.8285 - val_precision_m: 0.9461 - val_recall_m: 0.7383 - val_tp_m: 89.6400 - val_fp_m: 5.2000 - val_tn_m: 116.9333 - val_fn_m: 32.4933\n",
      "\n",
      "Epoch 00078: loss improved from 0.00049 to 0.00049, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.211437702178955\n",
      "Epoch 79/250\n",
      "epoch time start: 1578301577.4636645\n",
      " - 21s - loss: 6.6592e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4110 - val_acc: 0.8800 - val_f1_m: 0.8288 - val_precision_m: 0.9440 - val_recall_m: 0.7400 - val_tp_m: 89.8533 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 32.2800\n",
      "\n",
      "Epoch 00079: loss did not improve\n",
      "epoch time measured: 21.169268131256104\n",
      "Epoch 80/250\n",
      "epoch time start: 1578301598.6330361\n",
      " - 21s - loss: 4.4165e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4098 - val_acc: 0.8783 - val_f1_m: 0.8247 - val_precision_m: 0.9390 - val_recall_m: 0.7367 - val_tp_m: 89.4267 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 32.7067\n",
      "\n",
      "Epoch 00080: loss improved from 0.00049 to 0.00044, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.19263219833374\n",
      "Epoch 81/250\n",
      "epoch time start: 1578301619.8258207\n",
      " - 21s - loss: 7.5891e-04 - acc: 1.0000 - f1_m: 0.9983 - precision_m: 1.0000 - recall_m: 0.9967 - tp_m: 121.8400 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.2933 - val_loss: 0.4149 - val_acc: 0.8817 - val_f1_m: 0.8238 - val_precision_m: 0.9408 - val_recall_m: 0.7350 - val_tp_m: 89.2133 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 32.9200\n",
      "\n",
      "Epoch 00081: loss did not improve\n",
      "epoch time measured: 21.147827863693237\n",
      "Epoch 82/250\n",
      "epoch time start: 1578301640.9737694\n",
      " - 21s - loss: 4.6578e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4282 - val_acc: 0.8783 - val_f1_m: 0.8249 - val_precision_m: 0.9436 - val_recall_m: 0.7350 - val_tp_m: 89.2800 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 32.8533\n",
      "\n",
      "Epoch 00082: loss did not improve\n",
      "epoch time measured: 21.11875867843628\n",
      "Epoch 83/250\n",
      "epoch time start: 1578301662.092633\n",
      " - 21s - loss: 4.2057e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4260 - val_acc: 0.8833 - val_f1_m: 0.8286 - val_precision_m: 0.9443 - val_recall_m: 0.7400 - val_tp_m: 89.9200 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 32.2133\n",
      "\n",
      "Epoch 00083: loss improved from 0.00044 to 0.00042, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.209376573562622\n",
      "Epoch 84/250\n",
      "epoch time start: 1578301683.302118\n",
      " - 21s - loss: 4.1865e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4196 - val_acc: 0.8817 - val_f1_m: 0.8270 - val_precision_m: 0.9421 - val_recall_m: 0.7383 - val_tp_m: 89.7067 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 32.4267\n",
      "\n",
      "Epoch 00084: loss improved from 0.00042 to 0.00042, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.18188977241516\n",
      "Epoch 85/250\n",
      "epoch time start: 1578301704.484303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 21s - loss: 5.3959e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4232 - val_acc: 0.8817 - val_f1_m: 0.8291 - val_precision_m: 0.9422 - val_recall_m: 0.7417 - val_tp_m: 90.1333 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 32.0000\n",
      "\n",
      "Epoch 00085: loss did not improve\n",
      "epoch time measured: 21.201130151748657\n",
      "Epoch 86/250\n",
      "epoch time start: 1578301725.685573\n",
      " - 21s - loss: 4.5483e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4241 - val_acc: 0.8817 - val_f1_m: 0.8291 - val_precision_m: 0.9422 - val_recall_m: 0.7417 - val_tp_m: 90.1333 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 32.0000\n",
      "\n",
      "Epoch 00086: loss did not improve\n",
      "epoch time measured: 21.07830810546875\n",
      "Epoch 87/250\n",
      "epoch time start: 1578301746.7639918\n",
      " - 21s - loss: 4.1948e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4249 - val_acc: 0.8833 - val_f1_m: 0.8283 - val_precision_m: 0.9399 - val_recall_m: 0.7417 - val_tp_m: 90.0667 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 32.0667\n",
      "\n",
      "Epoch 00087: loss did not improve\n",
      "epoch time measured: 21.197380781173706\n",
      "Epoch 88/250\n",
      "epoch time start: 1578301767.9615102\n",
      " - 21s - loss: 4.3245e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4241 - val_acc: 0.8817 - val_f1_m: 0.8298 - val_precision_m: 0.9437 - val_recall_m: 0.7417 - val_tp_m: 90.0667 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 32.0667\n",
      "\n",
      "Epoch 00088: loss did not improve\n",
      "epoch time measured: 21.06662368774414\n",
      "Epoch 89/250\n",
      "epoch time start: 1578301789.028238\n",
      " - 21s - loss: 5.9803e-04 - acc: 1.0000 - f1_m: 0.9992 - precision_m: 1.0000 - recall_m: 0.9983 - tp_m: 121.9867 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.1467 - val_loss: 0.4246 - val_acc: 0.8800 - val_f1_m: 0.8285 - val_precision_m: 0.9436 - val_recall_m: 0.7400 - val_tp_m: 89.8533 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 32.2800\n",
      "\n",
      "Epoch 00089: loss did not improve\n",
      "epoch time measured: 21.206426858901978\n",
      "Epoch 90/250\n",
      "epoch time start: 1578301810.234787\n",
      " - 21s - loss: 3.9498e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4224 - val_acc: 0.8767 - val_f1_m: 0.8320 - val_precision_m: 0.9441 - val_recall_m: 0.7450 - val_tp_m: 90.4933 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 31.6400\n",
      "\n",
      "Epoch 00090: loss improved from 0.00042 to 0.00039, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.242260932922363\n",
      "Epoch 91/250\n",
      "epoch time start: 1578301831.477294\n",
      " - 21s - loss: 4.0427e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4256 - val_acc: 0.8783 - val_f1_m: 0.8298 - val_precision_m: 0.9437 - val_recall_m: 0.7417 - val_tp_m: 90.0667 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 32.0667\n",
      "\n",
      "Epoch 00091: loss did not improve\n",
      "epoch time measured: 21.168448209762573\n",
      "Epoch 92/250\n",
      "epoch time start: 1578301852.6458468\n",
      " - 21s - loss: 4.9078e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4316 - val_acc: 0.8783 - val_f1_m: 0.8296 - val_precision_m: 0.9437 - val_recall_m: 0.7417 - val_tp_m: 90.0667 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 32.0667\n",
      "\n",
      "Epoch 00092: loss did not improve\n",
      "epoch time measured: 21.35319185256958\n",
      "Epoch 93/250\n",
      "epoch time start: 1578301873.9991462\n",
      " - 21s - loss: 5.3314e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4331 - val_acc: 0.8800 - val_f1_m: 0.8318 - val_precision_m: 0.9440 - val_recall_m: 0.7450 - val_tp_m: 90.4267 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 31.7067\n",
      "\n",
      "Epoch 00093: loss did not improve\n",
      "epoch time measured: 21.1882803440094\n",
      "Epoch 94/250\n",
      "epoch time start: 1578301895.1875398\n",
      " - 21s - loss: 5.6308e-04 - acc: 1.0000 - f1_m: 0.9983 - precision_m: 1.0000 - recall_m: 0.9967 - tp_m: 121.7067 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.4267 - val_loss: 0.4316 - val_acc: 0.8800 - val_f1_m: 0.8323 - val_precision_m: 0.9423 - val_recall_m: 0.7467 - val_tp_m: 90.6400 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.4933\n",
      "\n",
      "Epoch 00094: loss did not improve\n",
      "epoch time measured: 21.41064763069153\n",
      "Epoch 95/250\n",
      "epoch time start: 1578301916.5984182\n",
      " - 21s - loss: 3.6232e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4323 - val_acc: 0.8800 - val_f1_m: 0.8317 - val_precision_m: 0.9439 - val_recall_m: 0.7450 - val_tp_m: 90.4267 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 31.7067\n",
      "\n",
      "Epoch 00095: loss improved from 0.00039 to 0.00036, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.221419095993042\n",
      "Epoch 96/250\n",
      "epoch time start: 1578301937.8200567\n",
      " - 21s - loss: 3.6224e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4315 - val_acc: 0.8800 - val_f1_m: 0.8320 - val_precision_m: 0.9418 - val_recall_m: 0.7467 - val_tp_m: 90.6400 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.4933\n",
      "\n",
      "Epoch 00096: loss improved from 0.00036 to 0.00036, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.310296535491943\n",
      "Epoch 97/250\n",
      "epoch time start: 1578301959.1305833\n",
      " - 21s - loss: 4.4525e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4313 - val_acc: 0.8733 - val_f1_m: 0.8311 - val_precision_m: 0.9418 - val_recall_m: 0.7450 - val_tp_m: 90.4267 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.7067\n",
      "\n",
      "Epoch 00097: loss did not improve\n",
      "epoch time measured: 21.155972003936768\n",
      "Epoch 98/250\n",
      "epoch time start: 1578301980.2866824\n",
      " - 21s - loss: 3.2609e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4315 - val_acc: 0.8733 - val_f1_m: 0.8303 - val_precision_m: 0.9397 - val_recall_m: 0.7450 - val_tp_m: 90.4267 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 31.7067\n",
      "\n",
      "Epoch 00098: loss improved from 0.00036 to 0.00033, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.241901874542236\n",
      "Epoch 99/250\n",
      "epoch time start: 1578302001.5288715\n",
      " - 21s - loss: 3.8805e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4349 - val_acc: 0.8800 - val_f1_m: 0.8259 - val_precision_m: 0.9370 - val_recall_m: 0.7400 - val_tp_m: 89.7867 - val_fp_m: 6.0533 - val_tn_m: 116.0800 - val_fn_m: 32.3467\n",
      "\n",
      "Epoch 00099: loss did not improve\n",
      "epoch time measured: 21.238701105117798\n",
      "Epoch 100/250\n",
      "epoch time start: 1578302022.7676811\n",
      " - 21s - loss: 3.2463e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4398 - val_acc: 0.8833 - val_f1_m: 0.8262 - val_precision_m: 0.9410 - val_recall_m: 0.7383 - val_tp_m: 89.5733 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 32.5600\n",
      "\n",
      "Epoch 00100: loss improved from 0.00033 to 0.00032, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.462457180023193\n",
      "Epoch 101/250\n",
      "epoch time start: 1578302044.2305295\n",
      " - 21s - loss: 3.4565e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4388 - val_acc: 0.8850 - val_f1_m: 0.8274 - val_precision_m: 0.9413 - val_recall_m: 0.7400 - val_tp_m: 89.7867 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 32.3467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00101: loss did not improve\n",
      "epoch time measured: 21.19627833366394\n",
      "Epoch 102/250\n",
      "epoch time start: 1578302065.4269109\n",
      " - 21s - loss: 4.4215e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4320 - val_acc: 0.8767 - val_f1_m: 0.8299 - val_precision_m: 0.9417 - val_recall_m: 0.7433 - val_tp_m: 90.2800 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.8533\n",
      "\n",
      "Epoch 00102: loss did not improve\n",
      "epoch time measured: 21.10729146003723\n",
      "Epoch 103/250\n",
      "epoch time start: 1578302086.5343337\n",
      " - 22s - loss: 2.8701e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4300 - val_acc: 0.8783 - val_f1_m: 0.8301 - val_precision_m: 0.9419 - val_recall_m: 0.7433 - val_tp_m: 90.2800 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.8533\n",
      "\n",
      "Epoch 00103: loss improved from 0.00032 to 0.00029, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.58410882949829\n",
      "Epoch 104/250\n",
      "epoch time start: 1578302108.1186657\n",
      " - 21s - loss: 3.0174e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4328 - val_acc: 0.8800 - val_f1_m: 0.8296 - val_precision_m: 0.9437 - val_recall_m: 0.7417 - val_tp_m: 90.0667 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 32.0667\n",
      "\n",
      "Epoch 00104: loss did not improve\n",
      "epoch time measured: 21.40674614906311\n",
      "Epoch 105/250\n",
      "epoch time start: 1578302129.5256224\n",
      " - 21s - loss: 5.3874e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4361 - val_acc: 0.8800 - val_f1_m: 0.8300 - val_precision_m: 0.9457 - val_recall_m: 0.7417 - val_tp_m: 90.0000 - val_fp_m: 5.2000 - val_tn_m: 116.9333 - val_fn_m: 32.1333\n",
      "\n",
      "Epoch 00105: loss did not improve\n",
      "epoch time measured: 21.220460176467896\n",
      "Epoch 106/250\n",
      "epoch time start: 1578302150.7461967\n",
      " - 21s - loss: 2.9599e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4384 - val_acc: 0.8800 - val_f1_m: 0.8326 - val_precision_m: 0.9462 - val_recall_m: 0.7450 - val_tp_m: 90.4267 - val_fp_m: 5.2000 - val_tn_m: 116.9333 - val_fn_m: 31.7067\n",
      "\n",
      "Epoch 00106: loss did not improve\n",
      "epoch time measured: 21.04041028022766\n",
      "Epoch 107/250\n",
      "epoch time start: 1578302171.7867076\n",
      " - 21s - loss: 4.1280e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4401 - val_acc: 0.8783 - val_f1_m: 0.8351 - val_precision_m: 0.9466 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 5.2000 - val_tn_m: 116.9333 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00107: loss did not improve\n",
      "epoch time measured: 21.277509927749634\n",
      "Epoch 108/250\n",
      "epoch time start: 1578302193.0643718\n",
      " - 21s - loss: 3.3267e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4477 - val_acc: 0.8767 - val_f1_m: 0.8360 - val_precision_m: 0.9407 - val_recall_m: 0.7533 - val_tp_m: 91.4933 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 30.6400\n",
      "\n",
      "Epoch 00108: loss did not improve\n",
      "epoch time measured: 21.2307710647583\n",
      "Epoch 109/250\n",
      "epoch time start: 1578302214.2952695\n",
      " - 21s - loss: 3.8577e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4513 - val_acc: 0.8767 - val_f1_m: 0.8368 - val_precision_m: 0.9428 - val_recall_m: 0.7533 - val_tp_m: 91.4933 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 30.6400\n",
      "\n",
      "Epoch 00109: loss did not improve\n",
      "epoch time measured: 21.330260276794434\n",
      "Epoch 110/250\n",
      "epoch time start: 1578302235.6256385\n",
      " - 22s - loss: 2.8087e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4483 - val_acc: 0.8783 - val_f1_m: 0.8349 - val_precision_m: 0.9405 - val_recall_m: 0.7517 - val_tp_m: 91.2800 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 30.8533\n",
      "\n",
      "Epoch 00110: loss improved from 0.00029 to 0.00028, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.581366300582886\n",
      "Epoch 111/250\n",
      "epoch time start: 1578302257.2071338\n",
      " - 21s - loss: 2.6327e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4442 - val_acc: 0.8783 - val_f1_m: 0.8333 - val_precision_m: 0.9421 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00111: loss improved from 0.00028 to 0.00026, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.111250638961792\n",
      "Epoch 112/250\n",
      "epoch time start: 1578302278.318598\n",
      " - 21s - loss: 2.4460e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4448 - val_acc: 0.8750 - val_f1_m: 0.8310 - val_precision_m: 0.9418 - val_recall_m: 0.7450 - val_tp_m: 90.4267 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.7067\n",
      "\n",
      "Epoch 00112: loss improved from 0.00026 to 0.00024, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.516247749328613\n",
      "Epoch 113/250\n",
      "epoch time start: 1578302299.8349648\n",
      " - 21s - loss: 3.5163e-04 - acc: 1.0000 - f1_m: 0.9992 - precision_m: 1.0000 - recall_m: 0.9983 - tp_m: 121.9200 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.2133 - val_loss: 0.4482 - val_acc: 0.8833 - val_f1_m: 0.8285 - val_precision_m: 0.9410 - val_recall_m: 0.7417 - val_tp_m: 90.0000 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 32.1333\n",
      "\n",
      "Epoch 00113: loss did not improve\n",
      "epoch time measured: 21.334972620010376\n",
      "Epoch 114/250\n",
      "epoch time start: 1578302321.1700482\n",
      " - 21s - loss: 2.6329e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4502 - val_acc: 0.8850 - val_f1_m: 0.8217 - val_precision_m: 0.9379 - val_recall_m: 0.7333 - val_tp_m: 88.9333 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 33.2000\n",
      "\n",
      "Epoch 00114: loss did not improve\n",
      "epoch time measured: 21.17539358139038\n",
      "Epoch 115/250\n",
      "epoch time start: 1578302342.3455768\n",
      " - 21s - loss: 2.4032e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4479 - val_acc: 0.8833 - val_f1_m: 0.8204 - val_precision_m: 0.9377 - val_recall_m: 0.7317 - val_tp_m: 88.7200 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 33.4133\n",
      "\n",
      "Epoch 00115: loss improved from 0.00024 to 0.00024, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.275983095169067\n",
      "Epoch 116/250\n",
      "epoch time start: 1578302363.6218064\n",
      " - 21s - loss: 2.9468e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4508 - val_acc: 0.8833 - val_f1_m: 0.8217 - val_precision_m: 0.9379 - val_recall_m: 0.7333 - val_tp_m: 88.9333 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 33.2000\n",
      "\n",
      "Epoch 00116: loss did not improve\n",
      "epoch time measured: 21.207808017730713\n",
      "Epoch 117/250\n",
      "epoch time start: 1578302384.8297272\n",
      " - 21s - loss: 2.8742e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4582 - val_acc: 0.8800 - val_f1_m: 0.8269 - val_precision_m: 0.9407 - val_recall_m: 0.7400 - val_tp_m: 89.7867 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 32.3467\n",
      "\n",
      "Epoch 00117: loss did not improve\n",
      "epoch time measured: 21.130242347717285\n",
      "Epoch 118/250\n",
      "epoch time start: 1578302405.9600894\n",
      " - 21s - loss: 2.2078e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4541 - val_acc: 0.8800 - val_f1_m: 0.8283 - val_precision_m: 0.9411 - val_recall_m: 0.7417 - val_tp_m: 90.0000 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 32.1333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00118: loss improved from 0.00024 to 0.00022, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.363289833068848\n",
      "Epoch 119/250\n",
      "epoch time start: 1578302427.3235881\n",
      " - 21s - loss: 2.6706e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4481 - val_acc: 0.8800 - val_f1_m: 0.8266 - val_precision_m: 0.9389 - val_recall_m: 0.7400 - val_tp_m: 89.7867 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 32.3467\n",
      "\n",
      "Epoch 00119: loss did not improve\n",
      "epoch time measured: 21.242708444595337\n",
      "Epoch 120/250\n",
      "epoch time start: 1578302448.5664227\n",
      " - 21s - loss: 2.7963e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4471 - val_acc: 0.8800 - val_f1_m: 0.8284 - val_precision_m: 0.9412 - val_recall_m: 0.7417 - val_tp_m: 90.0000 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 32.1333\n",
      "\n",
      "Epoch 00120: loss did not improve\n",
      "epoch time measured: 21.28249716758728\n",
      "Epoch 121/250\n",
      "epoch time start: 1578302469.8490243\n",
      " - 21s - loss: 2.5960e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4493 - val_acc: 0.8833 - val_f1_m: 0.8280 - val_precision_m: 0.9431 - val_recall_m: 0.7400 - val_tp_m: 89.7867 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 32.3467\n",
      "\n",
      "Epoch 00121: loss did not improve\n",
      "epoch time measured: 21.2475848197937\n",
      "Epoch 122/250\n",
      "epoch time start: 1578302491.096718\n",
      " - 21s - loss: 3.4430e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4515 - val_acc: 0.8833 - val_f1_m: 0.8291 - val_precision_m: 0.9431 - val_recall_m: 0.7417 - val_tp_m: 90.0000 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 32.1333\n",
      "\n",
      "Epoch 00122: loss did not improve\n",
      "epoch time measured: 21.280688285827637\n",
      "Epoch 123/250\n",
      "epoch time start: 1578302512.3775673\n",
      " - 21s - loss: 2.2741e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4502 - val_acc: 0.8817 - val_f1_m: 0.8304 - val_precision_m: 0.9435 - val_recall_m: 0.7433 - val_tp_m: 90.2133 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 31.9200\n",
      "\n",
      "Epoch 00123: loss did not improve\n",
      "epoch time measured: 21.197656631469727\n",
      "Epoch 124/250\n",
      "epoch time start: 1578302533.575685\n",
      " - 21s - loss: 2.5720e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4539 - val_acc: 0.8833 - val_f1_m: 0.8316 - val_precision_m: 0.9438 - val_recall_m: 0.7450 - val_tp_m: 90.4267 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 31.7067\n",
      "\n",
      "Epoch 00124: loss did not improve\n",
      "epoch time measured: 21.050175428390503\n",
      "Epoch 125/250\n",
      "epoch time start: 1578302554.6260805\n",
      " - 21s - loss: 2.5404e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4594 - val_acc: 0.8850 - val_f1_m: 0.8331 - val_precision_m: 0.9422 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00125: loss did not improve\n",
      "epoch time measured: 21.2281973361969\n",
      "Epoch 126/250\n",
      "epoch time start: 1578302575.854381\n",
      " - 21s - loss: 2.2466e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4732 - val_acc: 0.8783 - val_f1_m: 0.8305 - val_precision_m: 0.9416 - val_recall_m: 0.7450 - val_tp_m: 90.4267 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.7067\n",
      "\n",
      "Epoch 00126: loss did not improve\n",
      "epoch time measured: 21.105292081832886\n",
      "Epoch 127/250\n",
      "epoch time start: 1578302596.9598126\n",
      " - 21s - loss: 1.9429e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4708 - val_acc: 0.8817 - val_f1_m: 0.8303 - val_precision_m: 0.9438 - val_recall_m: 0.7433 - val_tp_m: 90.2133 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 31.9200\n",
      "\n",
      "Epoch 00127: loss improved from 0.00022 to 0.00019, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.157532453536987\n",
      "Epoch 128/250\n",
      "epoch time start: 1578302618.1176326\n",
      " - 21s - loss: 2.2391e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4629 - val_acc: 0.8800 - val_f1_m: 0.8347 - val_precision_m: 0.9404 - val_recall_m: 0.7517 - val_tp_m: 91.2800 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 30.8533\n",
      "\n",
      "Epoch 00128: loss did not improve\n",
      "epoch time measured: 21.058889865875244\n",
      "Epoch 129/250\n",
      "epoch time start: 1578302639.1766431\n",
      " - 21s - loss: 3.2211e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4623 - val_acc: 0.8783 - val_f1_m: 0.8357 - val_precision_m: 0.9404 - val_recall_m: 0.7533 - val_tp_m: 91.4933 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 30.6400\n",
      "\n",
      "Epoch 00129: loss did not improve\n",
      "epoch time measured: 21.195637941360474\n",
      "Epoch 130/250\n",
      "epoch time start: 1578302660.3723977\n",
      " - 21s - loss: 2.2183e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4631 - val_acc: 0.8783 - val_f1_m: 0.8333 - val_precision_m: 0.9400 - val_recall_m: 0.7500 - val_tp_m: 91.0667 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 31.0667\n",
      "\n",
      "Epoch 00130: loss did not improve\n",
      "epoch time measured: 21.18004274368286\n",
      "Epoch 131/250\n",
      "epoch time start: 1578302681.552547\n",
      " - 22s - loss: 2.4195e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4610 - val_acc: 0.8800 - val_f1_m: 0.8309 - val_precision_m: 0.9396 - val_recall_m: 0.7467 - val_tp_m: 90.6400 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 31.4933\n",
      "\n",
      "Epoch 00131: loss did not improve\n",
      "epoch time measured: 21.530908584594727\n",
      "Epoch 132/250\n",
      "epoch time start: 1578302703.0835598\n",
      " - 21s - loss: 1.8458e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4589 - val_acc: 0.8833 - val_f1_m: 0.8333 - val_precision_m: 0.9400 - val_recall_m: 0.7500 - val_tp_m: 91.0667 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 31.0667\n",
      "\n",
      "Epoch 00132: loss improved from 0.00019 to 0.00018, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.241372108459473\n",
      "Epoch 133/250\n",
      "epoch time start: 1578302724.3252084\n",
      " - 22s - loss: 1.7601e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4595 - val_acc: 0.8833 - val_f1_m: 0.8345 - val_precision_m: 0.9402 - val_recall_m: 0.7517 - val_tp_m: 91.2800 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 30.8533\n",
      "\n",
      "Epoch 00133: loss improved from 0.00018 to 0.00018, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.615607023239136\n",
      "Epoch 134/250\n",
      "epoch time start: 1578302745.9412158\n",
      " - 21s - loss: 2.0375e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4627 - val_acc: 0.8833 - val_f1_m: 0.8344 - val_precision_m: 0.9402 - val_recall_m: 0.7517 - val_tp_m: 91.2800 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 30.8533\n",
      "\n",
      "Epoch 00134: loss did not improve\n",
      "epoch time measured: 21.34020447731018\n",
      "Epoch 135/250\n",
      "epoch time start: 1578302767.2815685\n",
      " - 21s - loss: 2.6022e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4653 - val_acc: 0.8817 - val_f1_m: 0.8356 - val_precision_m: 0.9404 - val_recall_m: 0.7533 - val_tp_m: 91.4933 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 30.6400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00135: loss did not improve\n",
      "epoch time measured: 21.242324113845825\n",
      "Epoch 136/250\n",
      "epoch time start: 1578302788.524023\n",
      " - 21s - loss: 1.6995e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4692 - val_acc: 0.8800 - val_f1_m: 0.8357 - val_precision_m: 0.9404 - val_recall_m: 0.7533 - val_tp_m: 91.4933 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 30.6400\n",
      "\n",
      "Epoch 00136: loss improved from 0.00018 to 0.00017, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.100452661514282\n",
      "Epoch 137/250\n",
      "epoch time start: 1578302809.6246014\n",
      " - 21s - loss: 2.5574e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4694 - val_acc: 0.8783 - val_f1_m: 0.8347 - val_precision_m: 0.9404 - val_recall_m: 0.7517 - val_tp_m: 91.2800 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 30.8533\n",
      "\n",
      "Epoch 00137: loss did not improve\n",
      "epoch time measured: 21.18431568145752\n",
      "Epoch 138/250\n",
      "epoch time start: 1578302830.8090403\n",
      " - 21s - loss: 2.0766e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4689 - val_acc: 0.8817 - val_f1_m: 0.8360 - val_precision_m: 0.9407 - val_recall_m: 0.7533 - val_tp_m: 91.4933 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 30.6400\n",
      "\n",
      "Epoch 00138: loss did not improve\n",
      "epoch time measured: 21.128185272216797\n",
      "Epoch 139/250\n",
      "epoch time start: 1578302851.9373655\n",
      " - 21s - loss: 2.0824e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4712 - val_acc: 0.8783 - val_f1_m: 0.8353 - val_precision_m: 0.9424 - val_recall_m: 0.7517 - val_tp_m: 91.2800 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 30.8533\n",
      "\n",
      "Epoch 00139: loss did not improve\n",
      "epoch time measured: 21.21216058731079\n",
      "Epoch 140/250\n",
      "epoch time start: 1578302873.149663\n",
      " - 21s - loss: 1.6012e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4738 - val_acc: 0.8783 - val_f1_m: 0.8337 - val_precision_m: 0.9443 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00140: loss improved from 0.00017 to 0.00016, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.24527931213379\n",
      "Epoch 141/250\n",
      "epoch time start: 1578302894.3951194\n",
      " - 21s - loss: 1.8652e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4687 - val_acc: 0.8817 - val_f1_m: 0.8345 - val_precision_m: 0.9402 - val_recall_m: 0.7517 - val_tp_m: 91.2800 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 30.8533\n",
      "\n",
      "Epoch 00141: loss did not improve\n",
      "epoch time measured: 21.255000591278076\n",
      "Epoch 142/250\n",
      "epoch time start: 1578302915.6502492\n",
      " - 21s - loss: 1.7737e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4642 - val_acc: 0.8817 - val_f1_m: 0.8358 - val_precision_m: 0.9405 - val_recall_m: 0.7533 - val_tp_m: 91.4933 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 30.6400\n",
      "\n",
      "Epoch 00142: loss did not improve\n",
      "epoch time measured: 21.201777935028076\n",
      "Epoch 143/250\n",
      "epoch time start: 1578302936.8521338\n",
      " - 21s - loss: 1.7521e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4622 - val_acc: 0.8817 - val_f1_m: 0.8323 - val_precision_m: 0.9400 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00143: loss did not improve\n",
      "epoch time measured: 21.229275941848755\n",
      "Epoch 144/250\n",
      "epoch time start: 1578302958.0815814\n",
      " - 21s - loss: 1.7710e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4614 - val_acc: 0.8800 - val_f1_m: 0.8315 - val_precision_m: 0.9378 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 6.0533 - val_tn_m: 116.0800 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00144: loss did not improve\n",
      "epoch time measured: 21.207741260528564\n",
      "Epoch 145/250\n",
      "epoch time start: 1578302979.2894294\n",
      " - 22s - loss: 1.7111e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4656 - val_acc: 0.8867 - val_f1_m: 0.8312 - val_precision_m: 0.9398 - val_recall_m: 0.7467 - val_tp_m: 90.6400 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 31.4933\n",
      "\n",
      "Epoch 00145: loss did not improve\n",
      "epoch time measured: 21.521755695343018\n",
      "Epoch 146/250\n",
      "epoch time start: 1578303000.8113194\n",
      " - 21s - loss: 2.9099e-04 - acc: 1.0000 - f1_m: 0.9992 - precision_m: 1.0000 - recall_m: 0.9983 - tp_m: 121.9867 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.1467 - val_loss: 0.4712 - val_acc: 0.8850 - val_f1_m: 0.8322 - val_precision_m: 0.9399 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00146: loss did not improve\n",
      "epoch time measured: 21.24207901954651\n",
      "Epoch 147/250\n",
      "epoch time start: 1578303022.053541\n",
      " - 21s - loss: 2.6325e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4770 - val_acc: 0.8833 - val_f1_m: 0.8311 - val_precision_m: 0.9397 - val_recall_m: 0.7467 - val_tp_m: 90.6400 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 31.4933\n",
      "\n",
      "Epoch 00147: loss did not improve\n",
      "epoch time measured: 20.979363441467285\n",
      "Epoch 148/250\n",
      "epoch time start: 1578303043.0333798\n",
      " - 21s - loss: 1.7453e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4738 - val_acc: 0.8817 - val_f1_m: 0.8319 - val_precision_m: 0.9420 - val_recall_m: 0.7467 - val_tp_m: 90.6400 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.4933\n",
      "\n",
      "Epoch 00148: loss did not improve\n",
      "epoch time measured: 21.112345218658447\n",
      "Epoch 149/250\n",
      "epoch time start: 1578303064.1458366\n",
      " - 21s - loss: 2.2859e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4699 - val_acc: 0.8800 - val_f1_m: 0.8332 - val_precision_m: 0.9420 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00149: loss did not improve\n",
      "epoch time measured: 21.310887813568115\n",
      "Epoch 150/250\n",
      "epoch time start: 1578303085.4568527\n",
      " - 21s - loss: 2.3668e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4623 - val_acc: 0.8767 - val_f1_m: 0.8300 - val_precision_m: 0.9394 - val_recall_m: 0.7450 - val_tp_m: 90.4267 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 31.7067\n",
      "\n",
      "Epoch 00150: loss did not improve\n",
      "epoch time measured: 21.189703464508057\n",
      "Epoch 151/250\n",
      "epoch time start: 1578303106.6466594\n",
      " - 21s - loss: 1.6723e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4648 - val_acc: 0.8850 - val_f1_m: 0.8323 - val_precision_m: 0.9397 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00151: loss did not improve\n",
      "epoch time measured: 20.963814973831177\n",
      "Epoch 152/250\n",
      "epoch time start: 1578303127.6106176\n",
      " - 21s - loss: 1.9877e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4674 - val_acc: 0.8833 - val_f1_m: 0.8307 - val_precision_m: 0.9414 - val_recall_m: 0.7450 - val_tp_m: 90.4267 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.7067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00152: loss did not improve\n",
      "epoch time measured: 21.189390182495117\n",
      "Epoch 153/250\n",
      "epoch time start: 1578303148.8001213\n",
      " - 21s - loss: 1.6796e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4677 - val_acc: 0.8833 - val_f1_m: 0.8295 - val_precision_m: 0.9412 - val_recall_m: 0.7433 - val_tp_m: 90.2133 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.9200\n",
      "\n",
      "Epoch 00153: loss did not improve\n",
      "epoch time measured: 21.24040174484253\n",
      "Epoch 154/250\n",
      "epoch time start: 1578303170.0406153\n",
      " - 21s - loss: 1.6053e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4691 - val_acc: 0.8833 - val_f1_m: 0.8295 - val_precision_m: 0.9412 - val_recall_m: 0.7433 - val_tp_m: 90.2133 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.9200\n",
      "\n",
      "Epoch 00154: loss did not improve\n",
      "epoch time measured: 21.2134747505188\n",
      "Epoch 155/250\n",
      "epoch time start: 1578303191.2544303\n",
      " - 21s - loss: 2.0676e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4674 - val_acc: 0.8817 - val_f1_m: 0.8330 - val_precision_m: 0.9418 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00155: loss did not improve\n",
      "epoch time measured: 21.232876539230347\n",
      "Epoch 156/250\n",
      "epoch time start: 1578303212.487441\n",
      " - 21s - loss: 1.6350e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4649 - val_acc: 0.8817 - val_f1_m: 0.8334 - val_precision_m: 0.9421 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00156: loss did not improve\n",
      "epoch time measured: 21.01225733757019\n",
      "Epoch 157/250\n",
      "epoch time start: 1578303233.4998093\n",
      " - 21s - loss: 1.8963e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4692 - val_acc: 0.8800 - val_f1_m: 0.8312 - val_precision_m: 0.9398 - val_recall_m: 0.7467 - val_tp_m: 90.6400 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 31.4933\n",
      "\n",
      "Epoch 00157: loss did not improve\n",
      "epoch time measured: 20.935461282730103\n",
      "Epoch 158/250\n",
      "epoch time start: 1578303254.4370348\n",
      " - 21s - loss: 1.2924e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4763 - val_acc: 0.8800 - val_f1_m: 0.8310 - val_precision_m: 0.9396 - val_recall_m: 0.7467 - val_tp_m: 90.6400 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 31.4933\n",
      "\n",
      "Epoch 00158: loss improved from 0.00016 to 0.00013, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.307812213897705\n",
      "Epoch 159/250\n",
      "epoch time start: 1578303275.7450552\n",
      " - 21s - loss: 1.5863e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4752 - val_acc: 0.8817 - val_f1_m: 0.8310 - val_precision_m: 0.9396 - val_recall_m: 0.7467 - val_tp_m: 90.6400 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 31.4933\n",
      "\n",
      "Epoch 00159: loss did not improve\n",
      "epoch time measured: 21.16514015197754\n",
      "Epoch 160/250\n",
      "epoch time start: 1578303296.9103405\n",
      " - 22s - loss: 1.9555e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4699 - val_acc: 0.8817 - val_f1_m: 0.8320 - val_precision_m: 0.9418 - val_recall_m: 0.7467 - val_tp_m: 90.6400 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.4933\n",
      "\n",
      "Epoch 00160: loss did not improve\n",
      "epoch time measured: 21.748071432113647\n",
      "Epoch 161/250\n",
      "epoch time start: 1578303318.658519\n",
      " - 22s - loss: 1.3262e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4682 - val_acc: 0.8817 - val_f1_m: 0.8345 - val_precision_m: 0.9423 - val_recall_m: 0.7500 - val_tp_m: 91.0667 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.0667\n",
      "\n",
      "Epoch 00161: loss did not improve\n",
      "epoch time measured: 21.980690717697144\n",
      "Epoch 162/250\n",
      "epoch time start: 1578303340.6393514\n",
      " - 21s - loss: 1.5700e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4706 - val_acc: 0.8800 - val_f1_m: 0.8345 - val_precision_m: 0.9423 - val_recall_m: 0.7500 - val_tp_m: 91.0667 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.0667\n",
      "\n",
      "Epoch 00162: loss did not improve\n",
      "epoch time measured: 21.470543384552002\n",
      "Epoch 163/250\n",
      "epoch time start: 1578303362.1103232\n",
      " - 21s - loss: 1.9763e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4804 - val_acc: 0.8800 - val_f1_m: 0.8308 - val_precision_m: 0.9417 - val_recall_m: 0.7450 - val_tp_m: 90.4267 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.7067\n",
      "\n",
      "Epoch 00163: loss did not improve\n",
      "epoch time measured: 21.29925537109375\n",
      "Epoch 164/250\n",
      "epoch time start: 1578303383.409687\n",
      " - 21s - loss: 1.4568e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4844 - val_acc: 0.8817 - val_f1_m: 0.8316 - val_precision_m: 0.9379 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 6.0533 - val_tn_m: 116.0800 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00164: loss did not improve\n",
      "epoch time measured: 21.24562907218933\n",
      "Epoch 165/250\n",
      "epoch time start: 1578303404.6554198\n",
      " - 21s - loss: 1.6907e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4757 - val_acc: 0.8783 - val_f1_m: 0.8343 - val_precision_m: 0.9423 - val_recall_m: 0.7500 - val_tp_m: 91.0667 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.0667\n",
      "\n",
      "Epoch 00165: loss did not improve\n",
      "epoch time measured: 21.30204153060913\n",
      "Epoch 166/250\n",
      "epoch time start: 1578303425.9575777\n",
      " - 21s - loss: 1.2634e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4704 - val_acc: 0.8800 - val_f1_m: 0.8354 - val_precision_m: 0.9425 - val_recall_m: 0.7517 - val_tp_m: 91.2800 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 30.8533\n",
      "\n",
      "Epoch 00166: loss improved from 0.00013 to 0.00013, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.113041162490845\n",
      "Epoch 167/250\n",
      "epoch time start: 1578303447.07083\n",
      " - 21s - loss: 1.4292e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4728 - val_acc: 0.8783 - val_f1_m: 0.8332 - val_precision_m: 0.9423 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00167: loss did not improve\n",
      "epoch time measured: 21.23532271385193\n",
      "Epoch 168/250\n",
      "epoch time start: 1578303468.306262\n",
      " - 21s - loss: 1.3420e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4752 - val_acc: 0.8783 - val_f1_m: 0.8329 - val_precision_m: 0.9443 - val_recall_m: 0.7467 - val_tp_m: 90.6400 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 31.4933\n",
      "\n",
      "Epoch 00168: loss did not improve\n",
      "epoch time measured: 21.27471113204956\n",
      "Epoch 169/250\n",
      "epoch time start: 1578303489.581066\n",
      " - 21s - loss: 1.4384e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4784 - val_acc: 0.8767 - val_f1_m: 0.8329 - val_precision_m: 0.9443 - val_recall_m: 0.7467 - val_tp_m: 90.6400 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 31.4933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00169: loss did not improve\n",
      "epoch time measured: 21.26387882232666\n",
      "Epoch 170/250\n",
      "epoch time start: 1578303510.845084\n",
      " - 21s - loss: 1.3962e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4811 - val_acc: 0.8800 - val_f1_m: 0.8329 - val_precision_m: 0.9443 - val_recall_m: 0.7467 - val_tp_m: 90.6400 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 31.4933\n",
      "\n",
      "Epoch 00170: loss did not improve\n",
      "epoch time measured: 21.209274768829346\n",
      "Epoch 171/250\n",
      "epoch time start: 1578303532.0544763\n",
      " - 21s - loss: 1.3115e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4804 - val_acc: 0.8783 - val_f1_m: 0.8339 - val_precision_m: 0.9444 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00171: loss did not improve\n",
      "epoch time measured: 21.232765913009644\n",
      "Epoch 172/250\n",
      "epoch time start: 1578303553.2873561\n",
      " - 21s - loss: 1.3241e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4776 - val_acc: 0.8767 - val_f1_m: 0.8329 - val_precision_m: 0.9443 - val_recall_m: 0.7467 - val_tp_m: 90.6400 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 31.4933\n",
      "\n",
      "Epoch 00172: loss did not improve\n",
      "epoch time measured: 21.276962518692017\n",
      "Epoch 173/250\n",
      "epoch time start: 1578303574.564456\n",
      " - 21s - loss: 1.5266e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4770 - val_acc: 0.8783 - val_f1_m: 0.8332 - val_precision_m: 0.9423 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00173: loss did not improve\n",
      "epoch time measured: 21.203335285186768\n",
      "Epoch 174/250\n",
      "epoch time start: 1578303595.7679281\n",
      " - 21s - loss: 1.1449e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4775 - val_acc: 0.8783 - val_f1_m: 0.8324 - val_precision_m: 0.9400 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00174: loss improved from 0.00013 to 0.00011, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.23345685005188\n",
      "Epoch 175/250\n",
      "epoch time start: 1578303617.001646\n",
      " - 21s - loss: 1.7823e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4754 - val_acc: 0.8767 - val_f1_m: 0.8331 - val_precision_m: 0.9419 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00175: loss did not improve\n",
      "epoch time measured: 21.067137002944946\n",
      "Epoch 176/250\n",
      "epoch time start: 1578303638.0688906\n",
      " - 21s - loss: 1.2804e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4746 - val_acc: 0.8817 - val_f1_m: 0.8403 - val_precision_m: 0.9434 - val_recall_m: 0.7583 - val_tp_m: 92.1333 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 30.0000\n",
      "\n",
      "Epoch 00176: loss did not improve\n",
      "epoch time measured: 21.496142625808716\n",
      "Epoch 177/250\n",
      "epoch time start: 1578303659.5651512\n",
      " - 21s - loss: 1.1372e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4777 - val_acc: 0.8833 - val_f1_m: 0.8422 - val_precision_m: 0.9456 - val_recall_m: 0.7600 - val_tp_m: 92.3467 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 29.7867\n",
      "\n",
      "Epoch 00177: loss improved from 0.00011 to 0.00011, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.22242045402527\n",
      "Epoch 178/250\n",
      "epoch time start: 1578303680.7878559\n",
      " - 21s - loss: 1.3856e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4802 - val_acc: 0.8817 - val_f1_m: 0.8379 - val_precision_m: 0.9433 - val_recall_m: 0.7550 - val_tp_m: 91.7067 - val_fp_m: 5.5600 - val_tn_m: 116.5733 - val_fn_m: 30.4267\n",
      "\n",
      "Epoch 00178: loss did not improve\n",
      "epoch time measured: 21.29241633415222\n",
      "Epoch 179/250\n",
      "epoch time start: 1578303702.0803745\n",
      " - 21s - loss: 1.3602e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4811 - val_acc: 0.8800 - val_f1_m: 0.8368 - val_precision_m: 0.9428 - val_recall_m: 0.7533 - val_tp_m: 91.4933 - val_fp_m: 5.5600 - val_tn_m: 116.5733 - val_fn_m: 30.6400\n",
      "\n",
      "Epoch 00179: loss did not improve\n",
      "epoch time measured: 21.164527893066406\n",
      "Epoch 180/250\n",
      "epoch time start: 1578303723.245084\n",
      " - 21s - loss: 1.2424e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4793 - val_acc: 0.8817 - val_f1_m: 0.8359 - val_precision_m: 0.9406 - val_recall_m: 0.7533 - val_tp_m: 91.4933 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 30.6400\n",
      "\n",
      "Epoch 00180: loss did not improve\n",
      "epoch time measured: 21.05656385421753\n",
      "Epoch 181/250\n",
      "epoch time start: 1578303744.3017685\n",
      " - 21s - loss: 1.2223e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4750 - val_acc: 0.8800 - val_f1_m: 0.8336 - val_precision_m: 0.9403 - val_recall_m: 0.7500 - val_tp_m: 91.0667 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 31.0667\n",
      "\n",
      "Epoch 00181: loss did not improve\n",
      "epoch time measured: 21.127188205718994\n",
      "Epoch 182/250\n",
      "epoch time start: 1578303765.4290764\n",
      " - 21s - loss: 1.4795e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4755 - val_acc: 0.8800 - val_f1_m: 0.8324 - val_precision_m: 0.9400 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00182: loss did not improve\n",
      "epoch time measured: 21.157220602035522\n",
      "Epoch 183/250\n",
      "epoch time start: 1578303786.5864043\n",
      " - 21s - loss: 1.0643e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4772 - val_acc: 0.8800 - val_f1_m: 0.8324 - val_precision_m: 0.9400 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00183: loss improved from 0.00011 to 0.00011, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.36212706565857\n",
      "Epoch 184/250\n",
      "epoch time start: 1578303807.9487627\n",
      " - 22s - loss: 1.5799e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4805 - val_acc: 0.8783 - val_f1_m: 0.8345 - val_precision_m: 0.9402 - val_recall_m: 0.7517 - val_tp_m: 91.2800 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 30.8533\n",
      "\n",
      "Epoch 00184: loss did not improve\n",
      "epoch time measured: 21.54821276664734\n",
      "Epoch 185/250\n",
      "epoch time start: 1578303829.4971008\n",
      " - 21s - loss: 1.3986e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4869 - val_acc: 0.8817 - val_f1_m: 0.8327 - val_precision_m: 0.9379 - val_recall_m: 0.7500 - val_tp_m: 91.0667 - val_fp_m: 6.0533 - val_tn_m: 116.0800 - val_fn_m: 31.0667\n",
      "\n",
      "Epoch 00185: loss did not improve\n",
      "epoch time measured: 21.211870431900024\n",
      "Epoch 186/250\n",
      "epoch time start: 1578303850.7090983\n",
      " - 21s - loss: 1.2170e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4925 - val_acc: 0.8850 - val_f1_m: 0.8330 - val_precision_m: 0.9362 - val_recall_m: 0.7517 - val_tp_m: 91.2800 - val_fp_m: 6.2000 - val_tn_m: 115.9333 - val_fn_m: 30.8533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00186: loss did not improve\n",
      "epoch time measured: 21.157817363739014\n",
      "Epoch 187/250\n",
      "epoch time start: 1578303871.8670244\n",
      " - 21s - loss: 1.4930e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4874 - val_acc: 0.8800 - val_f1_m: 0.8338 - val_precision_m: 0.9381 - val_recall_m: 0.7517 - val_tp_m: 91.2800 - val_fp_m: 6.0533 - val_tn_m: 116.0800 - val_fn_m: 30.8533\n",
      "\n",
      "Epoch 00187: loss did not improve\n",
      "epoch time measured: 21.03899097442627\n",
      "Epoch 188/250\n",
      "epoch time start: 1578303892.9062316\n",
      " - 21s - loss: 1.0194e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4827 - val_acc: 0.8767 - val_f1_m: 0.8346 - val_precision_m: 0.9403 - val_recall_m: 0.7517 - val_tp_m: 91.2800 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 30.8533\n",
      "\n",
      "Epoch 00188: loss improved from 0.00011 to 0.00010, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.353734493255615\n",
      "Epoch 189/250\n",
      "epoch time start: 1578303914.2600827\n",
      " - 21s - loss: 9.4507e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4836 - val_acc: 0.8783 - val_f1_m: 0.8327 - val_precision_m: 0.9380 - val_recall_m: 0.7500 - val_tp_m: 91.0667 - val_fp_m: 6.0533 - val_tn_m: 116.0800 - val_fn_m: 31.0667\n",
      "\n",
      "Epoch 00189: loss improved from 0.00010 to 0.00009, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.19243311882019\n",
      "Epoch 190/250\n",
      "epoch time start: 1578303935.4527793\n",
      " - 21s - loss: 1.0884e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4840 - val_acc: 0.8817 - val_f1_m: 0.8324 - val_precision_m: 0.9398 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00190: loss did not improve\n",
      "epoch time measured: 21.235801458358765\n",
      "Epoch 191/250\n",
      "epoch time start: 1578303956.6886826\n",
      " - 21s - loss: 1.5455e-04 - acc: 1.0000 - f1_m: 0.9992 - precision_m: 1.0000 - recall_m: 0.9983 - tp_m: 121.9867 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.1467 - val_loss: 0.4805 - val_acc: 0.8783 - val_f1_m: 0.8350 - val_precision_m: 0.9442 - val_recall_m: 0.7500 - val_tp_m: 91.0667 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 31.0667\n",
      "\n",
      "Epoch 00191: loss did not improve\n",
      "epoch time measured: 21.221665382385254\n",
      "Epoch 192/250\n",
      "epoch time start: 1578303977.9104748\n",
      " - 21s - loss: 1.1313e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4877 - val_acc: 0.8833 - val_f1_m: 0.8327 - val_precision_m: 0.9379 - val_recall_m: 0.7500 - val_tp_m: 91.0667 - val_fp_m: 6.0533 - val_tn_m: 116.0800 - val_fn_m: 31.0667\n",
      "\n",
      "Epoch 00192: loss did not improve\n",
      "epoch time measured: 21.332785606384277\n",
      "Epoch 193/250\n",
      "epoch time start: 1578303999.2433846\n",
      " - 21s - loss: 1.3958e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4968 - val_acc: 0.8850 - val_f1_m: 0.8317 - val_precision_m: 0.9358 - val_recall_m: 0.7500 - val_tp_m: 91.0667 - val_fp_m: 6.2667 - val_tn_m: 115.8667 - val_fn_m: 31.0667\n",
      "\n",
      "Epoch 00193: loss did not improve\n",
      "epoch time measured: 21.19337272644043\n",
      "Epoch 194/250\n",
      "epoch time start: 1578304020.4368687\n",
      " - 21s - loss: 1.1640e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4975 - val_acc: 0.8850 - val_f1_m: 0.8317 - val_precision_m: 0.9358 - val_recall_m: 0.7500 - val_tp_m: 91.0667 - val_fp_m: 6.2667 - val_tn_m: 115.8667 - val_fn_m: 31.0667\n",
      "\n",
      "Epoch 00194: loss did not improve\n",
      "epoch time measured: 21.176846504211426\n",
      "Epoch 195/250\n",
      "epoch time start: 1578304041.6138258\n",
      " - 21s - loss: 1.1541e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4941 - val_acc: 0.8833 - val_f1_m: 0.8307 - val_precision_m: 0.9357 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 6.2667 - val_tn_m: 115.8667 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00195: loss did not improve\n",
      "epoch time measured: 21.180941343307495\n",
      "Epoch 196/250\n",
      "epoch time start: 1578304062.7948782\n",
      " - 21s - loss: 1.2760e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4899 - val_acc: 0.8833 - val_f1_m: 0.8315 - val_precision_m: 0.9377 - val_recall_m: 0.7483 - val_tp_m: 90.8533 - val_fp_m: 6.0533 - val_tn_m: 116.0800 - val_fn_m: 31.2800\n",
      "\n",
      "Epoch 00196: loss did not improve\n",
      "epoch time measured: 21.103130102157593\n",
      "Epoch 197/250\n",
      "epoch time start: 1578304083.8981335\n",
      " - 21s - loss: 9.6190e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4865 - val_acc: 0.8783 - val_f1_m: 0.8368 - val_precision_m: 0.9403 - val_recall_m: 0.7550 - val_tp_m: 91.7067 - val_fp_m: 5.8400 - val_tn_m: 116.2933 - val_fn_m: 30.4267\n",
      "\n",
      "Epoch 00197: loss did not improve\n",
      "epoch time measured: 20.958481311798096\n",
      "Epoch 198/250\n",
      "epoch time start: 1578304104.8567414\n",
      " - 21s - loss: 1.2652e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4862 - val_acc: 0.8783 - val_f1_m: 0.8350 - val_precision_m: 0.9383 - val_recall_m: 0.7533 - val_tp_m: 91.4933 - val_fp_m: 6.0533 - val_tn_m: 116.0800 - val_fn_m: 30.6400\n",
      "\n",
      "Epoch 00198: loss did not improve\n",
      "epoch time measured: 21.02127194404602\n",
      "Epoch 199/250\n",
      "epoch time start: 1578304125.8781202\n",
      " - 21s - loss: 1.1863e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4845 - val_acc: 0.8800 - val_f1_m: 0.8376 - val_precision_m: 0.9427 - val_recall_m: 0.7550 - val_tp_m: 91.7067 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 30.4267\n",
      "\n",
      "Epoch 00199: loss did not improve\n",
      "epoch time measured: 21.164772987365723\n",
      "Epoch 200/250\n",
      "epoch time start: 1578304147.0430048\n",
      " - 21s - loss: 1.3478e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4884 - val_acc: 0.8817 - val_f1_m: 0.8349 - val_precision_m: 0.9383 - val_recall_m: 0.7533 - val_tp_m: 91.4933 - val_fp_m: 6.0533 - val_tn_m: 116.0800 - val_fn_m: 30.6400\n",
      "\n",
      "Epoch 00200: loss did not improve\n",
      "epoch time measured: 21.01688313484192\n",
      "Epoch 201/250\n",
      "epoch time start: 1578304168.0599866\n",
      " - 21s - loss: 8.9987e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4939 - val_acc: 0.8833 - val_f1_m: 0.8338 - val_precision_m: 0.9384 - val_recall_m: 0.7517 - val_tp_m: 91.2800 - val_fp_m: 5.9867 - val_tn_m: 116.1467 - val_fn_m: 30.8533\n",
      "\n",
      "Epoch 00201: loss improved from 0.00009 to 0.00009, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.14424967765808\n",
      "Epoch 202/250\n",
      "epoch time start: 1578304189.2044556\n",
      " - 21s - loss: 1.1119e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4919 - val_acc: 0.8800 - val_f1_m: 0.8338 - val_precision_m: 0.9384 - val_recall_m: 0.7517 - val_tp_m: 91.2800 - val_fp_m: 5.9867 - val_tn_m: 116.1467 - val_fn_m: 30.8533\n",
      "\n",
      "Epoch 00202: loss did not improve\n",
      "epoch time measured: 21.145827531814575\n",
      "Epoch 203/250\n",
      "epoch time start: 1578304210.350593\n",
      " - 22s - loss: 1.0712e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4854 - val_acc: 0.8850 - val_f1_m: 0.8398 - val_precision_m: 0.9452 - val_recall_m: 0.7567 - val_tp_m: 91.9200 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 30.2133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00203: loss did not improve\n",
      "epoch time measured: 21.577107667922974\n",
      "Epoch 204/250\n",
      "epoch time start: 1578304231.9280012\n",
      " - 21s - loss: 1.2374e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4846 - val_acc: 0.8850 - val_f1_m: 0.8390 - val_precision_m: 0.9434 - val_recall_m: 0.7567 - val_tp_m: 91.9200 - val_fp_m: 5.5600 - val_tn_m: 116.5733 - val_fn_m: 30.2133\n",
      "\n",
      "Epoch 00204: loss did not improve\n",
      "epoch time measured: 21.32392120361328\n",
      "Epoch 205/250\n",
      "epoch time start: 1578304253.2520163\n",
      " - 21s - loss: 2.0375e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4834 - val_acc: 0.8817 - val_f1_m: 0.8376 - val_precision_m: 0.9427 - val_recall_m: 0.7550 - val_tp_m: 91.7067 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 30.4267\n",
      "\n",
      "Epoch 00205: loss did not improve\n",
      "epoch time measured: 21.099227905273438\n",
      "Epoch 206/250\n",
      "epoch time start: 1578304274.3513424\n",
      " - 21s - loss: 8.8675e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4853 - val_acc: 0.8850 - val_f1_m: 0.8384 - val_precision_m: 0.9447 - val_recall_m: 0.7550 - val_tp_m: 91.7067 - val_fp_m: 5.3467 - val_tn_m: 116.7867 - val_fn_m: 30.4267\n",
      "\n",
      "Epoch 00206: loss improved from 0.00009 to 0.00009, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.117096424102783\n",
      "Epoch 207/250\n",
      "epoch time start: 1578304295.468751\n",
      " - 21s - loss: 1.1869e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4834 - val_acc: 0.8800 - val_f1_m: 0.8384 - val_precision_m: 0.9447 - val_recall_m: 0.7550 - val_tp_m: 91.7067 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 30.4267\n",
      "\n",
      "Epoch 00207: loss did not improve\n",
      "epoch time measured: 21.145440578460693\n",
      "Epoch 208/250\n",
      "epoch time start: 1578304316.6142921\n",
      " - 21s - loss: 8.7594e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4807 - val_acc: 0.8783 - val_f1_m: 0.8385 - val_precision_m: 0.9447 - val_recall_m: 0.7550 - val_tp_m: 91.7067 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 30.4267\n",
      "\n",
      "Epoch 00208: loss improved from 0.00009 to 0.00009, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.131467819213867\n",
      "Epoch 209/250\n",
      "epoch time start: 1578304337.7459843\n",
      " - 21s - loss: 8.7630e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4818 - val_acc: 0.8783 - val_f1_m: 0.8378 - val_precision_m: 0.9428 - val_recall_m: 0.7550 - val_tp_m: 91.7067 - val_fp_m: 5.6267 - val_tn_m: 116.5067 - val_fn_m: 30.4267\n",
      "\n",
      "Epoch 00209: loss did not improve\n",
      "epoch time measured: 21.085431337356567\n",
      "Epoch 210/250\n",
      "epoch time start: 1578304358.8316267\n",
      " - 21s - loss: 9.1707e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4824 - val_acc: 0.8817 - val_f1_m: 0.8397 - val_precision_m: 0.9452 - val_recall_m: 0.7567 - val_tp_m: 91.9200 - val_fp_m: 5.4133 - val_tn_m: 116.7200 - val_fn_m: 30.2133\n",
      "\n",
      "Epoch 00210: loss did not improve\n",
      "epoch time measured: 21.162388801574707\n",
      "Epoch 211/250\n",
      "epoch time start: 1578304379.9941266\n",
      " - 21s - loss: 8.3250e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4841 - val_acc: 0.8833 - val_f1_m: 0.8389 - val_precision_m: 0.9433 - val_recall_m: 0.7567 - val_tp_m: 91.9200 - val_fp_m: 5.5600 - val_tn_m: 116.5733 - val_fn_m: 30.2133\n",
      "\n",
      "Epoch 00211: loss improved from 0.00009 to 0.00008, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.17520308494568\n",
      "Epoch 212/250\n",
      "epoch time start: 1578304401.1694605\n",
      " - 21s - loss: 1.1079e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4877 - val_acc: 0.8833 - val_f1_m: 0.8387 - val_precision_m: 0.9432 - val_recall_m: 0.7567 - val_tp_m: 91.9200 - val_fp_m: 5.5600 - val_tn_m: 116.5733 - val_fn_m: 30.2133\n",
      "\n",
      "Epoch 00212: loss did not improve\n",
      "epoch time measured: 21.18789505958557\n",
      "Epoch 213/250\n",
      "epoch time start: 1578304422.3574386\n",
      " - 21s - loss: 9.8794e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4896 - val_acc: 0.8833 - val_f1_m: 0.8368 - val_precision_m: 0.9409 - val_recall_m: 0.7550 - val_tp_m: 91.7067 - val_fp_m: 5.7733 - val_tn_m: 116.3600 - val_fn_m: 30.4267\n",
      "\n",
      "Epoch 00213: loss did not improve\n",
      "epoch time measured: 21.223795652389526\n",
      "Epoch 214/250\n",
      "epoch time start: 1578304443.5813482\n",
      " - 21s - loss: 8.8956e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4904 - val_acc: 0.8833 - val_f1_m: 0.8378 - val_precision_m: 0.9410 - val_recall_m: 0.7567 - val_tp_m: 91.9200 - val_fp_m: 5.7733 - val_tn_m: 116.3600 - val_fn_m: 30.2133\n",
      "\n",
      "Epoch 00214: loss did not improve\n",
      "epoch time measured: 21.358661651611328\n",
      "Epoch 215/250\n",
      "epoch time start: 1578304464.9401112\n",
      " - 21s - loss: 9.1401e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4910 - val_acc: 0.8817 - val_f1_m: 0.8399 - val_precision_m: 0.9435 - val_recall_m: 0.7583 - val_tp_m: 92.1333 - val_fp_m: 5.5600 - val_tn_m: 116.5733 - val_fn_m: 30.0000\n",
      "\n",
      "Epoch 00215: loss did not improve\n",
      "epoch time measured: 21.092698335647583\n",
      "Epoch 216/250\n",
      "epoch time start: 1578304486.0329146\n",
      " - 21s - loss: 8.6598e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4911 - val_acc: 0.8833 - val_f1_m: 0.8399 - val_precision_m: 0.9435 - val_recall_m: 0.7583 - val_tp_m: 92.1333 - val_fp_m: 5.5600 - val_tn_m: 116.5733 - val_fn_m: 30.0000\n",
      "\n",
      "Epoch 00216: loss did not improve\n",
      "epoch time measured: 21.22575807571411\n",
      "Epoch 217/250\n",
      "epoch time start: 1578304507.2587838\n",
      " - 21s - loss: 8.8234e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4929 - val_acc: 0.8833 - val_f1_m: 0.8389 - val_precision_m: 0.9412 - val_recall_m: 0.7583 - val_tp_m: 92.1333 - val_fp_m: 5.7733 - val_tn_m: 116.3600 - val_fn_m: 30.0000\n",
      "\n",
      "Epoch 00217: loss did not improve\n",
      "epoch time measured: 21.105350494384766\n",
      "Epoch 218/250\n",
      "epoch time start: 1578304528.3642344\n",
      " - 21s - loss: 1.1019e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4894 - val_acc: 0.8833 - val_f1_m: 0.8421 - val_precision_m: 0.9434 - val_recall_m: 0.7617 - val_tp_m: 92.5600 - val_fp_m: 5.5600 - val_tn_m: 116.5733 - val_fn_m: 29.5733\n",
      "\n",
      "Epoch 00218: loss did not improve\n",
      "epoch time measured: 21.098284482955933\n",
      "Epoch 219/250\n",
      "epoch time start: 1578304549.4626265\n",
      " - 21s - loss: 1.1216e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4843 - val_acc: 0.8833 - val_f1_m: 0.8390 - val_precision_m: 0.9431 - val_recall_m: 0.7567 - val_tp_m: 91.9200 - val_fp_m: 5.5600 - val_tn_m: 116.5733 - val_fn_m: 30.2133\n",
      "\n",
      "Epoch 00219: loss did not improve\n",
      "epoch time measured: 21.21251344680786\n",
      "Epoch 220/250\n",
      "epoch time start: 1578304570.6752691\n",
      " - 21s - loss: 9.6292e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4843 - val_acc: 0.8850 - val_f1_m: 0.8413 - val_precision_m: 0.9435 - val_recall_m: 0.7600 - val_tp_m: 92.3467 - val_fp_m: 5.5600 - val_tn_m: 116.5733 - val_fn_m: 29.7867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00220: loss did not improve\n",
      "epoch time measured: 21.17819118499756\n",
      "Epoch 221/250\n",
      "epoch time start: 1578304591.853635\n",
      " - 21s - loss: 8.6347e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4880 - val_acc: 0.8817 - val_f1_m: 0.8386 - val_precision_m: 0.9451 - val_recall_m: 0.7550 - val_tp_m: 91.7067 - val_fp_m: 5.3467 - val_tn_m: 116.7867 - val_fn_m: 30.4267\n",
      "\n",
      "Epoch 00221: loss did not improve\n",
      "epoch time measured: 20.99575662612915\n",
      "Epoch 222/250\n",
      "epoch time start: 1578304612.8495347\n",
      " - 21s - loss: 7.2727e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4902 - val_acc: 0.8850 - val_f1_m: 0.8395 - val_precision_m: 0.9452 - val_recall_m: 0.7567 - val_tp_m: 91.9200 - val_fp_m: 5.3467 - val_tn_m: 116.7867 - val_fn_m: 30.2133\n",
      "\n",
      "Epoch 00222: loss improved from 0.00008 to 0.00007, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.056107759475708\n",
      "Epoch 223/250\n",
      "epoch time start: 1578304633.905938\n",
      " - 21s - loss: 1.1383e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4942 - val_acc: 0.8867 - val_f1_m: 0.8371 - val_precision_m: 0.9448 - val_recall_m: 0.7533 - val_tp_m: 91.4933 - val_fp_m: 5.3467 - val_tn_m: 116.7867 - val_fn_m: 30.6400\n",
      "\n",
      "Epoch 00223: loss did not improve\n",
      "epoch time measured: 21.192900896072388\n",
      "Epoch 224/250\n",
      "epoch time start: 1578304655.0989857\n",
      " - 21s - loss: 9.6224e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4995 - val_acc: 0.8883 - val_f1_m: 0.8342 - val_precision_m: 0.9424 - val_recall_m: 0.7500 - val_tp_m: 91.0667 - val_fp_m: 5.5600 - val_tn_m: 116.5733 - val_fn_m: 31.0667\n",
      "\n",
      "Epoch 00224: loss did not improve\n",
      "epoch time measured: 21.05964708328247\n",
      "Epoch 225/250\n",
      "epoch time start: 1578304676.1587605\n",
      " - 21s - loss: 1.0159e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4995 - val_acc: 0.8917 - val_f1_m: 0.8396 - val_precision_m: 0.9452 - val_recall_m: 0.7567 - val_tp_m: 91.9200 - val_fp_m: 5.3467 - val_tn_m: 116.7867 - val_fn_m: 30.2133\n",
      "\n",
      "Epoch 00225: loss did not improve\n",
      "epoch time measured: 21.116958379745483\n",
      "Epoch 226/250\n",
      "epoch time start: 1578304697.2758312\n",
      " - 21s - loss: 8.4820e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4944 - val_acc: 0.8883 - val_f1_m: 0.8442 - val_precision_m: 0.9459 - val_recall_m: 0.7633 - val_tp_m: 92.7733 - val_fp_m: 5.3467 - val_tn_m: 116.7867 - val_fn_m: 29.3600\n",
      "\n",
      "Epoch 00226: loss did not improve\n",
      "epoch time measured: 21.119152784347534\n",
      "Epoch 227/250\n",
      "epoch time start: 1578304718.395381\n",
      " - 21s - loss: 7.8921e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4936 - val_acc: 0.8867 - val_f1_m: 0.8475 - val_precision_m: 0.9463 - val_recall_m: 0.7683 - val_tp_m: 93.4800 - val_fp_m: 5.3467 - val_tn_m: 116.7867 - val_fn_m: 28.6533\n",
      "\n",
      "Epoch 00227: loss did not improve\n",
      "epoch time measured: 21.21459937095642\n",
      "Epoch 228/250\n",
      "epoch time start: 1578304739.6100805\n",
      " - 21s - loss: 7.6267e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4955 - val_acc: 0.8850 - val_f1_m: 0.8445 - val_precision_m: 0.9442 - val_recall_m: 0.7650 - val_tp_m: 93.0533 - val_fp_m: 5.5600 - val_tn_m: 116.5733 - val_fn_m: 29.0800\n",
      "\n",
      "Epoch 00228: loss did not improve\n",
      "epoch time measured: 21.185465335845947\n",
      "Epoch 229/250\n",
      "epoch time start: 1578304760.7956736\n",
      " - 21s - loss: 9.4192e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4996 - val_acc: 0.8800 - val_f1_m: 0.8392 - val_precision_m: 0.9413 - val_recall_m: 0.7583 - val_tp_m: 92.1333 - val_fp_m: 5.7733 - val_tn_m: 116.3600 - val_fn_m: 30.0000\n",
      "\n",
      "Epoch 00229: loss did not improve\n",
      "epoch time measured: 21.056418657302856\n",
      "Epoch 230/250\n",
      "epoch time start: 1578304781.852207\n",
      " - 21s - loss: 2.1797e-04 - acc: 1.0000 - f1_m: 0.9992 - precision_m: 1.0000 - recall_m: 0.9983 - tp_m: 121.9200 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.2133 - val_loss: 0.4955 - val_acc: 0.8800 - val_f1_m: 0.8360 - val_precision_m: 0.9387 - val_recall_m: 0.7550 - val_tp_m: 91.7067 - val_fp_m: 5.9867 - val_tn_m: 116.1467 - val_fn_m: 30.4267\n",
      "\n",
      "Epoch 00230: loss did not improve\n",
      "epoch time measured: 21.259853839874268\n",
      "Epoch 231/250\n",
      "epoch time start: 1578304803.1121662\n",
      " - 21s - loss: 7.2073e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4965 - val_acc: 0.8833 - val_f1_m: 0.8371 - val_precision_m: 0.9385 - val_recall_m: 0.7567 - val_tp_m: 91.9200 - val_fp_m: 6.0533 - val_tn_m: 116.0800 - val_fn_m: 30.2133\n",
      "\n",
      "Epoch 00231: loss improved from 0.00007 to 0.00007, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.253451585769653\n",
      "Epoch 232/250\n",
      "epoch time start: 1578304824.3658414\n",
      " - 21s - loss: 7.8489e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4984 - val_acc: 0.8800 - val_f1_m: 0.8359 - val_precision_m: 0.9383 - val_recall_m: 0.7550 - val_tp_m: 91.7067 - val_fp_m: 6.0533 - val_tn_m: 116.0800 - val_fn_m: 30.4267\n",
      "\n",
      "Epoch 00232: loss did not improve\n",
      "epoch time measured: 21.14293885231018\n",
      "Epoch 233/250\n",
      "epoch time start: 1578304845.5089033\n",
      " - 21s - loss: 1.1155e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.5063 - val_acc: 0.8800 - val_f1_m: 0.8361 - val_precision_m: 0.9364 - val_recall_m: 0.7567 - val_tp_m: 91.9200 - val_fp_m: 6.2000 - val_tn_m: 115.9333 - val_fn_m: 30.2133\n",
      "\n",
      "Epoch 00233: loss did not improve\n",
      "epoch time measured: 21.146178245544434\n",
      "Epoch 234/250\n",
      "epoch time start: 1578304866.655205\n",
      " - 21s - loss: 1.1915e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.5136 - val_acc: 0.8850 - val_f1_m: 0.8348 - val_precision_m: 0.9365 - val_recall_m: 0.7550 - val_tp_m: 91.7067 - val_fp_m: 6.2000 - val_tn_m: 115.9333 - val_fn_m: 30.4267\n",
      "\n",
      "Epoch 00234: loss did not improve\n",
      "epoch time measured: 20.982624769210815\n",
      "Epoch 235/250\n",
      "epoch time start: 1578304887.6379576\n",
      " - 21s - loss: 6.8630e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.5080 - val_acc: 0.8833 - val_f1_m: 0.8346 - val_precision_m: 0.9384 - val_recall_m: 0.7533 - val_tp_m: 91.4933 - val_fp_m: 5.9867 - val_tn_m: 116.1467 - val_fn_m: 30.6400\n",
      "\n",
      "Epoch 00235: loss improved from 0.00007 to 0.00007, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.073607683181763\n",
      "Epoch 236/250\n",
      "epoch time start: 1578304908.7117915\n",
      " - 21s - loss: 8.1015e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.5029 - val_acc: 0.8833 - val_f1_m: 0.8370 - val_precision_m: 0.9388 - val_recall_m: 0.7567 - val_tp_m: 91.9200 - val_fp_m: 5.9867 - val_tn_m: 116.1467 - val_fn_m: 30.2133\n",
      "\n",
      "Epoch 00236: loss did not improve\n",
      "epoch time measured: 21.08832597732544\n",
      "Epoch 237/250\n",
      "epoch time start: 1578304929.8002617\n",
      " - 21s - loss: 7.3600e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.5003 - val_acc: 0.8817 - val_f1_m: 0.8360 - val_precision_m: 0.9387 - val_recall_m: 0.7550 - val_tp_m: 91.7067 - val_fp_m: 5.9867 - val_tn_m: 116.1467 - val_fn_m: 30.4267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00237: loss did not improve\n",
      "epoch time measured: 20.981904983520508\n",
      "Epoch 238/250\n",
      "epoch time start: 1578304950.782273\n",
      " - 21s - loss: 7.7932e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4990 - val_acc: 0.8833 - val_f1_m: 0.8364 - val_precision_m: 0.9429 - val_recall_m: 0.7533 - val_tp_m: 91.4933 - val_fp_m: 5.5600 - val_tn_m: 116.5733 - val_fn_m: 30.6400\n",
      "\n",
      "Epoch 00238: loss did not improve\n",
      "epoch time measured: 21.06362271308899\n",
      "Epoch 239/250\n",
      "epoch time start: 1578304971.846029\n",
      " - 21s - loss: 8.4860e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.5005 - val_acc: 0.8817 - val_f1_m: 0.8364 - val_precision_m: 0.9429 - val_recall_m: 0.7533 - val_tp_m: 91.4933 - val_fp_m: 5.5600 - val_tn_m: 116.5733 - val_fn_m: 30.6400\n",
      "\n",
      "Epoch 00239: loss did not improve\n",
      "epoch time measured: 20.87963581085205\n",
      "Epoch 240/250\n",
      "epoch time start: 1578304992.725781\n",
      " - 21s - loss: 8.6378e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.5018 - val_acc: 0.8800 - val_f1_m: 0.8364 - val_precision_m: 0.9429 - val_recall_m: 0.7533 - val_tp_m: 91.4933 - val_fp_m: 5.5600 - val_tn_m: 116.5733 - val_fn_m: 30.6400\n",
      "\n",
      "Epoch 00240: loss did not improve\n",
      "epoch time measured: 21.22793698310852\n",
      "Epoch 241/250\n",
      "epoch time start: 1578305013.9538283\n",
      " - 21s - loss: 1.0190e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.5011 - val_acc: 0.8817 - val_f1_m: 0.8389 - val_precision_m: 0.9433 - val_recall_m: 0.7567 - val_tp_m: 91.9200 - val_fp_m: 5.5600 - val_tn_m: 116.5733 - val_fn_m: 30.2133\n",
      "\n",
      "Epoch 00241: loss did not improve\n",
      "epoch time measured: 21.36985445022583\n",
      "Epoch 242/250\n",
      "epoch time start: 1578305035.3238072\n",
      " - 21s - loss: 6.1681e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.5017 - val_acc: 0.8817 - val_f1_m: 0.8390 - val_precision_m: 0.9434 - val_recall_m: 0.7567 - val_tp_m: 91.9200 - val_fp_m: 5.5600 - val_tn_m: 116.5733 - val_fn_m: 30.2133\n",
      "\n",
      "Epoch 00242: loss improved from 0.00007 to 0.00006, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 21.020615100860596\n",
      "Epoch 243/250\n",
      "epoch time start: 1578305056.3445537\n",
      " - 21s - loss: 7.0707e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.5037 - val_acc: 0.8800 - val_f1_m: 0.8378 - val_precision_m: 0.9432 - val_recall_m: 0.7550 - val_tp_m: 91.7067 - val_fp_m: 5.5600 - val_tn_m: 116.5733 - val_fn_m: 30.4267\n",
      "\n",
      "Epoch 00243: loss did not improve\n",
      "epoch time measured: 20.883690357208252\n",
      "Epoch 244/250\n",
      "epoch time start: 1578305077.228348\n",
      " - 21s - loss: 7.6249e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.5062 - val_acc: 0.8800 - val_f1_m: 0.8354 - val_precision_m: 0.9428 - val_recall_m: 0.7517 - val_tp_m: 91.2800 - val_fp_m: 5.5600 - val_tn_m: 116.5733 - val_fn_m: 30.8533\n",
      "\n",
      "Epoch 00244: loss did not improve\n",
      "epoch time measured: 21.260236024856567\n",
      "Epoch 245/250\n",
      "epoch time start: 1578305098.4887025\n",
      " - 21s - loss: 1.1359e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.5015 - val_acc: 0.8817 - val_f1_m: 0.8373 - val_precision_m: 0.9449 - val_recall_m: 0.7533 - val_tp_m: 91.4933 - val_fp_m: 5.3467 - val_tn_m: 116.7867 - val_fn_m: 30.6400\n",
      "\n",
      "Epoch 00245: loss did not improve\n",
      "epoch time measured: 21.00937533378601\n",
      "Epoch 246/250\n",
      "epoch time start: 1578305119.4981923\n",
      " - 21s - loss: 6.1786e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4982 - val_acc: 0.8800 - val_f1_m: 0.8395 - val_precision_m: 0.9451 - val_recall_m: 0.7567 - val_tp_m: 91.9200 - val_fp_m: 5.3467 - val_tn_m: 116.7867 - val_fn_m: 30.2133\n",
      "\n",
      "Epoch 00246: loss did not improve\n",
      "epoch time measured: 20.9313485622406\n",
      "Epoch 247/250\n",
      "epoch time start: 1578305140.4296422\n",
      " - 21s - loss: 1.1072e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4989 - val_acc: 0.8800 - val_f1_m: 0.8385 - val_precision_m: 0.9428 - val_recall_m: 0.7567 - val_tp_m: 91.9200 - val_fp_m: 5.5600 - val_tn_m: 116.5733 - val_fn_m: 30.2133\n",
      "\n",
      "Epoch 00247: loss did not improve\n",
      "epoch time measured: 21.024100303649902\n",
      "Epoch 248/250\n",
      "epoch time start: 1578305161.4538686\n",
      " - 21s - loss: 7.9455e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4981 - val_acc: 0.8867 - val_f1_m: 0.8358 - val_precision_m: 0.9382 - val_recall_m: 0.7550 - val_tp_m: 91.7067 - val_fp_m: 6.0533 - val_tn_m: 116.0800 - val_fn_m: 30.4267\n",
      "\n",
      "Epoch 00248: loss did not improve\n",
      "epoch time measured: 20.916927576065063\n",
      "Epoch 249/250\n",
      "epoch time start: 1578305182.3709035\n",
      " - 21s - loss: 7.8957e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4978 - val_acc: 0.8850 - val_f1_m: 0.8358 - val_precision_m: 0.9382 - val_recall_m: 0.7550 - val_tp_m: 91.7067 - val_fp_m: 6.0533 - val_tn_m: 116.0800 - val_fn_m: 30.4267\n",
      "\n",
      "Epoch 00249: loss did not improve\n",
      "epoch time measured: 21.090708255767822\n",
      "Epoch 250/250\n",
      "epoch time start: 1578305203.4617605\n",
      " - 21s - loss: 9.4506e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 122.1333 - fp_m: 0.0000e+00 - tn_m: 122.1333 - fn_m: 0.0000e+00 - val_loss: 0.4985 - val_acc: 0.8850 - val_f1_m: 0.8348 - val_precision_m: 0.9382 - val_recall_m: 0.7533 - val_tp_m: 91.4933 - val_fp_m: 6.0533 - val_tn_m: 116.0800 - val_fn_m: 30.6400\n",
      "\n",
      "Epoch 00250: loss did not improve\n",
      "epoch time measured: 20.91041922569275\n",
      "type(totalTrainingTime): <class 'numpy.float64'>\n",
      "type(convergenceEpochs): <class 'str'>\n",
      "Loading train / test dataset :  ../data/eeg_alco_large/ ../data/eeg_alco_large/\n",
      "x_train_path: ../data/eeg_alco_large/X_train.npy\n",
      "Finished processing train dataset..\n",
      "Finished loading test dataset..\n",
      "\n",
      "Number of train samples :  600 Number of test samples :  600\n",
      "Number of classes :  2\n",
      "Sequence length :  255\n",
      "y_true - 1 Tensor(\"metrics_1/tn_m/sub:0\", shape=(?, ?), dtype=float32)\n",
      "\n",
      "Evaluating : \n",
      "600/600 [==============================] - 7s 11ms/step\n",
      "predictions: [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False  True False False False  True False False  True False False\n",
      "  True  True  True  True  True  True  True False  True  True  True False\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True False  True False False  True  True False  True False\n",
      "  True  True  True False False  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True False  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True False False False False False False False\n",
      " False False False False False  True False False False False  True False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      "  True False False  True False False False  True False False False False\n",
      " False False False False False  True False False False  True  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      " False  True  True  True False False  True  True  True  True False False\n",
      " False False  True  True  True  True  True  True  True False False False\n",
      "  True False False False  True False False False  True  True  True False\n",
      "  True False  True False  True False  True  True  True False False  True\n",
      " False  True  True  True  True  True  True False False False  True  True\n",
      "  True  True  True  True  True  True  True  True  True False  True  True\n",
      "  True False  True  True  True  True  True  True False False False  True\n",
      " False  True  True  True  True  True  True False  True  True False  True\n",
      "  True False  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True False  True  True False False  True  True False  True\n",
      " False False False False  True False  True  True False  True  True  True\n",
      " False  True False False  True  True  True  True  True  True  True  True\n",
      "  True  True  True False  True False False  True  True  True  True  True\n",
      "  True False  True  True False  True  True False  True  True  True  True\n",
      "  True  True  True  True  True  True  True False  True  True  True  True\n",
      "  True False False False False  True False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "truelabels: [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "TP: 232\n",
      "TN: 282\n",
      "FP: 18\n",
      "FN: 68\n",
      "\n",
      "Accuracy: 0.8566666666666667\n",
      "Precision: 0.928\n",
      "Recall: 0.7733333333333333\n",
      "F1: 0.8436363636363636\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8566666666666667, 0.5016763567924499)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(resultsFilename, \"a\") as text_file:\n",
    "    print(f\"Current Fold: Only\", file=text_file)\n",
    "model = generate_model_2()\n",
    "train_model(model, DATASET_INDEX, dataset_prefix='eeg2_attention', epochs=n_epochs, batch_size=128)\n",
    "evaluate_model(model, DATASET_INDEX, dataset_prefix='eeg2_attention', batch_size=128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
