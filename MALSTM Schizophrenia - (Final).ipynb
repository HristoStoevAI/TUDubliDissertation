{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('MLSTM-FCN/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM, multiply, concatenate, Activation, Masking, Reshape\n",
    "from keras.layers import Conv1D, BatchNormalization, GlobalAveragePooling1D, Permute, Dropout\n",
    "\n",
    "from utils.constants import MAX_NB_VARIABLES, NB_CLASSES_LIST, MAX_TIMESTEPS_LIST\n",
    "from utils.keras_utils import train_model, evaluate_model, set_trainable\n",
    "from utils.layer_utils import AttentionLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsFilename='results_data_FINAL.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_INDEX_0 = 56\n",
    "DATASET_INDEX_1 = 57\n",
    "DATASET_INDEX_2 = 58\n",
    "DATASET_INDEX_3 = 59\n",
    "\n",
    "MAX_TIMESTEPS = MAX_TIMESTEPS_LIST[DATASET_INDEX_0]\n",
    "MAX_NB_VARIABLES = MAX_NB_VARIABLES[DATASET_INDEX_0]\n",
    "NB_CLASS = NB_CLASSES_LIST[DATASET_INDEX_0]\n",
    "\n",
    "TRAINABLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_2():\n",
    "    ip = Input(shape=(MAX_NB_VARIABLES, MAX_TIMESTEPS))\n",
    "    # stride = 10\n",
    "\n",
    "    # x = Permute((2, 1))(ip)\n",
    "    # x = Conv1D(MAX_NB_VARIABLES // stride, 8, strides=stride, padding='same', activation='relu', use_bias=False,\n",
    "    #            kernel_initializer='he_uniform')(x)  # (None, variables / stride, timesteps)\n",
    "    # x = Permute((2, 1))(x)\n",
    "\n",
    "    #ip1 = K.reshape(ip,shape=(MAX_TIMESTEPS,MAX_NB_VARIABLES))\n",
    "    #x = Permute((2, 1))(ip)\n",
    "    x = Masking()(ip)\n",
    "    x = AttentionLSTM(8)(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "\n",
    "    y = Permute((2, 1))(ip)\n",
    "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "\n",
    "    x = concatenate([x, y])\n",
    "\n",
    "    out = Dense(NB_CLASS, activation='softmax')(x)\n",
    "\n",
    "    model = Model(ip, out)\n",
    "    model.summary()\n",
    "\n",
    "    # add load model code here to fine-tune\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_3():\n",
    "    ip = Input(shape=(MAX_NB_VARIABLES, MAX_TIMESTEPS))\n",
    "\n",
    "    x = Masking()(ip)\n",
    "    x = LSTM(8)(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "\n",
    "    y = Permute((2, 1))(ip)\n",
    "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    #y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    #y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "\n",
    "    x = concatenate([x, y])\n",
    "\n",
    "    out = Dense(NB_CLASS, activation='softmax')(x)\n",
    "\n",
    "    model = Model(ip, out)\n",
    "    model.summary()\n",
    "\n",
    "    # add load model code here to fine-tune\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_4():\n",
    "    ip = Input(shape=(MAX_NB_VARIABLES, MAX_TIMESTEPS))\n",
    "    # stride = 3\n",
    "    #\n",
    "    # x = Permute((2, 1))(ip)\n",
    "    # x = Conv1D(MAX_NB_VARIABLES // stride, 8, strides=stride, padding='same', activation='relu', use_bias=False,\n",
    "    #            kernel_initializer='he_uniform')(x)  # (None, variables / stride, timesteps)\n",
    "    # x = Permute((2, 1))(x)\n",
    "\n",
    "    x = Masking()(ip)\n",
    "    x = AttentionLSTM(8)(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "\n",
    "    y = Permute((2, 1))(ip)\n",
    "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    #y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    #y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "\n",
    "    x = concatenate([x, y])\n",
    "\n",
    "    out = Dense(NB_CLASS, activation='softmax')(x)\n",
    "\n",
    "    model = Model(ip, out)\n",
    "    model.summary()\n",
    "\n",
    "    # add load model code here to fine-tune\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_excite_block(input):\n",
    "    ''' Create a squeeze-excite block\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "        k: width factor\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    filters = input._keras_shape[-1] # channel_axis = -1 for TF\n",
    "\n",
    "    se = GlobalAveragePooling1D()(input)\n",
    "    se = Reshape((1, filters))(se)\n",
    "    se = Dense(filters // 16,  activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = multiply([input, se])\n",
    "    return se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 16, 7680)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 7680, 16)     0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 7680, 128)    16512       permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 7680, 128)    512         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 7680, 128)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 128)          0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 128)       0           global_average_pooling1d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1, 8)         1024        reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1, 128)       1024        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 7680, 128)    0           activation_4[0][0]               \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 7680, 256)    164096      multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 7680, 256)    1024        conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 7680, 256)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 256)          0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 256)       0           global_average_pooling1d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1, 16)        4096        reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1, 256)       4096        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 7680, 256)    0           activation_5[0][0]               \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 7680, 128)    98432       multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "masking_2 (Masking)             (None, 16, 7680)     0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 7680, 128)    512         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_lstm_2 (AttentionLSTM (None, 8)            553328      masking_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7680, 128)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 8)            0           attention_lstm_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 128)          0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 136)          0           dropout_2[0][0]                  \n",
      "                                                                 global_average_pooling1d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 2)            274         concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 844,930\n",
      "Trainable params: 843,906\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "Loading train / test dataset :  ../data/eeg_schizo_1/ ../data/eeg_schizo_1/\n",
      "x_train_path: ../data/eeg_schizo_1/X_train.npy\n",
      "Finished processing train dataset..\n",
      "Finished loading test dataset..\n",
      "\n",
      "Number of train samples :  62 Number of test samples :  17\n",
      "Number of classes :  2\n",
      "Sequence length :  7680\n",
      "Class weights :  [1. 1.]\n",
      "y_true - 1 Tensor(\"metrics_1/tn_m/sub:0\", shape=(?, ?), dtype=float32)\n",
      "Train on 62 samples, validate on 17 samples\n",
      "Epoch 1/250\n",
      "epoch time start: 1578287095.1016295\n",
      " - 18s - loss: 0.7297 - acc: 0.5000 - f1_m: 0.5000 - precision_m: 0.5000 - recall_m: 0.5000 - tp_m: 31.0000 - fp_m: 31.0000 - tn_m: 31.0000 - fn_m: 31.0000 - val_loss: 0.8418 - val_acc: 0.4706 - val_f1_m: 0.4706 - val_precision_m: 0.4706 - val_recall_m: 0.4706 - val_tp_m: 8.0000 - val_fp_m: 9.0000 - val_tn_m: 8.0000 - val_fn_m: 9.0000\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.72969, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 18.184871435165405\n",
      "Epoch 2/250\n",
      "epoch time start: 1578287113.286701\n",
      " - 16s - loss: 0.5550 - acc: 0.7419 - f1_m: 0.7419 - precision_m: 0.7419 - recall_m: 0.7419 - tp_m: 46.0000 - fp_m: 16.0000 - tn_m: 46.0000 - fn_m: 16.0000 - val_loss: 0.5878 - val_acc: 0.5882 - val_f1_m: 0.5882 - val_precision_m: 0.5882 - val_recall_m: 0.5882 - val_tp_m: 10.0000 - val_fp_m: 7.0000 - val_tn_m: 10.0000 - val_fn_m: 7.0000\n",
      "\n",
      "Epoch 00002: loss improved from 0.72969 to 0.55504, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.15794825553894\n",
      "Epoch 3/250\n",
      "epoch time start: 1578287129.4447865\n",
      " - 16s - loss: 0.5006 - acc: 0.8387 - f1_m: 0.8387 - precision_m: 0.8387 - recall_m: 0.8387 - tp_m: 52.0000 - fp_m: 10.0000 - tn_m: 52.0000 - fn_m: 10.0000 - val_loss: 0.5842 - val_acc: 0.5882 - val_f1_m: 0.5882 - val_precision_m: 0.5882 - val_recall_m: 0.5882 - val_tp_m: 10.0000 - val_fp_m: 7.0000 - val_tn_m: 10.0000 - val_fn_m: 7.0000\n",
      "\n",
      "Epoch 00003: loss improved from 0.55504 to 0.50057, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.176392078399658\n",
      "Epoch 4/250\n",
      "epoch time start: 1578287145.6213114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 16s - loss: 0.4595 - acc: 0.7581 - f1_m: 0.7581 - precision_m: 0.7581 - recall_m: 0.7581 - tp_m: 47.0000 - fp_m: 15.0000 - tn_m: 47.0000 - fn_m: 15.0000 - val_loss: 0.6321 - val_acc: 0.6471 - val_f1_m: 0.6471 - val_precision_m: 0.6471 - val_recall_m: 0.6471 - val_tp_m: 11.0000 - val_fp_m: 6.0000 - val_tn_m: 11.0000 - val_fn_m: 6.0000\n",
      "\n",
      "Epoch 00004: loss improved from 0.50057 to 0.45947, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.202544450759888\n",
      "Epoch 5/250\n",
      "epoch time start: 1578287161.8240325\n",
      " - 16s - loss: 0.4409 - acc: 0.7903 - f1_m: 0.7903 - precision_m: 0.7903 - recall_m: 0.7903 - tp_m: 49.0000 - fp_m: 13.0000 - tn_m: 49.0000 - fn_m: 13.0000 - val_loss: 0.5708 - val_acc: 0.5882 - val_f1_m: 0.5882 - val_precision_m: 0.5882 - val_recall_m: 0.5882 - val_tp_m: 10.0000 - val_fp_m: 7.0000 - val_tn_m: 10.0000 - val_fn_m: 7.0000\n",
      "\n",
      "Epoch 00005: loss improved from 0.45947 to 0.44091, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.127795696258545\n",
      "Epoch 6/250\n",
      "epoch time start: 1578287177.9520042\n",
      " - 16s - loss: 0.3512 - acc: 0.8710 - f1_m: 0.8710 - precision_m: 0.8710 - recall_m: 0.8710 - tp_m: 54.0000 - fp_m: 8.0000 - tn_m: 54.0000 - fn_m: 8.0000 - val_loss: 0.4758 - val_acc: 0.7647 - val_f1_m: 0.7647 - val_precision_m: 0.7647 - val_recall_m: 0.7647 - val_tp_m: 13.0000 - val_fp_m: 4.0000 - val_tn_m: 13.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00006: loss improved from 0.44091 to 0.35116, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.120070457458496\n",
      "Epoch 7/250\n",
      "epoch time start: 1578287194.0722287\n",
      " - 16s - loss: 0.3421 - acc: 0.8548 - f1_m: 0.8548 - precision_m: 0.8548 - recall_m: 0.8548 - tp_m: 53.0000 - fp_m: 9.0000 - tn_m: 53.0000 - fn_m: 9.0000 - val_loss: 0.3828 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "\n",
      "Epoch 00007: loss improved from 0.35116 to 0.34207, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.157434225082397\n",
      "Epoch 8/250\n",
      "epoch time start: 1578287210.2298136\n",
      " - 16s - loss: 0.2815 - acc: 0.9194 - f1_m: 0.9194 - precision_m: 0.9194 - recall_m: 0.9194 - tp_m: 57.0000 - fp_m: 5.0000 - tn_m: 57.0000 - fn_m: 5.0000 - val_loss: 0.3465 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00008: loss improved from 0.34207 to 0.28149, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.388673782348633\n",
      "Epoch 9/250\n",
      "epoch time start: 1578287226.6186545\n",
      " - 16s - loss: 0.3079 - acc: 0.8871 - f1_m: 0.8871 - precision_m: 0.8871 - recall_m: 0.8871 - tp_m: 55.0000 - fp_m: 7.0000 - tn_m: 55.0000 - fn_m: 7.0000 - val_loss: 0.3174 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "\n",
      "Epoch 00009: loss did not improve\n",
      "epoch time measured: 16.101650714874268\n",
      "Epoch 10/250\n",
      "epoch time start: 1578287242.7204695\n",
      " - 16s - loss: 0.2441 - acc: 0.9194 - f1_m: 0.9194 - precision_m: 0.9194 - recall_m: 0.9194 - tp_m: 57.0000 - fp_m: 5.0000 - tn_m: 57.0000 - fn_m: 5.0000 - val_loss: 0.3265 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "\n",
      "Epoch 00010: loss improved from 0.28149 to 0.24412, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.406627655029297\n",
      "Epoch 11/250\n",
      "epoch time start: 1578287259.1272535\n",
      " - 16s - loss: 0.2498 - acc: 0.9194 - f1_m: 0.9194 - precision_m: 0.9194 - recall_m: 0.9194 - tp_m: 57.0000 - fp_m: 5.0000 - tn_m: 57.0000 - fn_m: 5.0000 - val_loss: 0.4621 - val_acc: 0.7059 - val_f1_m: 0.7059 - val_precision_m: 0.7059 - val_recall_m: 0.7059 - val_tp_m: 12.0000 - val_fp_m: 5.0000 - val_tn_m: 12.0000 - val_fn_m: 5.0000\n",
      "\n",
      "Epoch 00011: loss did not improve\n",
      "epoch time measured: 16.29280400276184\n",
      "Epoch 12/250\n",
      "epoch time start: 1578287275.4201653\n",
      " - 16s - loss: 0.2046 - acc: 0.9355 - f1_m: 0.9355 - precision_m: 0.9355 - recall_m: 0.9355 - tp_m: 58.0000 - fp_m: 4.0000 - tn_m: 58.0000 - fn_m: 4.0000 - val_loss: 0.5440 - val_acc: 0.7647 - val_f1_m: 0.7647 - val_precision_m: 0.7647 - val_recall_m: 0.7647 - val_tp_m: 13.0000 - val_fp_m: 4.0000 - val_tn_m: 13.0000 - val_fn_m: 4.0000\n",
      "\n",
      "Epoch 00012: loss improved from 0.24412 to 0.20463, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.14242386817932\n",
      "Epoch 13/250\n",
      "epoch time start: 1578287291.5627189\n",
      " - 16s - loss: 0.2181 - acc: 0.9194 - f1_m: 0.9194 - precision_m: 0.9194 - recall_m: 0.9194 - tp_m: 57.0000 - fp_m: 5.0000 - tn_m: 57.0000 - fn_m: 5.0000 - val_loss: 0.3609 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "\n",
      "Epoch 00013: loss did not improve\n",
      "epoch time measured: 16.04121971130371\n",
      "Epoch 14/250\n",
      "epoch time start: 1578287307.6040478\n",
      " - 16s - loss: 0.1748 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - tp_m: 61.0000 - fp_m: 1.0000 - tn_m: 61.0000 - fn_m: 1.0000 - val_loss: 0.2591 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00014: loss improved from 0.20463 to 0.17484, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.297990083694458\n",
      "Epoch 15/250\n",
      "epoch time start: 1578287323.9021895\n",
      " - 16s - loss: 0.1799 - acc: 0.9516 - f1_m: 0.9516 - precision_m: 0.9516 - recall_m: 0.9516 - tp_m: 59.0000 - fp_m: 3.0000 - tn_m: 59.0000 - fn_m: 3.0000 - val_loss: 0.2294 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00015: loss did not improve\n",
      "epoch time measured: 16.431123971939087\n",
      "Epoch 16/250\n",
      "epoch time start: 1578287340.3334525\n",
      " - 16s - loss: 0.1369 - acc: 0.9677 - f1_m: 0.9677 - precision_m: 0.9677 - recall_m: 0.9677 - tp_m: 60.0000 - fp_m: 2.0000 - tn_m: 60.0000 - fn_m: 2.0000 - val_loss: 0.2194 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00016: loss improved from 0.17484 to 0.13690, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.163002252578735\n",
      "Epoch 17/250\n",
      "epoch time start: 1578287356.4965925\n",
      " - 16s - loss: 0.1533 - acc: 0.9677 - f1_m: 0.9677 - precision_m: 0.9677 - recall_m: 0.9677 - tp_m: 60.0000 - fp_m: 2.0000 - tn_m: 60.0000 - fn_m: 2.0000 - val_loss: 0.2204 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00017: loss did not improve\n",
      "epoch time measured: 16.100651025772095\n",
      "Epoch 18/250\n",
      "epoch time start: 1578287372.5973673\n",
      " - 16s - loss: 0.1083 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - tp_m: 61.0000 - fp_m: 1.0000 - tn_m: 61.0000 - fn_m: 1.0000 - val_loss: 0.2235 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00018: loss improved from 0.13690 to 0.10832, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.216670274734497\n",
      "Epoch 19/250\n",
      "epoch time start: 1578287388.814162\n",
      " - 16s - loss: 0.1140 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2337 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00019: loss did not improve\n",
      "epoch time measured: 16.22695255279541\n",
      "Epoch 20/250\n",
      "epoch time start: 1578287405.0412807\n",
      " - 16s - loss: 0.0898 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2159 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00020: loss improved from 0.10832 to 0.08976, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.182763814926147\n",
      "Epoch 21/250\n",
      "epoch time start: 1578287421.2241862\n",
      " - 16s - loss: 0.0856 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - tp_m: 61.0000 - fp_m: 1.0000 - tn_m: 61.0000 - fn_m: 1.0000 - val_loss: 0.1995 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00021: loss improved from 0.08976 to 0.08562, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.1155743598938\n",
      "Epoch 22/250\n",
      "epoch time start: 1578287437.3399003\n",
      " - 16s - loss: 0.0680 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1891 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00022: loss improved from 0.08562 to 0.06805, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.170237064361572\n",
      "Epoch 23/250\n",
      "epoch time start: 1578287453.5102696\n",
      " - 16s - loss: 0.0582 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1920 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00023: loss improved from 0.06805 to 0.05818, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.172987699508667\n",
      "Epoch 24/250\n",
      "epoch time start: 1578287469.6833963\n",
      " - 16s - loss: 0.0559 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2127 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00024: loss improved from 0.05818 to 0.05586, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.050174474716187\n",
      "Epoch 25/250\n",
      "epoch time start: 1578287485.733709\n",
      " - 16s - loss: 0.0371 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2378 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00025: loss improved from 0.05586 to 0.03710, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.280653476715088\n",
      "Epoch 26/250\n",
      "epoch time start: 1578287502.0144978\n",
      " - 16s - loss: 0.0452 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - tp_m: 61.0000 - fp_m: 1.0000 - tn_m: 61.0000 - fn_m: 1.0000 - val_loss: 0.1741 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00026: loss did not improve\n",
      "epoch time measured: 16.08882999420166\n",
      "Epoch 27/250\n",
      "epoch time start: 1578287518.1034403\n",
      " - 16s - loss: 0.0413 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1812 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "\n",
      "Epoch 00027: loss did not improve\n",
      "epoch time measured: 16.017188549041748\n",
      "Epoch 28/250\n",
      "epoch time start: 1578287534.1207678\n",
      " - 16s - loss: 0.0403 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1663 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00028: loss did not improve\n",
      "epoch time measured: 16.267513751983643\n",
      "Epoch 29/250\n",
      "epoch time start: 1578287550.3887584\n",
      " - 16s - loss: 0.0293 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1593 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00029: loss improved from 0.03710 to 0.02928, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.393193006515503\n",
      "Epoch 30/250\n",
      "epoch time start: 1578287566.7820988\n",
      " - 16s - loss: 0.0265 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2009 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00030: loss improved from 0.02928 to 0.02651, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.289043426513672\n",
      "Epoch 31/250\n",
      "epoch time start: 1578287583.0714176\n",
      " - 16s - loss: 0.0271 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1744 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00031: loss did not improve\n",
      "epoch time measured: 16.432945251464844\n",
      "Epoch 32/250\n",
      "epoch time start: 1578287599.5044684\n",
      " - 16s - loss: 0.0187 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1507 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00032: loss improved from 0.02651 to 0.01874, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.15137243270874\n",
      "Epoch 33/250\n",
      "epoch time start: 1578287615.655981\n",
      " - 16s - loss: 0.0171 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1405 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00033: loss improved from 0.01874 to 0.01709, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.082568645477295\n",
      "Epoch 34/250\n",
      "epoch time start: 1578287631.7387083\n",
      " - 16s - loss: 0.0153 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1444 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00034: loss improved from 0.01709 to 0.01530, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.093812227249146\n",
      "Epoch 35/250\n",
      "epoch time start: 1578287647.8328507\n",
      " - 16s - loss: 0.0128 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1453 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00035: loss improved from 0.01530 to 0.01277, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.19657063484192\n",
      "Epoch 36/250\n",
      "epoch time start: 1578287664.0295744\n",
      " - 16s - loss: 0.0101 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1439 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00036: loss improved from 0.01277 to 0.01009, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.282090425491333\n",
      "Epoch 37/250\n",
      "epoch time start: 1578287680.3118308\n",
      " - 16s - loss: 0.0092 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1408 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00037: loss improved from 0.01009 to 0.00915, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.095375537872314\n",
      "Epoch 38/250\n",
      "epoch time start: 1578287696.4073303\n",
      " - 16s - loss: 0.0096 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1364 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00038: loss did not improve\n",
      "epoch time measured: 16.239494800567627\n",
      "Epoch 39/250\n",
      "epoch time start: 1578287712.6471958\n",
      " - 16s - loss: 0.0077 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1288 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00039: loss improved from 0.00915 to 0.00766, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.257131338119507\n",
      "Epoch 40/250\n",
      "epoch time start: 1578287728.904503\n",
      " - 16s - loss: 0.0072 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1232 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00040: loss improved from 0.00766 to 0.00717, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.142436981201172\n",
      "Epoch 41/250\n",
      "epoch time start: 1578287745.0470772\n",
      " - 16s - loss: 0.0056 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1199 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00041: loss improved from 0.00717 to 0.00556, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.240867614746094\n",
      "Epoch 42/250\n",
      "epoch time start: 1578287761.2880838\n",
      " - 16s - loss: 0.0057 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1174 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00042: loss did not improve\n",
      "epoch time measured: 16.185784101486206\n",
      "Epoch 43/250\n",
      "epoch time start: 1578287777.4739838\n",
      " - 16s - loss: 0.0038 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1153 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00043: loss improved from 0.00556 to 0.00378, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.14249038696289\n",
      "Epoch 44/250\n",
      "epoch time start: 1578287793.6166356\n",
      " - 16s - loss: 0.0041 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1138 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00044: loss did not improve\n",
      "epoch time measured: 16.051718711853027\n",
      "Epoch 45/250\n",
      "epoch time start: 1578287809.6684623\n",
      " - 16s - loss: 0.0030 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1119 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00045: loss improved from 0.00378 to 0.00298, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.175584077835083\n",
      "Epoch 46/250\n",
      "epoch time start: 1578287825.844181\n",
      " - 16s - loss: 0.0029 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1079 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00046: loss improved from 0.00298 to 0.00290, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.304434061050415\n",
      "Epoch 47/250\n",
      "epoch time start: 1578287842.1487782\n",
      " - 16s - loss: 0.0027 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1040 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00047: loss improved from 0.00290 to 0.00268, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.127250909805298\n",
      "Epoch 48/250\n",
      "epoch time start: 1578287858.2764661\n",
      " - 16s - loss: 0.0023 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1003 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00048: loss improved from 0.00268 to 0.00230, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.193852186203003\n",
      "Epoch 49/250\n",
      "epoch time start: 1578287874.470451\n",
      " - 16s - loss: 0.0025 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0974 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00049: loss did not improve\n",
      "epoch time measured: 16.049745082855225\n",
      "Epoch 50/250\n",
      "epoch time start: 1578287890.5203156\n",
      " - 16s - loss: 0.0018 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0950 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00050: loss improved from 0.00230 to 0.00185, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.125993728637695\n",
      "Epoch 51/250\n",
      "epoch time start: 1578287906.64647\n",
      " - 16s - loss: 0.0016 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0929 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00051: loss improved from 0.00185 to 0.00163, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.12132716178894\n",
      "Epoch 52/250\n",
      "epoch time start: 1578287922.7679405\n",
      " - 16s - loss: 0.0017 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0910 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00052: loss did not improve\n",
      "epoch time measured: 16.13459014892578\n",
      "Epoch 53/250\n",
      "epoch time start: 1578287938.9026732\n",
      " - 16s - loss: 0.0016 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0893 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00053: loss improved from 0.00163 to 0.00160, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.23422861099243\n",
      "Epoch 54/250\n",
      "epoch time start: 1578287955.1370566\n",
      " - 16s - loss: 0.0015 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0874 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00054: loss improved from 0.00160 to 0.00148, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.140848636627197\n",
      "Epoch 55/250\n",
      "epoch time start: 1578287971.2780492\n",
      " - 16s - loss: 0.0015 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0855 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00055: loss did not improve\n",
      "epoch time measured: 16.10645890235901\n",
      "Epoch 56/250\n",
      "epoch time start: 1578287987.3846266\n",
      " - 16s - loss: 0.0015 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0822 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00056: loss did not improve\n",
      "epoch time measured: 16.310969591140747\n",
      "Epoch 57/250\n",
      "epoch time start: 1578288003.6958625\n",
      " - 16s - loss: 0.0010 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0787 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00057: loss improved from 0.00148 to 0.00103, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.233311653137207\n",
      "Epoch 58/250\n",
      "epoch time start: 1578288019.9293084\n",
      " - 16s - loss: 0.0014 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0759 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00058: loss did not improve\n",
      "epoch time measured: 16.174798488616943\n",
      "Epoch 59/250\n",
      "epoch time start: 1578288036.1043878\n",
      " - 16s - loss: 0.0013 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0742 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00059: loss did not improve\n",
      "epoch time measured: 16.17667865753174\n",
      "Epoch 60/250\n",
      "epoch time start: 1578288052.2812035\n",
      " - 16s - loss: 0.0013 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0738 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00060: loss did not improve\n",
      "epoch time measured: 16.123830318450928\n",
      "Epoch 61/250\n",
      "epoch time start: 1578288068.40514\n",
      " - 16s - loss: 0.0010 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0745 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00061: loss did not improve\n",
      "epoch time measured: 16.22402048110962\n",
      "Epoch 62/250\n",
      "epoch time start: 1578288084.6294158\n",
      " - 16s - loss: 9.5576e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0760 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00062: loss improved from 0.00103 to 0.00096, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.180139541625977\n",
      "Epoch 63/250\n",
      "epoch time start: 1578288100.8097003\n",
      " - 17s - loss: 0.0011 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0771 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00063: loss did not improve\n",
      "epoch time measured: 16.63651943206787\n",
      "Epoch 64/250\n",
      "epoch time start: 1578288117.4463482\n",
      " - 16s - loss: 0.0011 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0769 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00064: loss did not improve\n",
      "epoch time measured: 16.44262170791626\n",
      "Epoch 65/250\n",
      "epoch time start: 1578288133.8890684\n",
      " - 16s - loss: 7.7455e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0761 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00065: loss improved from 0.00096 to 0.00077, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.073230028152466\n",
      "Epoch 66/250\n",
      "epoch time start: 1578288149.9624758\n",
      " - 16s - loss: 7.7881e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0744 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00066: loss did not improve\n",
      "epoch time measured: 16.03446125984192\n",
      "Epoch 67/250\n",
      "epoch time start: 1578288165.997081\n",
      " - 16s - loss: 7.7355e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0719 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00067: loss improved from 0.00077 to 0.00077, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.05327820777893\n",
      "Epoch 68/250\n",
      "epoch time start: 1578288182.0505157\n",
      " - 16s - loss: 8.2991e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0685 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "\n",
      "Epoch 00068: loss did not improve\n",
      "epoch time measured: 16.215953826904297\n",
      "Epoch 69/250\n",
      "epoch time start: 1578288198.2665884\n",
      " - 16s - loss: 8.5916e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0645 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00069: loss did not improve\n",
      "epoch time measured: 16.23924493789673\n",
      "Epoch 70/250\n",
      "epoch time start: 1578288214.5061765\n",
      " - 16s - loss: 9.4948e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0605 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00070: loss did not improve\n",
      "epoch time measured: 16.26404619216919\n",
      "Epoch 71/250\n",
      "epoch time start: 1578288230.770466\n",
      " - 16s - loss: 8.5865e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0563 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00071: loss did not improve\n",
      "epoch time measured: 16.072813034057617\n",
      "Epoch 72/250\n",
      "epoch time start: 1578288246.8434637\n",
      " - 16s - loss: 6.7704e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0530 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00072: loss improved from 0.00077 to 0.00068, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.198320388793945\n",
      "Epoch 73/250\n",
      "epoch time start: 1578288263.041918\n",
      " - 16s - loss: 7.2405e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0502 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00073: loss did not improve\n",
      "epoch time measured: 16.115578174591064\n",
      "Epoch 74/250\n",
      "epoch time start: 1578288279.1576347\n",
      " - 16s - loss: 7.2340e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0478 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00074: loss did not improve\n",
      "epoch time measured: 16.055124521255493\n",
      "Epoch 75/250\n",
      "epoch time start: 1578288295.2128754\n",
      " - 16s - loss: 6.1473e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0458 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00075: loss improved from 0.00068 to 0.00061, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.348530530929565\n",
      "Epoch 76/250\n",
      "epoch time start: 1578288311.5615485\n",
      " - 16s - loss: 6.8466e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0443 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00076: loss did not improve\n",
      "epoch time measured: 16.09364914894104\n",
      "Epoch 77/250\n",
      "epoch time start: 1578288327.655301\n",
      " - 16s - loss: 6.9979e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0429 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00077: loss did not improve\n",
      "epoch time measured: 16.16929817199707\n",
      "Epoch 78/250\n",
      "epoch time start: 1578288343.824741\n",
      " - 16s - loss: 7.2787e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0419 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00078: loss did not improve\n",
      "epoch time measured: 16.34377884864807\n",
      "Epoch 79/250\n",
      "epoch time start: 1578288360.16879\n",
      " - 16s - loss: 6.5500e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0409 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00079: loss did not improve\n",
      "epoch time measured: 16.220422506332397\n",
      "Epoch 80/250\n",
      "epoch time start: 1578288376.389323\n",
      " - 16s - loss: 6.6903e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0401 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00080: loss did not improve\n",
      "epoch time measured: 16.25388193130493\n",
      "Epoch 81/250\n",
      "epoch time start: 1578288392.6434565\n",
      " - 16s - loss: 6.1671e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0394 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00081: loss did not improve\n",
      "epoch time measured: 16.12091827392578\n",
      "Epoch 82/250\n",
      "epoch time start: 1578288408.7644837\n",
      " - 16s - loss: 5.2266e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0389 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00082: loss improved from 0.00061 to 0.00052, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.15508794784546\n",
      "Epoch 83/250\n",
      "epoch time start: 1578288424.9196968\n",
      " - 16s - loss: 5.9268e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0384 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00083: loss did not improve\n",
      "epoch time measured: 16.04084610939026\n",
      "Epoch 84/250\n",
      "epoch time start: 1578288440.9606774\n",
      " - 16s - loss: 5.8967e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0383 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00084: loss did not improve\n",
      "epoch time measured: 16.1104154586792\n",
      "Epoch 85/250\n",
      "epoch time start: 1578288457.0711973\n",
      " - 16s - loss: 5.9207e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0379 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00085: loss did not improve\n",
      "epoch time measured: 16.085512161254883\n",
      "Epoch 86/250\n",
      "epoch time start: 1578288473.1568544\n",
      " - 16s - loss: 5.0959e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0375 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00086: loss improved from 0.00052 to 0.00051, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.272566080093384\n",
      "Epoch 87/250\n",
      "epoch time start: 1578288489.4295516\n",
      " - 16s - loss: 4.6549e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0368 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00087: loss improved from 0.00051 to 0.00047, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.02732801437378\n",
      "Epoch 88/250\n",
      "epoch time start: 1578288505.457012\n",
      " - 16s - loss: 5.3255e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0362 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00088: loss did not improve\n",
      "epoch time measured: 16.034145832061768\n",
      "Epoch 89/250\n",
      "epoch time start: 1578288521.491297\n",
      " - 16s - loss: 4.4618e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0355 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00089: loss improved from 0.00047 to 0.00045, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.049702882766724\n",
      "Epoch 90/250\n",
      "epoch time start: 1578288537.54115\n",
      " - 16s - loss: 5.4567e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0346 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00090: loss did not improve\n",
      "epoch time measured: 16.076831340789795\n",
      "Epoch 91/250\n",
      "epoch time start: 1578288553.6181128\n",
      " - 16s - loss: 5.1899e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0337 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00091: loss did not improve\n",
      "epoch time measured: 16.033105850219727\n",
      "Epoch 92/250\n",
      "epoch time start: 1578288569.6513116\n",
      " - 16s - loss: 5.4613e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0327 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00092: loss did not improve\n",
      "epoch time measured: 16.064836502075195\n",
      "Epoch 93/250\n",
      "epoch time start: 1578288585.7162979\n",
      " - 16s - loss: 4.7617e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0316 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00093: loss did not improve\n",
      "epoch time measured: 16.15190100669861\n",
      "Epoch 94/250\n",
      "epoch time start: 1578288601.8683357\n",
      " - 16s - loss: 4.2505e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0305 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00094: loss improved from 0.00045 to 0.00043, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.116597652435303\n",
      "Epoch 95/250\n",
      "epoch time start: 1578288617.9850912\n",
      " - 16s - loss: 4.9040e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0297 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00095: loss did not improve\n",
      "epoch time measured: 16.116098165512085\n",
      "Epoch 96/250\n",
      "epoch time start: 1578288634.1013336\n",
      " - 16s - loss: 4.5842e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0287 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00096: loss did not improve\n",
      "epoch time measured: 16.109683752059937\n",
      "Epoch 97/250\n",
      "epoch time start: 1578288650.2111373\n",
      " - 16s - loss: 3.8296e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0280 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00097: loss improved from 0.00043 to 0.00038, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.23479199409485\n",
      "Epoch 98/250\n",
      "epoch time start: 1578288666.4460726\n",
      " - 16s - loss: 4.3177e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0275 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00098: loss did not improve\n",
      "epoch time measured: 16.167481184005737\n",
      "Epoch 99/250\n",
      "epoch time start: 1578288682.6136613\n",
      " - 16s - loss: 4.5410e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0272 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00099: loss did not improve\n",
      "epoch time measured: 16.232261180877686\n",
      "Epoch 100/250\n",
      "epoch time start: 1578288698.8460329\n",
      " - 16s - loss: 4.4972e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0270 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00100: loss did not improve\n",
      "epoch time measured: 16.180153131484985\n",
      "Epoch 101/250\n",
      "epoch time start: 1578288715.026298\n",
      " - 16s - loss: 4.4132e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0269 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00101: loss did not improve\n",
      "epoch time measured: 16.1593017578125\n",
      "Epoch 102/250\n",
      "epoch time start: 1578288731.185718\n",
      " - 16s - loss: 4.6289e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0270 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00102: loss did not improve\n",
      "epoch time measured: 16.188889741897583\n",
      "Epoch 103/250\n",
      "epoch time start: 1578288747.3748093\n",
      " - 16s - loss: 4.0640e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0270 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00103: loss did not improve\n",
      "epoch time measured: 16.154988765716553\n",
      "Epoch 104/250\n",
      "epoch time start: 1578288763.530077\n",
      " - 16s - loss: 3.8008e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0269 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00104: loss improved from 0.00038 to 0.00038, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.176658391952515\n",
      "Epoch 105/250\n",
      "epoch time start: 1578288779.7068806\n",
      " - 16s - loss: 3.8272e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0264 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00105: loss did not improve\n",
      "epoch time measured: 16.262545347213745\n",
      "Epoch 106/250\n",
      "epoch time start: 1578288795.969533\n",
      " - 16s - loss: 4.4969e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0259 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00106: loss did not improve\n",
      "epoch time measured: 16.351080417633057\n",
      "Epoch 107/250\n",
      "epoch time start: 1578288812.3207514\n",
      " - 16s - loss: 4.0705e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0254 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00107: loss did not improve\n",
      "epoch time measured: 16.17706847190857\n",
      "Epoch 108/250\n",
      "epoch time start: 1578288828.4980538\n",
      " - 17s - loss: 3.6162e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0249 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00108: loss improved from 0.00038 to 0.00036, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.77977418899536\n",
      "Epoch 109/250\n",
      "epoch time start: 1578288845.2779794\n",
      " - 16s - loss: 4.2656e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0245 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00109: loss did not improve\n",
      "epoch time measured: 16.00446844100952\n",
      "Epoch 110/250\n",
      "epoch time start: 1578288861.2825592\n",
      " - 16s - loss: 3.5267e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0240 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00110: loss improved from 0.00036 to 0.00035, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.13325786590576\n",
      "Epoch 111/250\n",
      "epoch time start: 1578288877.4159603\n",
      " - 16s - loss: 4.0216e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0235 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00111: loss did not improve\n",
      "epoch time measured: 16.149360179901123\n",
      "Epoch 112/250\n",
      "epoch time start: 1578288893.5655792\n",
      " - 16s - loss: 3.9833e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0232 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00112: loss did not improve\n",
      "epoch time measured: 16.165053844451904\n",
      "Epoch 113/250\n",
      "epoch time start: 1578288909.7307365\n",
      " - 16s - loss: 3.1628e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0229 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00113: loss improved from 0.00035 to 0.00032, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.13022780418396\n",
      "Epoch 114/250\n",
      "epoch time start: 1578288925.8615143\n",
      " - 16s - loss: 3.9360e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0226 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00114: loss did not improve\n",
      "epoch time measured: 16.172195434570312\n",
      "Epoch 115/250\n",
      "epoch time start: 1578288942.0338302\n",
      " - 16s - loss: 3.4800e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0223 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00115: loss did not improve\n",
      "epoch time measured: 16.16398000717163\n",
      "Epoch 116/250\n",
      "epoch time start: 1578288958.197922\n",
      " - 16s - loss: 3.5216e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0221 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00116: loss did not improve\n",
      "epoch time measured: 16.09999680519104\n",
      "Epoch 117/250\n",
      "epoch time start: 1578288974.2980351\n",
      " - 16s - loss: 3.4833e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0219 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00117: loss did not improve\n",
      "epoch time measured: 16.126456022262573\n",
      "Epoch 118/250\n",
      "epoch time start: 1578288990.4246023\n",
      " - 16s - loss: 3.3682e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0217 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00118: loss did not improve\n",
      "epoch time measured: 16.04163408279419\n",
      "Epoch 119/250\n",
      "epoch time start: 1578289006.4663446\n",
      " - 16s - loss: 3.0993e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0216 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00119: loss improved from 0.00032 to 0.00031, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.026254653930664\n",
      "Epoch 120/250\n",
      "epoch time start: 1578289022.4927793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 16s - loss: 3.1055e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0216 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00120: loss did not improve\n",
      "epoch time measured: 16.01005983352661\n",
      "Epoch 121/250\n",
      "epoch time start: 1578289038.5029447\n",
      " - 16s - loss: 3.3156e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0217 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00121: loss did not improve\n",
      "epoch time measured: 16.10410213470459\n",
      "Epoch 122/250\n",
      "epoch time start: 1578289054.6071522\n",
      " - 16s - loss: 3.4343e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0218 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00122: loss did not improve\n",
      "epoch time measured: 16.026002883911133\n",
      "Epoch 123/250\n",
      "epoch time start: 1578289070.633277\n",
      " - 16s - loss: 3.0146e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0221 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00123: loss improved from 0.00031 to 0.00030, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.241321086883545\n",
      "Epoch 124/250\n",
      "epoch time start: 1578289086.874719\n",
      " - 16s - loss: 3.6618e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0224 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00124: loss did not improve\n",
      "epoch time measured: 16.32858967781067\n",
      "Epoch 125/250\n",
      "epoch time start: 1578289103.2035654\n",
      " - 16s - loss: 3.0160e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0224 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00125: loss did not improve\n",
      "epoch time measured: 16.135401725769043\n",
      "Epoch 126/250\n",
      "epoch time start: 1578289119.3391132\n",
      " - 16s - loss: 2.7722e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0222 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00126: loss improved from 0.00030 to 0.00028, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.284523248672485\n",
      "Epoch 127/250\n",
      "epoch time start: 1578289135.6237571\n",
      " - 16s - loss: 3.1890e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0217 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00127: loss did not improve\n",
      "epoch time measured: 16.118109703063965\n",
      "Epoch 128/250\n",
      "epoch time start: 1578289151.7422576\n",
      " - 16s - loss: 3.0025e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0210 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00128: loss did not improve\n",
      "epoch time measured: 16.296080112457275\n",
      "Epoch 129/250\n",
      "epoch time start: 1578289168.0386581\n",
      " - 16s - loss: 2.9002e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0204 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00129: loss did not improve\n",
      "epoch time measured: 16.191354274749756\n",
      "Epoch 130/250\n",
      "epoch time start: 1578289184.2302926\n",
      " - 16s - loss: 2.6790e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0199 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00130: loss improved from 0.00028 to 0.00027, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.084938049316406\n",
      "Epoch 131/250\n",
      "epoch time start: 1578289200.3153653\n",
      " - 16s - loss: 3.0601e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0196 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00131: loss did not improve\n",
      "epoch time measured: 16.014373779296875\n",
      "Epoch 132/250\n",
      "epoch time start: 1578289216.3298593\n",
      " - 16s - loss: 3.3412e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0195 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00132: loss did not improve\n",
      "epoch time measured: 15.991825342178345\n",
      "Epoch 133/250\n",
      "epoch time start: 1578289232.321888\n",
      " - 16s - loss: 2.9387e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0195 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00133: loss did not improve\n",
      "epoch time measured: 16.02294921875\n",
      "Epoch 134/250\n",
      "epoch time start: 1578289248.3450341\n",
      " - 16s - loss: 3.0087e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0195 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00134: loss did not improve\n",
      "epoch time measured: 16.20630407333374\n",
      "Epoch 135/250\n",
      "epoch time start: 1578289264.5514565\n",
      " - 16s - loss: 3.1094e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0194 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00135: loss did not improve\n",
      "epoch time measured: 16.412212371826172\n",
      "Epoch 136/250\n",
      "epoch time start: 1578289280.9637856\n",
      " - 16s - loss: 2.8721e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0192 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00136: loss did not improve\n",
      "epoch time measured: 16.077083110809326\n",
      "Epoch 137/250\n",
      "epoch time start: 1578289297.0410006\n",
      " - 16s - loss: 3.1350e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0189 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00137: loss did not improve\n",
      "epoch time measured: 16.03342843055725\n",
      "Epoch 138/250\n",
      "epoch time start: 1578289313.0745385\n",
      " - 16s - loss: 3.0174e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0187 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00138: loss did not improve\n",
      "epoch time measured: 16.12564778327942\n",
      "Epoch 139/250\n",
      "epoch time start: 1578289329.2002957\n",
      " - 16s - loss: 2.6163e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0187 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00139: loss improved from 0.00027 to 0.00026, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.09621787071228\n",
      "Epoch 140/250\n",
      "epoch time start: 1578289345.296645\n",
      " - 17s - loss: 3.2245e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0189 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00140: loss did not improve\n",
      "epoch time measured: 16.53100323677063\n",
      "Epoch 141/250\n",
      "epoch time start: 1578289361.8277516\n",
      " - 16s - loss: 2.6006e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0193 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00141: loss improved from 0.00026 to 0.00026, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.109001874923706\n",
      "Epoch 142/250\n",
      "epoch time start: 1578289377.9369006\n",
      " - 16s - loss: 3.1096e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0198 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00142: loss did not improve\n",
      "epoch time measured: 16.26088523864746\n",
      "Epoch 143/250\n",
      "epoch time start: 1578289394.197907\n",
      " - 16s - loss: 2.6593e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0203 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00143: loss did not improve\n",
      "epoch time measured: 16.085399627685547\n",
      "Epoch 144/250\n",
      "epoch time start: 1578289410.2834074\n",
      " - 16s - loss: 2.4743e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0205 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00144: loss improved from 0.00026 to 0.00025, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.115358114242554\n",
      "Epoch 145/250\n",
      "epoch time start: 1578289426.3989\n",
      " - 17s - loss: 2.5635e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0209 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00145: loss did not improve\n",
      "epoch time measured: 16.790754795074463\n",
      "Epoch 146/250\n",
      "epoch time start: 1578289443.1897697\n",
      " - 16s - loss: 2.6726e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0212 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00146: loss did not improve\n",
      "epoch time measured: 16.039180994033813\n",
      "Epoch 147/250\n",
      "epoch time start: 1578289459.2290745\n",
      " - 16s - loss: 2.8121e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0212 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00147: loss did not improve\n",
      "epoch time measured: 16.00407123565674\n",
      "Epoch 148/250\n",
      "epoch time start: 1578289475.2332613\n",
      " - 16s - loss: 3.1148e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0206 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00148: loss did not improve\n",
      "epoch time measured: 16.069228172302246\n",
      "Epoch 149/250\n",
      "epoch time start: 1578289491.3026016\n",
      " - 16s - loss: 2.6541e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0200 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00149: loss did not improve\n",
      "epoch time measured: 16.14722990989685\n",
      "Epoch 150/250\n",
      "epoch time start: 1578289507.4499655\n",
      " - 16s - loss: 2.4193e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0194 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00150: loss improved from 0.00025 to 0.00024, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.0024197101593\n",
      "Epoch 151/250\n",
      "epoch time start: 1578289523.4525332\n",
      " - 16s - loss: 2.5251e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0187 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00151: loss did not improve\n",
      "epoch time measured: 15.99340009689331\n",
      "Epoch 152/250\n",
      "epoch time start: 1578289539.4460428\n",
      " - 16s - loss: 2.5098e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0182 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00152: loss did not improve\n",
      "epoch time measured: 16.212093353271484\n",
      "Epoch 153/250\n",
      "epoch time start: 1578289555.6584132\n",
      " - 16s - loss: 2.2766e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0179 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00153: loss improved from 0.00024 to 0.00023, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.18761372566223\n",
      "Epoch 154/250\n",
      "epoch time start: 1578289571.8464794\n",
      " - 16s - loss: 1.9795e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0176 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00154: loss improved from 0.00023 to 0.00020, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.06044030189514\n",
      "Epoch 155/250\n",
      "epoch time start: 1578289587.9070468\n",
      " - 16s - loss: 2.5268e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0173 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00155: loss did not improve\n",
      "epoch time measured: 16.233951330184937\n",
      "Epoch 156/250\n",
      "epoch time start: 1578289604.1412473\n",
      " - 16s - loss: 2.5270e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0171 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00156: loss did not improve\n",
      "epoch time measured: 16.264628171920776\n",
      "Epoch 157/250\n",
      "epoch time start: 1578289620.4059901\n",
      " - 16s - loss: 2.4861e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0170 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00157: loss did not improve\n",
      "epoch time measured: 16.273037433624268\n",
      "Epoch 158/250\n",
      "epoch time start: 1578289636.6791565\n",
      " - 16s - loss: 2.7962e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0169 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00158: loss did not improve\n",
      "epoch time measured: 16.182454347610474\n",
      "Epoch 159/250\n",
      "epoch time start: 1578289652.861727\n",
      " - 16s - loss: 1.8404e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0168 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00159: loss improved from 0.00020 to 0.00018, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.164976358413696\n",
      "Epoch 160/250\n",
      "epoch time start: 1578289669.027098\n",
      " - 16s - loss: 2.3597e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0168 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00160: loss did not improve\n",
      "epoch time measured: 16.06934642791748\n",
      "Epoch 161/250\n",
      "epoch time start: 1578289685.0965617\n",
      " - 16s - loss: 1.8762e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0167 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00161: loss did not improve\n",
      "epoch time measured: 16.122830152511597\n",
      "Epoch 162/250\n",
      "epoch time start: 1578289701.2195115\n",
      " - 16s - loss: 2.6246e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0168 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00162: loss did not improve\n",
      "epoch time measured: 16.08151865005493\n",
      "Epoch 163/250\n",
      "epoch time start: 1578289717.301139\n",
      " - 16s - loss: 2.2246e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0170 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00163: loss did not improve\n",
      "epoch time measured: 16.287955045700073\n",
      "Epoch 164/250\n",
      "epoch time start: 1578289733.5892365\n",
      " - 16s - loss: 2.5906e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0171 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00164: loss did not improve\n",
      "epoch time measured: 16.009546995162964\n",
      "Epoch 165/250\n",
      "epoch time start: 1578289749.5989063\n",
      " - 16s - loss: 2.3039e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0174 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00165: loss did not improve\n",
      "epoch time measured: 16.018035173416138\n",
      "Epoch 166/250\n",
      "epoch time start: 1578289765.6170592\n",
      " - 16s - loss: 2.2622e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0174 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00166: loss did not improve\n",
      "epoch time measured: 15.983192920684814\n",
      "Epoch 167/250\n",
      "epoch time start: 1578289781.600372\n",
      " - 16s - loss: 2.6759e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0174 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00167: loss did not improve\n",
      "epoch time measured: 16.063448429107666\n",
      "Epoch 168/250\n",
      "epoch time start: 1578289797.663924\n",
      " - 16s - loss: 2.3923e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0174 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00168: loss did not improve\n",
      "epoch time measured: 16.055675983428955\n",
      "Epoch 169/250\n",
      "epoch time start: 1578289813.719726\n",
      " - 16s - loss: 2.2517e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0175 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00169: loss did not improve\n",
      "epoch time measured: 16.08025026321411\n",
      "Epoch 170/250\n",
      "epoch time start: 1578289829.8001497\n",
      " - 16s - loss: 2.1031e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0174 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00170: loss did not improve\n",
      "epoch time measured: 16.07416272163391\n",
      "Epoch 171/250\n",
      "epoch time start: 1578289845.8744574\n",
      " - 16s - loss: 2.0057e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0176 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00171: loss did not improve\n",
      "epoch time measured: 15.997064590454102\n",
      "Epoch 172/250\n",
      "epoch time start: 1578289861.8716671\n",
      " - 16s - loss: 1.9092e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0176 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00172: loss did not improve\n",
      "epoch time measured: 16.047858715057373\n",
      "Epoch 173/250\n",
      "epoch time start: 1578289877.9196618\n",
      " - 16s - loss: 2.1282e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0176 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00173: loss did not improve\n",
      "epoch time measured: 16.12326979637146\n",
      "Epoch 174/250\n",
      "epoch time start: 1578289894.0430524\n",
      " - 16s - loss: 1.8298e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0175 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00174: loss improved from 0.00018 to 0.00018, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 15.989647150039673\n",
      "Epoch 175/250\n",
      "epoch time start: 1578289910.0328555\n",
      " - 16s - loss: 1.9080e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0174 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00175: loss did not improve\n",
      "epoch time measured: 16.340341329574585\n",
      "Epoch 176/250\n",
      "epoch time start: 1578289926.3735235\n",
      " - 16s - loss: 2.5662e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0170 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00176: loss did not improve\n",
      "epoch time measured: 16.007981061935425\n",
      "Epoch 177/250\n",
      "epoch time start: 1578289942.381624\n",
      " - 16s - loss: 2.2185e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0166 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00177: loss did not improve\n",
      "epoch time measured: 16.06340527534485\n",
      "Epoch 178/250\n",
      "epoch time start: 1578289958.4451365\n",
      " - 16s - loss: 1.9956e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0162 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00178: loss did not improve\n",
      "epoch time measured: 16.110422611236572\n",
      "Epoch 179/250\n",
      "epoch time start: 1578289974.555686\n",
      " - 16s - loss: 2.0896e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0160 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00179: loss did not improve\n",
      "epoch time measured: 16.10982394218445\n",
      "Epoch 180/250\n",
      "epoch time start: 1578289990.665615\n",
      " - 16s - loss: 2.1111e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0158 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00180: loss did not improve\n",
      "epoch time measured: 16.164218425750732\n",
      "Epoch 181/250\n",
      "epoch time start: 1578290006.8299391\n",
      " - 16s - loss: 1.7897e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0159 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00181: loss improved from 0.00018 to 0.00018, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.363749742507935\n",
      "Epoch 182/250\n",
      "epoch time start: 1578290023.1938217\n",
      " - 16s - loss: 2.1031e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0159 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00182: loss did not improve\n",
      "epoch time measured: 16.057336807250977\n",
      "Epoch 183/250\n",
      "epoch time start: 1578290039.2513614\n",
      " - 16s - loss: 2.2300e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0159 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00183: loss did not improve\n",
      "epoch time measured: 16.200700998306274\n",
      "Epoch 184/250\n",
      "epoch time start: 1578290055.4523883\n",
      " - 16s - loss: 2.0402e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0161 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00184: loss did not improve\n",
      "epoch time measured: 16.00169348716736\n",
      "Epoch 185/250\n",
      "epoch time start: 1578290071.454278\n",
      " - 16s - loss: 2.1854e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0163 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00185: loss did not improve\n",
      "epoch time measured: 16.059757709503174\n",
      "Epoch 186/250\n",
      "epoch time start: 1578290087.5141838\n",
      " - 16s - loss: 2.1962e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0165 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00186: loss did not improve\n",
      "epoch time measured: 16.08303141593933\n",
      "Epoch 187/250\n",
      "epoch time start: 1578290103.5973258\n",
      " - 16s - loss: 2.3355e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0170 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00187: loss did not improve\n",
      "epoch time measured: 16.146645307540894\n",
      "Epoch 188/250\n",
      "epoch time start: 1578290119.7440858\n",
      " - 16s - loss: 2.1625e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0172 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00188: loss did not improve\n",
      "epoch time measured: 16.00996494293213\n",
      "Epoch 189/250\n",
      "epoch time start: 1578290135.754365\n",
      " - 16s - loss: 1.7865e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0176 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00189: loss improved from 0.00018 to 0.00018, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.085086584091187\n",
      "Epoch 190/250\n",
      "epoch time start: 1578290151.8396323\n",
      " - 16s - loss: 1.9162e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0178 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00190: loss did not improve\n",
      "epoch time measured: 16.114368200302124\n",
      "Epoch 191/250\n",
      "epoch time start: 1578290167.9541328\n",
      " - 16s - loss: 1.9491e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0177 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00191: loss did not improve\n",
      "epoch time measured: 16.14847445487976\n",
      "Epoch 192/250\n",
      "epoch time start: 1578290184.1027217\n",
      " - 16s - loss: 1.8881e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0173 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00192: loss did not improve\n",
      "epoch time measured: 16.07694959640503\n",
      "Epoch 193/250\n",
      "epoch time start: 1578290200.1797838\n",
      " - 16s - loss: 1.9157e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0169 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00193: loss did not improve\n",
      "epoch time measured: 16.012474060058594\n",
      "Epoch 194/250\n",
      "epoch time start: 1578290216.192537\n",
      " - 16s - loss: 2.1360e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0165 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00194: loss did not improve\n",
      "epoch time measured: 16.136252403259277\n",
      "Epoch 195/250\n",
      "epoch time start: 1578290232.3289266\n",
      " - 16s - loss: 1.8708e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0162 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00195: loss did not improve\n",
      "epoch time measured: 16.04331684112549\n",
      "Epoch 196/250\n",
      "epoch time start: 1578290248.3723726\n",
      " - 16s - loss: 1.7136e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0160 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00196: loss improved from 0.00018 to 0.00017, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.17140507698059\n",
      "Epoch 197/250\n",
      "epoch time start: 1578290264.5439003\n",
      " - 16s - loss: 1.9964e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0158 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00197: loss did not improve\n",
      "epoch time measured: 16.054596662521362\n",
      "Epoch 198/250\n",
      "epoch time start: 1578290280.598635\n",
      " - 16s - loss: 1.6746e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0156 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00198: loss improved from 0.00017 to 0.00017, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.062152862548828\n",
      "Epoch 199/250\n",
      "epoch time start: 1578290296.6609516\n",
      " - 16s - loss: 1.5671e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0154 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00199: loss improved from 0.00017 to 0.00016, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.07534122467041\n",
      "Epoch 200/250\n",
      "epoch time start: 1578290312.736445\n",
      " - 16s - loss: 1.7695e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0153 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00200: loss did not improve\n",
      "epoch time measured: 16.27806067466736\n",
      "Epoch 201/250\n",
      "epoch time start: 1578290329.0146272\n",
      " - 16s - loss: 1.5989e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0153 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00201: loss did not improve\n",
      "epoch time measured: 16.10088872909546\n",
      "Epoch 202/250\n",
      "epoch time start: 1578290345.1156926\n",
      " - 16s - loss: 1.8780e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0155 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00202: loss did not improve\n",
      "epoch time measured: 16.088199377059937\n",
      "Epoch 203/250\n",
      "epoch time start: 1578290361.204025\n",
      " - 16s - loss: 1.7904e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0156 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00203: loss did not improve\n",
      "epoch time measured: 16.420161485671997\n",
      "Epoch 204/250\n",
      "epoch time start: 1578290377.6243038\n",
      " - 16s - loss: 1.8349e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0161 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00204: loss did not improve\n",
      "epoch time measured: 16.03717827796936\n",
      "Epoch 205/250\n",
      "epoch time start: 1578290393.6616251\n",
      " - 16s - loss: 1.6802e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0164 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00205: loss did not improve\n",
      "epoch time measured: 16.105181217193604\n",
      "Epoch 206/250\n",
      "epoch time start: 1578290409.7669356\n",
      " - 16s - loss: 1.8295e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0171 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00206: loss did not improve\n",
      "epoch time measured: 16.09752368927002\n",
      "Epoch 207/250\n",
      "epoch time start: 1578290425.864581\n",
      " - 16s - loss: 1.8866e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0175 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00207: loss did not improve\n",
      "epoch time measured: 16.29833149909973\n",
      "Epoch 208/250\n",
      "epoch time start: 1578290442.1630394\n",
      " - 16s - loss: 1.6544e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0181 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00208: loss did not improve\n",
      "epoch time measured: 16.258667469024658\n",
      "Epoch 209/250\n",
      "epoch time start: 1578290458.4218318\n",
      " - 16s - loss: 1.6939e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0188 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00209: loss did not improve\n",
      "epoch time measured: 16.0833420753479\n",
      "Epoch 210/250\n",
      "epoch time start: 1578290474.5052822\n",
      " - 16s - loss: 1.6769e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0197 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00210: loss did not improve\n",
      "epoch time measured: 16.270772457122803\n",
      "Epoch 211/250\n",
      "epoch time start: 1578290490.7761707\n",
      " - 16s - loss: 1.5741e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0204 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00211: loss did not improve\n",
      "epoch time measured: 16.276083946228027\n",
      "Epoch 212/250\n",
      "epoch time start: 1578290507.052584\n",
      " - 16s - loss: 1.6126e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0209 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00212: loss did not improve\n",
      "epoch time measured: 16.088043212890625\n",
      "Epoch 213/250\n",
      "epoch time start: 1578290523.1407304\n",
      " - 16s - loss: 1.8287e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0208 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00213: loss did not improve\n",
      "epoch time measured: 16.233091592788696\n",
      "Epoch 214/250\n",
      "epoch time start: 1578290539.374082\n",
      " - 16s - loss: 1.7230e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0204 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00214: loss did not improve\n",
      "epoch time measured: 16.153798818588257\n",
      "Epoch 215/250\n",
      "epoch time start: 1578290555.5279863\n",
      " - 16s - loss: 1.8651e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0194 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00215: loss did not improve\n",
      "epoch time measured: 16.168264150619507\n",
      "Epoch 216/250\n",
      "epoch time start: 1578290571.6963568\n",
      " - 16s - loss: 1.5494e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0183 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00216: loss improved from 0.00016 to 0.00015, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.220534563064575\n",
      "Epoch 217/250\n",
      "epoch time start: 1578290587.9170125\n",
      " - 16s - loss: 1.5197e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0174 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00217: loss improved from 0.00015 to 0.00015, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.113950967788696\n",
      "Epoch 218/250\n",
      "epoch time start: 1578290604.0311089\n",
      " - 16s - loss: 1.5312e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0165 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00218: loss did not improve\n",
      "epoch time measured: 16.113112211227417\n",
      "Epoch 219/250\n",
      "epoch time start: 1578290620.1444857\n",
      " - 16s - loss: 1.7406e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0157 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00219: loss did not improve\n",
      "epoch time measured: 16.033483266830444\n",
      "Epoch 220/250\n",
      "epoch time start: 1578290636.1781192\n",
      " - 16s - loss: 1.7388e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0152 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00220: loss did not improve\n",
      "epoch time measured: 16.112586736679077\n",
      "Epoch 221/250\n",
      "epoch time start: 1578290652.290834\n",
      " - 16s - loss: 1.8126e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0148 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00221: loss did not improve\n",
      "epoch time measured: 16.06287670135498\n",
      "Epoch 222/250\n",
      "epoch time start: 1578290668.3539407\n",
      " - 16s - loss: 1.5262e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0146 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00222: loss did not improve\n",
      "epoch time measured: 16.27842378616333\n",
      "Epoch 223/250\n",
      "epoch time start: 1578290684.6324937\n",
      " - 16s - loss: 1.5024e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0143 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00223: loss improved from 0.00015 to 0.00015, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.05065631866455\n",
      "Epoch 224/250\n",
      "epoch time start: 1578290700.683326\n",
      " - 16s - loss: 1.7047e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0142 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00224: loss did not improve\n",
      "epoch time measured: 16.13284158706665\n",
      "Epoch 225/250\n",
      "epoch time start: 1578290716.816274\n",
      " - 16s - loss: 1.5648e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0143 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00225: loss did not improve\n",
      "epoch time measured: 16.215627670288086\n",
      "Epoch 226/250\n",
      "epoch time start: 1578290733.0322275\n",
      " - 17s - loss: 1.3805e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0144 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00226: loss improved from 0.00015 to 0.00014, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.59252619743347\n",
      "Epoch 227/250\n",
      "epoch time start: 1578290749.624907\n",
      " - 16s - loss: 1.6579e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0146 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00227: loss did not improve\n",
      "epoch time measured: 16.04709792137146\n",
      "Epoch 228/250\n",
      "epoch time start: 1578290765.6721206\n",
      " - 16s - loss: 1.3574e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0148 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00228: loss improved from 0.00014 to 0.00014, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.13147807121277\n",
      "Epoch 229/250\n",
      "epoch time start: 1578290781.8038566\n",
      " - 16s - loss: 1.4794e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0151 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00229: loss did not improve\n",
      "epoch time measured: 16.2897891998291\n",
      "Epoch 230/250\n",
      "epoch time start: 1578290798.0939276\n",
      " - 16s - loss: 1.4807e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0155 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00230: loss did not improve\n",
      "epoch time measured: 16.149678707122803\n",
      "Epoch 231/250\n",
      "epoch time start: 1578290814.2440453\n",
      " - 16s - loss: 1.8545e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0159 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00231: loss did not improve\n",
      "epoch time measured: 16.045605421066284\n",
      "Epoch 232/250\n",
      "epoch time start: 1578290830.289802\n",
      " - 16s - loss: 1.4652e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0165 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00232: loss did not improve\n",
      "epoch time measured: 16.053762435913086\n",
      "Epoch 233/250\n",
      "epoch time start: 1578290846.343696\n",
      " - 16s - loss: 1.7024e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0168 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00233: loss did not improve\n",
      "epoch time measured: 16.05893111228943\n",
      "Epoch 234/250\n",
      "epoch time start: 1578290862.4027503\n",
      " - 16s - loss: 1.5132e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0170 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00234: loss did not improve\n",
      "epoch time measured: 16.032978296279907\n",
      "Epoch 235/250\n",
      "epoch time start: 1578290878.4358726\n",
      " - 16s - loss: 1.5409e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0171 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00235: loss did not improve\n",
      "epoch time measured: 16.146723747253418\n",
      "Epoch 236/250\n",
      "epoch time start: 1578290894.5827787\n",
      " - 16s - loss: 1.3729e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0173 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00236: loss did not improve\n",
      "epoch time measured: 16.12416124343872\n",
      "Epoch 237/250\n",
      "epoch time start: 1578290910.707059\n",
      " - 16s - loss: 1.4995e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0170 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00237: loss did not improve\n",
      "epoch time measured: 16.016916513442993\n",
      "Epoch 238/250\n",
      "epoch time start: 1578290926.7240875\n",
      " - 16s - loss: 1.4649e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0165 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00238: loss did not improve\n",
      "epoch time measured: 16.04261350631714\n",
      "Epoch 239/250\n",
      "epoch time start: 1578290942.7668355\n",
      " - 16s - loss: 1.3160e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0161 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00239: loss improved from 0.00014 to 0.00013, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.100348711013794\n",
      "Epoch 240/250\n",
      "epoch time start: 1578290958.867333\n",
      " - 16s - loss: 1.4884e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0158 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00240: loss did not improve\n",
      "epoch time measured: 16.00179433822632\n",
      "Epoch 241/250\n",
      "epoch time start: 1578290974.8692513\n",
      " - 16s - loss: 1.1353e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0155 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00241: loss improved from 0.00013 to 0.00011, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.272220134735107\n",
      "Epoch 242/250\n",
      "epoch time start: 1578290991.1416287\n",
      " - 17s - loss: 1.5523e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0151 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00242: loss did not improve\n",
      "epoch time measured: 16.776297092437744\n",
      "Epoch 243/250\n",
      "epoch time start: 1578291007.9180558\n",
      " - 16s - loss: 1.6030e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0146 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00243: loss did not improve\n",
      "epoch time measured: 16.2355899810791\n",
      "Epoch 244/250\n",
      "epoch time start: 1578291024.153738\n",
      " - 16s - loss: 1.3326e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0141 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00244: loss did not improve\n",
      "epoch time measured: 16.23955774307251\n",
      "Epoch 245/250\n",
      "epoch time start: 1578291040.3933802\n",
      " - 16s - loss: 1.3595e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0136 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00245: loss did not improve\n",
      "epoch time measured: 16.08852744102478\n",
      "Epoch 246/250\n",
      "epoch time start: 1578291056.482022\n",
      " - 16s - loss: 1.4329e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0132 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00246: loss did not improve\n",
      "epoch time measured: 16.081035614013672\n",
      "Epoch 247/250\n",
      "epoch time start: 1578291072.5636299\n",
      " - 17s - loss: 1.4404e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0128 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00247: loss did not improve\n",
      "epoch time measured: 16.573350429534912\n",
      "Epoch 248/250\n",
      "epoch time start: 1578291089.1371064\n",
      " - 16s - loss: 1.2004e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0126 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00248: loss did not improve\n",
      "epoch time measured: 15.927029609680176\n",
      "Epoch 249/250\n",
      "epoch time start: 1578291105.06442\n",
      " - 16s - loss: 1.2393e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0125 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00249: loss did not improve\n",
      "epoch time measured: 16.034034252166748\n",
      "Epoch 250/250\n",
      "epoch time start: 1578291121.098556\n",
      " - 17s - loss: 1.3592e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0126 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "\n",
      "Epoch 00250: loss did not improve\n",
      "epoch time measured: 16.61437439918518\n",
      "type(totalTrainingTime): <class 'numpy.float64'>\n",
      "type(convergenceEpochs): <class 'str'>\n",
      "Loading train / test dataset :  ../data/eeg_schizo_1/ ../data/eeg_schizo_1/\n",
      "x_train_path: ../data/eeg_schizo_1/X_train.npy\n",
      "Finished processing train dataset..\n",
      "Finished loading test dataset..\n",
      "\n",
      "Number of train samples :  62 Number of test samples :  17\n",
      "Number of classes :  2\n",
      "Sequence length :  7680\n",
      "y_true - 1 Tensor(\"metrics_2/tn_m/sub:0\", shape=(?, ?), dtype=float32)\n",
      "\n",
      "Evaluating : \n",
      "17/17 [==============================] - 2s 110ms/step\n",
      "predictions: [ True  True False False  True  True  True False False  True  True False\n",
      " False False False False  True]\n",
      "truelabels: [ True  True False False  True  True  True False False  True  True False\n",
      " False False False False  True]\n",
      "TP: 8\n",
      "TN: 9\n",
      "FP: 0\n",
      "FN: 0\n",
      "\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    with open(resultsFilename, \"a\") as text_file:\n",
    "        print(f\"Current Fold: 0\", file=text_file)\n",
    "    model = generate_model_2()\n",
    "    train_model(model, DATASET_INDEX_0, dataset_prefix='eeg2_attention', epochs=n_epochs, batch_size=128)\n",
    "    evaluate_model(model, DATASET_INDEX_0, dataset_prefix='eeg2_attention', batch_size=128)\n",
    "    with open(resultsFilename, \"a\") as text_file:\n",
    "        print(f\"Current Fold: 1\", file=text_file)\n",
    "    model = generate_model_2()\n",
    "    train_model(model, DATASET_INDEX_1, dataset_prefix='eeg2_attention', epochs=n_epochs, batch_size=128)\n",
    "    evaluate_model(model, DATASET_INDEX_1, dataset_prefix='eeg2_attention', batch_size=128)\n",
    "    with open(resultsFilename, \"a\") as text_file:\n",
    "        print(f\"Current Fold: 2\", file=text_file)\n",
    "    model = generate_model_2()\n",
    "    train_model(model, DATASET_INDEX_2, dataset_prefix='eeg2_attention', epochs=n_epochs, batch_size=128)\n",
    "    evaluate_model(model, DATASET_INDEX_2, dataset_prefix='eeg2_attention', batch_size=128)\n",
    "    with open(resultsFilename, \"a\") as text_file:\n",
    "        print(f\"Current Fold: 3\", file=text_file)\n",
    "    model = generate_model_2()\n",
    "    train_model(model, DATASET_INDEX_3, dataset_prefix='eeg2_attention', epochs=n_epochs, batch_size=128)\n",
    "    evaluate_model(model, DATASET_INDEX_3, dataset_prefix='eeg2_attention', batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16, 7680)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 7680, 16)     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 7680, 128)    16512       permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 7680, 128)    512         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 7680, 128)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 128)       0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 8)         1024        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 128)       1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 7680, 128)    0           activation_1[0][0]               \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 7680, 256)    164096      multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 7680, 256)    1024        conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 7680, 256)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 256)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 256)       0           global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 16)        4096        reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1, 256)       4096        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 7680, 256)    0           activation_2[0][0]               \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 7680, 128)    98432       multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 16, 7680)     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 7680, 128)    512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_lstm_1 (AttentionLSTM (None, 8)            553328      masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 7680, 128)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 8)            0           attention_lstm_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 128)          0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 136)          0           dropout_1[0][0]                  \n",
      "                                                                 global_average_pooling1d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            274         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 844,930\n",
      "Trainable params: 843,906\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "Loading train / test dataset :  ../data/eeg_schizo_0/ ../data/eeg_schizo_0/\n",
      "x_train_path: ../data/eeg_schizo_0/X_train.npy\n",
      "Finished processing train dataset..\n",
      "Finished loading test dataset..\n",
      "\n",
      "Number of train samples :  62 Number of test samples :  17\n",
      "Number of classes :  2\n",
      "Sequence length :  7680\n",
      "Class weights :  [1. 1.]\n",
      "y_true - 1 Tensor(\"metrics/tn_m/sub:0\", shape=(?, ?), dtype=float32)\n",
      "Train on 62 samples, validate on 17 samples\n",
      "epoch time start: 1578261797.7823951\n",
      "Epoch 1/250\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.74914, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.79479193687439\n",
      " - 18s - loss: 0.7491 - acc: 0.4839 - f1_m: 0.4839 - precision_m: 0.4839 - recall_m: 0.4839 - tp_m: 30.0000 - fp_m: 32.0000 - tn_m: 30.0000 - fn_m: 32.0000 - val_loss: 0.8777 - val_acc: 0.5294 - val_f1_m: 0.5294 - val_precision_m: 0.5294 - val_recall_m: 0.5294 - val_tp_m: 9.0000 - val_fp_m: 8.0000 - val_tn_m: 9.0000 - val_fn_m: 8.0000\n",
      "epoch time start: 1578261815.5785768\n",
      "Epoch 2/250\n",
      "\n",
      "Epoch 00002: loss improved from 0.74914 to 0.62868, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 16.236354112625122\n",
      " - 16s - loss: 0.6287 - acc: 0.6774 - f1_m: 0.6774 - precision_m: 0.6774 - recall_m: 0.6774 - tp_m: 42.0000 - fp_m: 20.0000 - tn_m: 42.0000 - fn_m: 20.0000 - val_loss: 0.6004 - val_acc: 0.7059 - val_f1_m: 0.7059 - val_precision_m: 0.7059 - val_recall_m: 0.7059 - val_tp_m: 12.0000 - val_fp_m: 5.0000 - val_tn_m: 12.0000 - val_fn_m: 5.0000\n",
      "epoch time start: 1578261831.815895\n",
      "Epoch 3/250\n",
      "\n",
      "Epoch 00003: loss improved from 0.62868 to 0.48634, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.43103790283203\n",
      " - 17s - loss: 0.4863 - acc: 0.7742 - f1_m: 0.7742 - precision_m: 0.7742 - recall_m: 0.7742 - tp_m: 48.0000 - fp_m: 14.0000 - tn_m: 48.0000 - fn_m: 14.0000 - val_loss: 0.7725 - val_acc: 0.4706 - val_f1_m: 0.4706 - val_precision_m: 0.4706 - val_recall_m: 0.4706 - val_tp_m: 8.0000 - val_fp_m: 9.0000 - val_tn_m: 8.0000 - val_fn_m: 9.0000\n",
      "epoch time start: 1578261849.2490082\n",
      "Epoch 4/250\n",
      "\n",
      "Epoch 00004: loss improved from 0.48634 to 0.45860, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.635684967041016\n",
      " - 18s - loss: 0.4586 - acc: 0.8065 - f1_m: 0.8065 - precision_m: 0.8065 - recall_m: 0.8065 - tp_m: 50.0000 - fp_m: 12.0000 - tn_m: 50.0000 - fn_m: 12.0000 - val_loss: 0.7846 - val_acc: 0.4706 - val_f1_m: 0.4706 - val_precision_m: 0.4706 - val_recall_m: 0.4706 - val_tp_m: 8.0000 - val_fp_m: 9.0000 - val_tn_m: 8.0000 - val_fn_m: 9.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578261866.8861992\n",
      "Epoch 5/250\n",
      "\n",
      "Epoch 00005: loss improved from 0.45860 to 0.45542, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.539481163024902\n",
      " - 18s - loss: 0.4554 - acc: 0.7742 - f1_m: 0.7742 - precision_m: 0.7742 - recall_m: 0.7742 - tp_m: 48.0000 - fp_m: 14.0000 - tn_m: 48.0000 - fn_m: 14.0000 - val_loss: 0.5851 - val_acc: 0.5294 - val_f1_m: 0.5294 - val_precision_m: 0.5294 - val_recall_m: 0.5294 - val_tp_m: 9.0000 - val_fp_m: 8.0000 - val_tn_m: 9.0000 - val_fn_m: 8.0000\n",
      "epoch time start: 1578261884.4271972\n",
      "Epoch 6/250\n",
      "\n",
      "Epoch 00006: loss improved from 0.45542 to 0.38435, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 18.56748366355896\n",
      " - 19s - loss: 0.3844 - acc: 0.8548 - f1_m: 0.8548 - precision_m: 0.8548 - recall_m: 0.8548 - tp_m: 53.0000 - fp_m: 9.0000 - tn_m: 53.0000 - fn_m: 9.0000 - val_loss: 0.4296 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578261902.9968596\n",
      "Epoch 7/250\n",
      "\n",
      "Epoch 00007: loss improved from 0.38435 to 0.34208, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 18.11104965209961\n",
      " - 18s - loss: 0.3421 - acc: 0.8871 - f1_m: 0.8871 - precision_m: 0.8871 - recall_m: 0.8871 - tp_m: 55.0000 - fp_m: 7.0000 - tn_m: 55.0000 - fn_m: 7.0000 - val_loss: 0.4029 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578261921.1106563\n",
      "Epoch 8/250\n",
      "\n",
      "Epoch 00008: loss improved from 0.34208 to 0.32818, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.605018854141235\n",
      " - 18s - loss: 0.3282 - acc: 0.9355 - f1_m: 0.9355 - precision_m: 0.9355 - recall_m: 0.9355 - tp_m: 58.0000 - fp_m: 4.0000 - tn_m: 58.0000 - fn_m: 4.0000 - val_loss: 0.4012 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578261938.7170284\n",
      "Epoch 9/250\n",
      "\n",
      "Epoch 00009: loss improved from 0.32818 to 0.29867, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.701524257659912\n",
      " - 18s - loss: 0.2987 - acc: 0.9194 - f1_m: 0.9194 - precision_m: 0.9194 - recall_m: 0.9194 - tp_m: 57.0000 - fp_m: 5.0000 - tn_m: 57.0000 - fn_m: 5.0000 - val_loss: 0.5299 - val_acc: 0.6471 - val_f1_m: 0.6471 - val_precision_m: 0.6471 - val_recall_m: 0.6471 - val_tp_m: 11.0000 - val_fp_m: 6.0000 - val_tn_m: 11.0000 - val_fn_m: 6.0000\n",
      "epoch time start: 1578261956.4199479\n",
      "Epoch 10/250\n",
      "\n",
      "Epoch 00010: loss improved from 0.29867 to 0.27011, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.563422203063965\n",
      " - 18s - loss: 0.2701 - acc: 0.9194 - f1_m: 0.9194 - precision_m: 0.9194 - recall_m: 0.9194 - tp_m: 57.0000 - fp_m: 5.0000 - tn_m: 57.0000 - fn_m: 5.0000 - val_loss: 0.9237 - val_acc: 0.4706 - val_f1_m: 0.4706 - val_precision_m: 0.4706 - val_recall_m: 0.4706 - val_tp_m: 8.0000 - val_fp_m: 9.0000 - val_tn_m: 8.0000 - val_fn_m: 9.0000\n",
      "epoch time start: 1578261973.984395\n",
      "Epoch 11/250\n",
      "\n",
      "Epoch 00011: loss improved from 0.27011 to 0.26824, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.87804341316223\n",
      " - 18s - loss: 0.2682 - acc: 0.9516 - f1_m: 0.9516 - precision_m: 0.9516 - recall_m: 0.9516 - tp_m: 59.0000 - fp_m: 3.0000 - tn_m: 59.0000 - fn_m: 3.0000 - val_loss: 1.2536 - val_acc: 0.4706 - val_f1_m: 0.4706 - val_precision_m: 0.4706 - val_recall_m: 0.4706 - val_tp_m: 8.0000 - val_fp_m: 9.0000 - val_tn_m: 8.0000 - val_fn_m: 9.0000\n",
      "epoch time start: 1578261991.8641622\n",
      "Epoch 12/250\n",
      "\n",
      "Epoch 00012: loss improved from 0.26824 to 0.23479, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.545127153396606\n",
      " - 18s - loss: 0.2348 - acc: 0.9355 - f1_m: 0.9355 - precision_m: 0.9355 - recall_m: 0.9355 - tp_m: 58.0000 - fp_m: 4.0000 - tn_m: 58.0000 - fn_m: 4.0000 - val_loss: 1.3487 - val_acc: 0.4706 - val_f1_m: 0.4706 - val_precision_m: 0.4706 - val_recall_m: 0.4706 - val_tp_m: 8.0000 - val_fp_m: 9.0000 - val_tn_m: 8.0000 - val_fn_m: 9.0000\n",
      "epoch time start: 1578262009.4105053\n",
      "Epoch 13/250\n",
      "\n",
      "Epoch 00013: loss improved from 0.23479 to 0.21868, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 18.089350938796997\n",
      " - 18s - loss: 0.2187 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - tp_m: 61.0000 - fp_m: 1.0000 - tn_m: 61.0000 - fn_m: 1.0000 - val_loss: 1.1195 - val_acc: 0.5294 - val_f1_m: 0.5294 - val_precision_m: 0.5294 - val_recall_m: 0.5294 - val_tp_m: 9.0000 - val_fp_m: 8.0000 - val_tn_m: 9.0000 - val_fn_m: 8.0000\n",
      "epoch time start: 1578262027.5016563\n",
      "Epoch 14/250\n",
      "\n",
      "Epoch 00014: loss improved from 0.21868 to 0.18829, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.748669862747192\n",
      " - 18s - loss: 0.1883 - acc: 0.9516 - f1_m: 0.9516 - precision_m: 0.9516 - recall_m: 0.9516 - tp_m: 59.0000 - fp_m: 3.0000 - tn_m: 59.0000 - fn_m: 3.0000 - val_loss: 0.6699 - val_acc: 0.5882 - val_f1_m: 0.5882 - val_precision_m: 0.5882 - val_recall_m: 0.5882 - val_tp_m: 10.0000 - val_fp_m: 7.0000 - val_tn_m: 10.0000 - val_fn_m: 7.0000\n",
      "epoch time start: 1578262045.252041\n",
      "Epoch 15/250\n",
      "\n",
      "Epoch 00015: loss improved from 0.18829 to 0.16894, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.64600133895874\n",
      " - 18s - loss: 0.1689 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3701 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578262062.8994355\n",
      "Epoch 16/250\n",
      "\n",
      "Epoch 00016: loss did not improve\n",
      "epoch time measured: 17.824557065963745\n",
      " - 18s - loss: 0.1731 - acc: 0.9516 - f1_m: 0.9516 - precision_m: 0.9516 - recall_m: 0.9516 - tp_m: 59.0000 - fp_m: 3.0000 - tn_m: 59.0000 - fn_m: 3.0000 - val_loss: 0.3227 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578262080.7250826\n",
      "Epoch 17/250\n",
      "\n",
      "Epoch 00017: loss improved from 0.16894 to 0.14089, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.485193014144897\n",
      " - 17s - loss: 0.1409 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - tp_m: 61.0000 - fp_m: 1.0000 - tn_m: 61.0000 - fn_m: 1.0000 - val_loss: 0.3968 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262098.211506\n",
      "Epoch 18/250\n",
      "\n",
      "Epoch 00018: loss improved from 0.14089 to 0.13560, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.96759581565857\n",
      " - 18s - loss: 0.1356 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - tp_m: 61.0000 - fp_m: 1.0000 - tn_m: 61.0000 - fn_m: 1.0000 - val_loss: 0.5479 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262116.181092\n",
      "Epoch 19/250\n",
      "\n",
      "Epoch 00019: loss improved from 0.13560 to 0.11339, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.60753107070923\n",
      " - 18s - loss: 0.1134 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.5692 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262133.789855\n",
      "Epoch 20/250\n",
      "\n",
      "Epoch 00020: loss did not improve\n",
      "epoch time measured: 17.436211824417114\n",
      " - 17s - loss: 0.1198 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.5469 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578262151.2273283\n",
      "Epoch 21/250\n",
      "\n",
      "Epoch 00021: loss improved from 0.11339 to 0.10737, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.382821321487427\n",
      " - 17s - loss: 0.1074 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - tp_m: 61.0000 - fp_m: 1.0000 - tn_m: 61.0000 - fn_m: 1.0000 - val_loss: 0.4459 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262168.6119695\n",
      "Epoch 22/250\n",
      "\n",
      "Epoch 00022: loss improved from 0.10737 to 0.09196, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.490198612213135\n",
      " - 17s - loss: 0.0920 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3652 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262186.1033838\n",
      "Epoch 23/250\n",
      "\n",
      "Epoch 00023: loss improved from 0.09196 to 0.07583, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.80772376060486\n",
      " - 18s - loss: 0.0758 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3043 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578262203.9125097\n",
      "Epoch 24/250\n",
      "\n",
      "Epoch 00024: loss did not improve\n",
      "epoch time measured: 17.37709617614746\n",
      " - 17s - loss: 0.0769 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3110 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578262221.2908885\n",
      "Epoch 25/250\n",
      "\n",
      "Epoch 00025: loss improved from 0.07583 to 0.06798, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 18.216690063476562\n",
      " - 18s - loss: 0.0680 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3184 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262239.508985\n",
      "Epoch 26/250\n",
      "\n",
      "Epoch 00026: loss improved from 0.06798 to 0.06214, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.580671072006226\n",
      " - 18s - loss: 0.0621 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3795 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262257.0911639\n",
      "Epoch 27/250\n",
      "\n",
      "Epoch 00027: loss improved from 0.06214 to 0.05137, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.59133243560791\n",
      " - 18s - loss: 0.0514 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.4556 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262274.683806\n",
      "Epoch 28/250\n",
      "\n",
      "Epoch 00028: loss improved from 0.05137 to 0.05076, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.858009338378906\n",
      " - 18s - loss: 0.0508 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.4349 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262292.5433557\n",
      "Epoch 29/250\n",
      "\n",
      "Epoch 00029: loss did not improve\n",
      "epoch time measured: 18.10077667236328\n",
      " - 18s - loss: 0.0534 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3575 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262310.6453102\n",
      "Epoch 30/250\n",
      "\n",
      "Epoch 00030: loss improved from 0.05076 to 0.03195, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.517140865325928\n",
      " - 18s - loss: 0.0319 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3603 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262328.1639864\n",
      "Epoch 31/250\n",
      "\n",
      "Epoch 00031: loss did not improve\n",
      "epoch time measured: 17.467746257781982\n",
      " - 17s - loss: 0.0433 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2671 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578262345.632874\n",
      "Epoch 32/250\n",
      "\n",
      "Epoch 00032: loss did not improve\n",
      "epoch time measured: 17.250035762786865\n",
      " - 17s - loss: 0.0348 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1970 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578262362.8841248\n",
      "Epoch 33/250\n",
      "\n",
      "Epoch 00033: loss improved from 0.03195 to 0.02150, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.868268966674805\n",
      " - 18s - loss: 0.0215 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1808 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578262380.753971\n",
      "Epoch 34/250\n",
      "\n",
      "Epoch 00034: loss did not improve\n",
      "epoch time measured: 17.358670234680176\n",
      " - 17s - loss: 0.0243 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1788 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578262398.1136568\n",
      "Epoch 35/250\n",
      "\n",
      "Epoch 00035: loss improved from 0.02150 to 0.02127, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.72065567970276\n",
      " - 18s - loss: 0.0213 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1979 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578262415.836111\n",
      "Epoch 36/250\n",
      "\n",
      "Epoch 00036: loss did not improve\n",
      "epoch time measured: 17.60548448562622\n",
      " - 18s - loss: 0.0234 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2185 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578262433.442777\n",
      "Epoch 37/250\n",
      "\n",
      "Epoch 00037: loss improved from 0.02127 to 0.01986, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.374009609222412\n",
      " - 17s - loss: 0.0199 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2102 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578262450.8183672\n",
      "Epoch 38/250\n",
      "\n",
      "Epoch 00038: loss improved from 0.01986 to 0.01659, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.479416131973267\n",
      " - 17s - loss: 0.0166 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1944 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578262468.299292\n",
      "Epoch 39/250\n",
      "\n",
      "Epoch 00039: loss improved from 0.01659 to 0.01116, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.70742964744568\n",
      " - 18s - loss: 0.0112 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1803 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578262486.008188\n",
      "Epoch 40/250\n",
      "\n",
      "Epoch 00040: loss improved from 0.01116 to 0.00930, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.96252465248108\n",
      " - 18s - loss: 0.0093 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1734 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578262503.9718945\n",
      "Epoch 41/250\n",
      "\n",
      "Epoch 00041: loss did not improve\n",
      "epoch time measured: 17.995331048965454\n",
      " - 18s - loss: 0.0104 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1703 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578262521.9682748\n",
      "Epoch 42/250\n",
      "\n",
      "Epoch 00042: loss did not improve\n",
      "epoch time measured: 17.382548093795776\n",
      " - 17s - loss: 0.0095 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1680 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578262539.3519356\n",
      "Epoch 43/250\n",
      "\n",
      "Epoch 00043: loss improved from 0.00930 to 0.00761, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.58949565887451\n",
      " - 18s - loss: 0.0076 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1694 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578262556.9429367\n",
      "Epoch 44/250\n",
      "\n",
      "Epoch 00044: loss improved from 0.00761 to 0.00612, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.84579348564148\n",
      " - 18s - loss: 0.0061 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1846 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578262574.7903135\n",
      "Epoch 45/250\n",
      "\n",
      "Epoch 00045: loss improved from 0.00612 to 0.00465, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.8564555644989\n",
      " - 18s - loss: 0.0047 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2068 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578262592.6481414\n",
      "Epoch 46/250\n",
      "\n",
      "Epoch 00046: loss did not improve\n",
      "epoch time measured: 17.716336727142334\n",
      " - 18s - loss: 0.0048 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2255 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578262610.36558\n",
      "Epoch 47/250\n",
      "\n",
      "Epoch 00047: loss did not improve\n",
      "epoch time measured: 17.68907070159912\n",
      " - 18s - loss: 0.0054 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2322 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578262628.0559838\n",
      "Epoch 48/250\n",
      "\n",
      "Epoch 00048: loss did not improve\n",
      "epoch time measured: 17.337368488311768\n",
      " - 17s - loss: 0.0047 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2314 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578262645.394566\n",
      "Epoch 49/250\n",
      "\n",
      "Epoch 00049: loss improved from 0.00465 to 0.00394, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.461148977279663\n",
      " - 17s - loss: 0.0039 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2288 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578262662.856936\n",
      "Epoch 50/250\n",
      "\n",
      "Epoch 00050: loss improved from 0.00394 to 0.00274, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.51830005645752\n",
      " - 18s - loss: 0.0027 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2226 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578262680.3765185\n",
      "Epoch 51/250\n",
      "\n",
      "Epoch 00051: loss improved from 0.00274 to 0.00266, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.996344804763794\n",
      " - 18s - loss: 0.0027 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2223 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578262698.3747532\n",
      "Epoch 52/250\n",
      "\n",
      "Epoch 00052: loss improved from 0.00266 to 0.00263, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 18.19698977470398\n",
      " - 18s - loss: 0.0026 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2300 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578262716.573362\n",
      "Epoch 53/250\n",
      "\n",
      "Epoch 00053: loss improved from 0.00263 to 0.00213, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.796303749084473\n",
      " - 18s - loss: 0.0021 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2444 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578262734.3712823\n",
      "Epoch 54/250\n",
      "\n",
      "Epoch 00054: loss improved from 0.00213 to 0.00175, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.639718055725098\n",
      " - 18s - loss: 0.0018 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2601 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578262752.01324\n",
      "Epoch 55/250\n",
      "\n",
      "Epoch 00055: loss improved from 0.00175 to 0.00116, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.394825220108032\n",
      " - 17s - loss: 0.0012 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2736 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262769.4095895\n",
      "Epoch 56/250\n",
      "\n",
      "Epoch 00056: loss did not improve\n",
      "epoch time measured: 17.834717273712158\n",
      " - 18s - loss: 0.0013 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2932 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262787.24539\n",
      "Epoch 57/250\n",
      "\n",
      "Epoch 00057: loss did not improve\n",
      "epoch time measured: 17.5897536277771\n",
      " - 18s - loss: 0.0017 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3096 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262804.83634\n",
      "Epoch 58/250\n",
      "\n",
      "Epoch 00058: loss improved from 0.00116 to 0.00104, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.885247468948364\n",
      " - 18s - loss: 0.0010 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3261 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262822.7231708\n",
      "Epoch 59/250\n",
      "\n",
      "Epoch 00059: loss did not improve\n",
      "epoch time measured: 17.331722497940063\n",
      " - 17s - loss: 0.0012 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3413 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262840.0563471\n",
      "Epoch 60/250\n",
      "\n",
      "Epoch 00060: loss did not improve\n",
      "epoch time measured: 17.497658491134644\n",
      " - 17s - loss: 0.0015 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3507 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262857.5551794\n",
      "Epoch 61/250\n",
      "\n",
      "Epoch 00061: loss did not improve\n",
      "epoch time measured: 17.8574800491333\n",
      " - 18s - loss: 0.0011 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3584 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262875.413689\n",
      "Epoch 62/250\n",
      "\n",
      "Epoch 00062: loss did not improve\n",
      "epoch time measured: 17.885228633880615\n",
      " - 18s - loss: 0.0013 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3629 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262893.3001084\n",
      "Epoch 63/250\n",
      "\n",
      "Epoch 00063: loss improved from 0.00104 to 0.00093, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.44101643562317\n",
      " - 17s - loss: 9.3121e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3681 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262910.7425172\n",
      "Epoch 64/250\n",
      "\n",
      "Epoch 00064: loss did not improve\n",
      "epoch time measured: 17.280189752578735\n",
      " - 17s - loss: 0.0010 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3698 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262928.0237927\n",
      "Epoch 65/250\n",
      "\n",
      "Epoch 00065: loss improved from 0.00093 to 0.00089, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.800652980804443\n",
      " - 18s - loss: 8.8659e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3714 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262945.8260782\n",
      "Epoch 66/250\n",
      "\n",
      "Epoch 00066: loss improved from 0.00089 to 0.00081, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.5269558429718\n",
      " - 18s - loss: 8.1062e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3684 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262963.354344\n",
      "Epoch 67/250\n",
      "\n",
      "Epoch 00067: loss did not improve\n",
      "epoch time measured: 17.406317710876465\n",
      " - 17s - loss: 8.9702e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3637 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262980.7619472\n",
      "Epoch 68/250\n",
      "\n",
      "Epoch 00068: loss improved from 0.00081 to 0.00080, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.285539865493774\n",
      " - 17s - loss: 8.0421e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3553 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578262998.0492065\n",
      "Epoch 69/250\n",
      "\n",
      "Epoch 00069: loss improved from 0.00080 to 0.00078, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.421215534210205\n",
      " - 17s - loss: 7.7798e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3399 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578263015.4717462\n",
      "Epoch 70/250\n",
      "\n",
      "Epoch 00070: loss did not improve\n",
      "epoch time measured: 17.517168045043945\n",
      " - 18s - loss: 8.3365e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3244 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263032.9900236\n",
      "Epoch 71/250\n",
      "\n",
      "Epoch 00071: loss improved from 0.00078 to 0.00065, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.78719210624695\n",
      " - 18s - loss: 6.5369e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3093 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263050.7786272\n",
      "Epoch 72/250\n",
      "\n",
      "Epoch 00072: loss improved from 0.00065 to 0.00056, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.2743239402771\n",
      " - 17s - loss: 5.5826e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2929 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263068.054123\n",
      "Epoch 73/250\n",
      "\n",
      "Epoch 00073: loss did not improve\n",
      "epoch time measured: 17.40566349029541\n",
      " - 17s - loss: 6.3534e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2776 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263085.461277\n",
      "Epoch 74/250\n",
      "\n",
      "Epoch 00074: loss did not improve\n",
      "epoch time measured: 17.637492179870605\n",
      " - 18s - loss: 6.1913e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2630 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263103.1001394\n",
      "Epoch 75/250\n",
      "\n",
      "Epoch 00075: loss did not improve\n",
      "epoch time measured: 17.29843306541443\n",
      " - 17s - loss: 5.9415e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2491 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263120.3995328\n",
      "Epoch 76/250\n",
      "\n",
      "Epoch 00076: loss did not improve\n",
      "epoch time measured: 17.83293318748474\n",
      " - 18s - loss: 7.1550e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2395 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578263138.2335472\n",
      "Epoch 77/250\n",
      "\n",
      "Epoch 00077: loss did not improve\n",
      "epoch time measured: 17.891168355941772\n",
      " - 18s - loss: 5.9370e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2343 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578263156.126029\n",
      "Epoch 78/250\n",
      "\n",
      "Epoch 00078: loss improved from 0.00056 to 0.00052, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.48301911354065\n",
      " - 17s - loss: 5.1862e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2349 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578263173.6105082\n",
      "Epoch 79/250\n",
      "\n",
      "Epoch 00079: loss improved from 0.00052 to 0.00051, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.796676874160767\n",
      " - 18s - loss: 5.0506e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2380 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263191.4085183\n",
      "Epoch 80/250\n",
      "\n",
      "Epoch 00080: loss did not improve\n",
      "epoch time measured: 17.444199562072754\n",
      " - 17s - loss: 5.5554e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2454 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263208.8540308\n",
      "Epoch 81/250\n",
      "\n",
      "Epoch 00081: loss improved from 0.00051 to 0.00049, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.810247659683228\n",
      " - 18s - loss: 4.9232e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2568 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263226.66575\n",
      "Epoch 82/250\n",
      "\n",
      "Epoch 00082: loss did not improve\n",
      "epoch time measured: 17.294910192489624\n",
      " - 17s - loss: 5.6834e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2646 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263243.9618406\n",
      "Epoch 83/250\n",
      "\n",
      "Epoch 00083: loss improved from 0.00049 to 0.00049, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.40657138824463\n",
      " - 17s - loss: 4.8769e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2763 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263261.370351\n",
      "Epoch 84/250\n",
      "\n",
      "Epoch 00084: loss improved from 0.00049 to 0.00048, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.52053689956665\n",
      " - 18s - loss: 4.8375e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2886 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263278.892329\n",
      "Epoch 85/250\n",
      "\n",
      "Epoch 00085: loss did not improve\n",
      "epoch time measured: 17.35553240776062\n",
      " - 17s - loss: 5.4994e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2967 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263296.2493527\n",
      "Epoch 86/250\n",
      "\n",
      "Epoch 00086: loss did not improve\n",
      "epoch time measured: 18.195035934448242\n",
      " - 18s - loss: 5.5728e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3024 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578263314.4456415\n",
      "Epoch 87/250\n",
      "\n",
      "Epoch 00087: loss improved from 0.00048 to 0.00040, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.824331760406494\n",
      " - 18s - loss: 4.0375e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3081 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263332.2717133\n",
      "Epoch 88/250\n",
      "\n",
      "Epoch 00088: loss improved from 0.00040 to 0.00040, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.186644554138184\n",
      " - 17s - loss: 4.0094e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3120 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263349.4598815\n",
      "Epoch 89/250\n",
      "\n",
      "Epoch 00089: loss improved from 0.00040 to 0.00038, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.510488510131836\n",
      " - 18s - loss: 3.8297e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3134 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263366.9717145\n",
      "Epoch 90/250\n",
      "\n",
      "Epoch 00090: loss did not improve\n",
      "epoch time measured: 17.522984504699707\n",
      " - 18s - loss: 4.9505e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3132 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263384.4964721\n",
      "Epoch 91/250\n",
      "\n",
      "Epoch 00091: loss did not improve\n",
      "epoch time measured: 17.76801037788391\n",
      " - 18s - loss: 4.7533e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3106 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263402.2656717\n",
      "Epoch 92/250\n",
      "\n",
      "Epoch 00092: loss did not improve\n",
      "epoch time measured: 18.059762954711914\n",
      " - 18s - loss: 4.2711e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3039 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263420.3265533\n",
      "Epoch 93/250\n",
      "\n",
      "Epoch 00093: loss did not improve\n",
      "epoch time measured: 17.255120992660522\n",
      " - 17s - loss: 4.1328e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2933 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263437.582809\n",
      "Epoch 94/250\n",
      "\n",
      "Epoch 00094: loss improved from 0.00038 to 0.00036, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.671900033950806\n",
      " - 18s - loss: 3.6197e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2869 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263455.256308\n",
      "Epoch 95/250\n",
      "\n",
      "Epoch 00095: loss did not improve\n",
      "epoch time measured: 17.31229043006897\n",
      " - 17s - loss: 4.0807e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2786 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263472.569612\n",
      "Epoch 96/250\n",
      "\n",
      "Epoch 00096: loss improved from 0.00036 to 0.00034, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.307327270507812\n",
      " - 17s - loss: 3.3698e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2708 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263489.8785298\n",
      "Epoch 97/250\n",
      "\n",
      "Epoch 00097: loss did not improve\n",
      "epoch time measured: 18.03087854385376\n",
      " - 18s - loss: 4.3011e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2646 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263507.9110355\n",
      "Epoch 98/250\n",
      "\n",
      "Epoch 00098: loss did not improve\n",
      "epoch time measured: 17.4672532081604\n",
      " - 17s - loss: 3.6017e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2573 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263525.37931\n",
      "Epoch 99/250\n",
      "\n",
      "Epoch 00099: loss did not improve\n",
      "epoch time measured: 17.668582677841187\n",
      " - 18s - loss: 3.4519e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2497 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263543.0490987\n",
      "Epoch 100/250\n",
      "\n",
      "Epoch 00100: loss did not improve\n",
      "epoch time measured: 18.101128101348877\n",
      " - 18s - loss: 3.8534e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2449 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263561.1515493\n",
      "Epoch 101/250\n",
      "\n",
      "Epoch 00101: loss did not improve\n",
      "epoch time measured: 17.329960346221924\n",
      " - 17s - loss: 3.7579e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2415 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263578.4829345\n",
      "Epoch 102/250\n",
      "\n",
      "Epoch 00102: loss improved from 0.00034 to 0.00028, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.555914878845215\n",
      " - 18s - loss: 2.8019e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2388 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263596.0404558\n",
      "Epoch 103/250\n",
      "\n",
      "Epoch 00103: loss did not improve\n",
      "epoch time measured: 17.738227128982544\n",
      " - 18s - loss: 3.7127e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2358 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578263613.779935\n",
      "Epoch 104/250\n",
      "\n",
      "Epoch 00104: loss did not improve\n",
      "epoch time measured: 17.74395728111267\n",
      " - 18s - loss: 3.3459e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2369 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263631.5249426\n",
      "Epoch 105/250\n",
      "\n",
      "Epoch 00105: loss did not improve\n",
      "epoch time measured: 17.373902082443237\n",
      " - 17s - loss: 3.5235e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2382 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263648.900079\n",
      "Epoch 106/250\n",
      "\n",
      "Epoch 00106: loss did not improve\n",
      "epoch time measured: 17.434311151504517\n",
      " - 17s - loss: 3.2784e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2388 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263666.3357518\n",
      "Epoch 107/250\n",
      "\n",
      "Epoch 00107: loss did not improve\n",
      "epoch time measured: 17.34073543548584\n",
      " - 17s - loss: 3.5032e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2379 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263683.6781986\n",
      "Epoch 108/250\n",
      "\n",
      "Epoch 00108: loss did not improve\n",
      "epoch time measured: 17.75626492500305\n",
      " - 18s - loss: 3.7307e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2338 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263701.4355643\n",
      "Epoch 109/250\n",
      "\n",
      "Epoch 00109: loss did not improve\n",
      "epoch time measured: 17.431271076202393\n",
      " - 17s - loss: 3.5956e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2301 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578263718.8681824\n",
      "Epoch 110/250\n",
      "\n",
      "Epoch 00110: loss did not improve\n",
      "epoch time measured: 17.21866536140442\n",
      " - 17s - loss: 3.3252e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2263 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578263736.088047\n",
      "Epoch 111/250\n",
      "\n",
      "Epoch 00111: loss did not improve\n",
      "epoch time measured: 17.411091327667236\n",
      " - 17s - loss: 2.9805e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2209 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578263753.5002923\n",
      "Epoch 112/250\n",
      "\n",
      "Epoch 00112: loss did not improve\n",
      "epoch time measured: 17.18828821182251\n",
      " - 17s - loss: 3.4024e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2170 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578263770.6898787\n",
      "Epoch 113/250\n",
      "\n",
      "Epoch 00113: loss did not improve\n",
      "epoch time measured: 17.617640733718872\n",
      " - 18s - loss: 2.9452e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2176 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578263788.308559\n",
      "Epoch 114/250\n",
      "\n",
      "Epoch 00114: loss improved from 0.00028 to 0.00026, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.5733003616333\n",
      " - 18s - loss: 2.5731e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2200 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578263805.8832984\n",
      "Epoch 115/250\n",
      "\n",
      "Epoch 00115: loss did not improve\n",
      "epoch time measured: 17.667952299118042\n",
      " - 18s - loss: 3.0821e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2207 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578263823.5523086\n",
      "Epoch 116/250\n",
      "\n",
      "Epoch 00116: loss did not improve\n",
      "epoch time measured: 18.036361932754517\n",
      " - 18s - loss: 3.6045e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2218 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578263841.589964\n",
      "Epoch 117/250\n",
      "\n",
      "Epoch 00117: loss did not improve\n",
      "epoch time measured: 17.226494789123535\n",
      " - 17s - loss: 2.8014e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2227 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578263858.81766\n",
      "Epoch 118/250\n",
      "\n",
      "Epoch 00118: loss did not improve\n",
      "epoch time measured: 17.545146226882935\n",
      " - 18s - loss: 2.9488e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2266 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578263876.3642309\n",
      "Epoch 119/250\n",
      "\n",
      "Epoch 00119: loss improved from 0.00026 to 0.00025, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.88453221321106\n",
      " - 18s - loss: 2.5199e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2298 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263894.250379\n",
      "Epoch 120/250\n",
      "\n",
      "Epoch 00120: loss did not improve\n",
      "epoch time measured: 17.447994470596313\n",
      " - 17s - loss: 2.7603e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2310 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578263911.6995375\n",
      "Epoch 121/250\n",
      "\n",
      "Epoch 00121: loss did not improve\n",
      "epoch time measured: 17.54418683052063\n",
      " - 18s - loss: 3.1663e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2308 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263929.2454762\n",
      "Epoch 122/250\n",
      "\n",
      "Epoch 00122: loss did not improve\n",
      "epoch time measured: 17.635370016098022\n",
      " - 18s - loss: 2.8111e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2308 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263946.8819022\n",
      "Epoch 123/250\n",
      "\n",
      "Epoch 00123: loss did not improve\n",
      "epoch time measured: 17.334446907043457\n",
      " - 17s - loss: 2.5792e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2296 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263964.2175426\n",
      "Epoch 124/250\n",
      "\n",
      "Epoch 00124: loss improved from 0.00025 to 0.00025, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.870880842208862\n",
      " - 18s - loss: 2.4919e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2270 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578263982.0903227\n",
      "Epoch 125/250\n",
      "\n",
      "Epoch 00125: loss did not improve\n",
      "epoch time measured: 17.350040674209595\n",
      " - 17s - loss: 2.7390e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2244 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578263999.4416504\n",
      "Epoch 126/250\n",
      "\n",
      "Epoch 00126: loss improved from 0.00025 to 0.00025, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.817281246185303\n",
      " - 18s - loss: 2.4591e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2241 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578264017.260771\n",
      "Epoch 127/250\n",
      "\n",
      "Epoch 00127: loss did not improve\n",
      "epoch time measured: 17.499012231826782\n",
      " - 17s - loss: 2.7748e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2264 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578264034.7608964\n",
      "Epoch 128/250\n",
      "\n",
      "Epoch 00128: loss did not improve\n",
      "epoch time measured: 18.179603815078735\n",
      " - 18s - loss: 3.2398e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2242 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578264052.9418068\n",
      "Epoch 129/250\n",
      "\n",
      "Epoch 00129: loss improved from 0.00025 to 0.00022, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.443548917770386\n",
      " - 17s - loss: 2.2347e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2244 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578264070.3869004\n",
      "Epoch 130/250\n",
      "\n",
      "Epoch 00130: loss did not improve\n",
      "epoch time measured: 17.41697406768799\n",
      " - 17s - loss: 2.4153e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2250 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578264087.8050072\n",
      "Epoch 131/250\n",
      "\n",
      "Epoch 00131: loss did not improve\n",
      "epoch time measured: 17.594162464141846\n",
      " - 18s - loss: 2.4870e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2233 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578264105.400512\n",
      "Epoch 132/250\n",
      "\n",
      "Epoch 00132: loss improved from 0.00022 to 0.00022, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.651824951171875\n",
      " - 18s - loss: 2.2244e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2241 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578264123.0540519\n",
      "Epoch 133/250\n",
      "\n",
      "Epoch 00133: loss did not improve\n",
      "epoch time measured: 17.231557607650757\n",
      " - 17s - loss: 2.7352e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2236 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578264140.2869782\n",
      "Epoch 134/250\n",
      "\n",
      "Epoch 00134: loss did not improve\n",
      "epoch time measured: 17.203430891036987\n",
      " - 17s - loss: 2.8974e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2211 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264157.4915273\n",
      "Epoch 135/250\n",
      "\n",
      "Epoch 00135: loss did not improve\n",
      "epoch time measured: 17.772273302078247\n",
      " - 18s - loss: 2.2449e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2183 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264175.2650325\n",
      "Epoch 136/250\n",
      "\n",
      "Epoch 00136: loss did not improve\n",
      "epoch time measured: 18.072428464889526\n",
      " - 18s - loss: 2.4788e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2160 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264193.3392107\n",
      "Epoch 137/250\n",
      "\n",
      "Epoch 00137: loss did not improve\n",
      "epoch time measured: 17.856313705444336\n",
      " - 18s - loss: 2.2680e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2128 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578264211.1967132\n",
      "Epoch 138/250\n",
      "\n",
      "Epoch 00138: loss did not improve\n",
      "epoch time measured: 17.5962176322937\n",
      " - 18s - loss: 2.2581e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2075 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264228.7939851\n",
      "Epoch 139/250\n",
      "\n",
      "Epoch 00139: loss did not improve\n",
      "epoch time measured: 17.80626344680786\n",
      " - 18s - loss: 2.4102e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2025 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264246.6015615\n",
      "Epoch 140/250\n",
      "\n",
      "Epoch 00140: loss did not improve\n",
      "epoch time measured: 18.100022554397583\n",
      " - 18s - loss: 2.3570e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1977 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264264.7031791\n",
      "Epoch 141/250\n",
      "\n",
      "Epoch 00141: loss did not improve\n",
      "epoch time measured: 17.43045926094055\n",
      " - 17s - loss: 2.4055e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1937 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264282.1348405\n",
      "Epoch 142/250\n",
      "\n",
      "Epoch 00142: loss did not improve\n",
      "epoch time measured: 17.88915753364563\n",
      " - 18s - loss: 2.3345e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1914 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264300.0253158\n",
      "Epoch 143/250\n",
      "\n",
      "Epoch 00143: loss improved from 0.00022 to 0.00018, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.327148914337158\n",
      " - 17s - loss: 1.8364e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1887 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264317.3538747\n",
      "Epoch 144/250\n",
      "\n",
      "Epoch 00144: loss did not improve\n",
      "epoch time measured: 17.935722589492798\n",
      " - 18s - loss: 2.1924e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1862 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264335.291028\n",
      "Epoch 145/250\n",
      "\n",
      "Epoch 00145: loss did not improve\n",
      "epoch time measured: 17.687275886535645\n",
      " - 18s - loss: 2.1573e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1855 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264352.979655\n",
      "Epoch 146/250\n",
      "\n",
      "Epoch 00146: loss did not improve\n",
      "epoch time measured: 17.385804176330566\n",
      " - 17s - loss: 1.9797e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1863 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264370.3665485\n",
      "Epoch 147/250\n",
      "\n",
      "Epoch 00147: loss did not improve\n",
      "epoch time measured: 17.408969163894653\n",
      " - 17s - loss: 1.9498e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1875 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264387.7767184\n",
      "Epoch 148/250\n",
      "\n",
      "Epoch 00148: loss improved from 0.00018 to 0.00017, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.608144521713257\n",
      " - 18s - loss: 1.6847e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1894 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264405.3861616\n",
      "Epoch 149/250\n",
      "\n",
      "Epoch 00149: loss did not improve\n",
      "epoch time measured: 17.99408769607544\n",
      " - 18s - loss: 2.0880e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1913 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264423.3814595\n",
      "Epoch 150/250\n",
      "\n",
      "Epoch 00150: loss did not improve\n",
      "epoch time measured: 17.391762495040894\n",
      " - 17s - loss: 2.2561e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1925 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264440.7743354\n",
      "Epoch 151/250\n",
      "\n",
      "Epoch 00151: loss did not improve\n",
      "epoch time measured: 17.61526894569397\n",
      " - 18s - loss: 1.9248e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1952 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264458.391044\n",
      "Epoch 152/250\n",
      "\n",
      "Epoch 00152: loss did not improve\n",
      "epoch time measured: 17.24236273765564\n",
      " - 17s - loss: 1.9470e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1966 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264475.6349103\n",
      "Epoch 153/250\n",
      "\n",
      "Epoch 00153: loss did not improve\n",
      "epoch time measured: 17.61415433883667\n",
      " - 18s - loss: 1.9636e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1979 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264493.2501843\n",
      "Epoch 154/250\n",
      "\n",
      "Epoch 00154: loss did not improve\n",
      "epoch time measured: 17.247762441635132\n",
      " - 17s - loss: 2.0345e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1978 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578264510.499056\n",
      "Epoch 155/250\n",
      "\n",
      "Epoch 00155: loss did not improve\n",
      "epoch time measured: 17.31810164451599\n",
      " - 17s - loss: 1.9074e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1965 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264527.8184345\n",
      "Epoch 156/250\n",
      "\n",
      "Epoch 00156: loss did not improve\n",
      "epoch time measured: 17.707948684692383\n",
      " - 18s - loss: 2.1064e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1943 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264545.5283942\n",
      "Epoch 157/250\n",
      "\n",
      "Epoch 00157: loss did not improve\n",
      "epoch time measured: 17.268599033355713\n",
      " - 17s - loss: 1.8796e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1925 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264562.798151\n",
      "Epoch 158/250\n",
      "\n",
      "Epoch 00158: loss did not improve\n",
      "epoch time measured: 17.663745164871216\n",
      " - 18s - loss: 1.6976e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1912 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264580.4636045\n",
      "Epoch 159/250\n",
      "\n",
      "Epoch 00159: loss did not improve\n",
      "epoch time measured: 17.552783966064453\n",
      " - 18s - loss: 1.7161e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1888 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264598.0178225\n",
      "Epoch 160/250\n",
      "\n",
      "Epoch 00160: loss did not improve\n",
      "epoch time measured: 17.83163046836853\n",
      " - 18s - loss: 1.9819e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1866 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264615.850558\n",
      "Epoch 161/250\n",
      "\n",
      "Epoch 00161: loss improved from 0.00017 to 0.00016, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.635543823242188\n",
      " - 18s - loss: 1.5767e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1845 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264633.4878976\n",
      "Epoch 162/250\n",
      "\n",
      "Epoch 00162: loss did not improve\n",
      "epoch time measured: 17.650066614151\n",
      " - 18s - loss: 1.7460e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1842 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264651.1394348\n",
      "Epoch 163/250\n",
      "\n",
      "Epoch 00163: loss did not improve\n",
      "epoch time measured: 17.891666650772095\n",
      " - 18s - loss: 1.9963e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1832 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264669.0325892\n",
      "Epoch 164/250\n",
      "\n",
      "Epoch 00164: loss did not improve\n",
      "epoch time measured: 17.227627992630005\n",
      " - 17s - loss: 1.7980e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1823 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264686.261563\n",
      "Epoch 165/250\n",
      "\n",
      "Epoch 00165: loss did not improve\n",
      "epoch time measured: 17.532658100128174\n",
      " - 18s - loss: 1.6902e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1816 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264703.7953095\n",
      "Epoch 166/250\n",
      "\n",
      "Epoch 00166: loss did not improve\n",
      "epoch time measured: 17.0640230178833\n",
      " - 17s - loss: 1.9440e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1815 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264720.8604233\n",
      "Epoch 167/250\n",
      "\n",
      "Epoch 00167: loss did not improve\n",
      "epoch time measured: 17.463189363479614\n",
      " - 17s - loss: 1.6509e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1815 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264738.324832\n",
      "Epoch 168/250\n",
      "\n",
      "Epoch 00168: loss improved from 0.00016 to 0.00015, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.44535803794861\n",
      " - 17s - loss: 1.5273e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1821 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264755.7716248\n",
      "Epoch 169/250\n",
      "\n",
      "Epoch 00169: loss did not improve\n",
      "epoch time measured: 17.137317895889282\n",
      " - 17s - loss: 1.9912e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1824 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264772.9101052\n",
      "Epoch 170/250\n",
      "\n",
      "Epoch 00170: loss did not improve\n",
      "epoch time measured: 17.288759231567383\n",
      " - 17s - loss: 1.6737e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1832 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264790.2002676\n",
      "Epoch 171/250\n",
      "\n",
      "Epoch 00171: loss did not improve\n",
      "epoch time measured: 17.260716676712036\n",
      " - 17s - loss: 1.5369e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1857 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578264807.46213\n",
      "Epoch 172/250\n",
      "\n",
      "Epoch 00172: loss did not improve\n",
      "epoch time measured: 18.015707969665527\n",
      " - 18s - loss: 2.0331e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1878 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264825.478923\n",
      "Epoch 173/250\n",
      "\n",
      "Epoch 00173: loss improved from 0.00015 to 0.00015, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.873549699783325\n",
      " - 18s - loss: 1.5052e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1896 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264843.3539014\n",
      "Epoch 174/250\n",
      "\n",
      "Epoch 00174: loss did not improve\n",
      "epoch time measured: 17.332319974899292\n",
      " - 17s - loss: 2.1241e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1911 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264860.6874158\n",
      "Epoch 175/250\n",
      "\n",
      "Epoch 00175: loss did not improve\n",
      "epoch time measured: 17.192652463912964\n",
      " - 17s - loss: 1.7563e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1910 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264877.8811648\n",
      "Epoch 176/250\n",
      "\n",
      "Epoch 00176: loss did not improve\n",
      "epoch time measured: 17.30409026145935\n",
      " - 17s - loss: 1.7991e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1905 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264895.1862712\n",
      "Epoch 177/250\n",
      "\n",
      "Epoch 00177: loss did not improve\n",
      "epoch time measured: 18.219765186309814\n",
      " - 18s - loss: 1.7138e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1915 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264913.407304\n",
      "Epoch 178/250\n",
      "\n",
      "Epoch 00178: loss did not improve\n",
      "epoch time measured: 17.450080394744873\n",
      " - 17s - loss: 1.6139e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1928 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264930.8586042\n",
      "Epoch 179/250\n",
      "\n",
      "Epoch 00179: loss did not improve\n",
      "epoch time measured: 17.672974586486816\n",
      " - 18s - loss: 1.7751e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1937 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264948.5329416\n",
      "Epoch 180/250\n",
      "\n",
      "Epoch 00180: loss did not improve\n",
      "epoch time measured: 17.738115549087524\n",
      " - 18s - loss: 1.5950e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1942 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264966.2723005\n",
      "Epoch 181/250\n",
      "\n",
      "Epoch 00181: loss improved from 0.00015 to 0.00015, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.93474555015564\n",
      " - 18s - loss: 1.4522e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1947 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578264984.2087412\n",
      "Epoch 182/250\n",
      "\n",
      "Epoch 00182: loss did not improve\n",
      "epoch time measured: 17.652196168899536\n",
      " - 18s - loss: 1.5271e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1959 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265001.8625035\n",
      "Epoch 183/250\n",
      "\n",
      "Epoch 00183: loss did not improve\n",
      "epoch time measured: 17.64586091041565\n",
      " - 18s - loss: 1.5740e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1958 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265019.5097618\n",
      "Epoch 184/250\n",
      "\n",
      "Epoch 00184: loss did not improve\n",
      "epoch time measured: 17.94730830192566\n",
      " - 18s - loss: 1.5420e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1953 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265037.4584677\n",
      "Epoch 185/250\n",
      "\n",
      "Epoch 00185: loss did not improve\n",
      "epoch time measured: 17.731375455856323\n",
      " - 18s - loss: 2.0371e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1943 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265055.190951\n",
      "Epoch 186/250\n",
      "\n",
      "Epoch 00186: loss did not improve\n",
      "epoch time measured: 17.413600206375122\n",
      " - 17s - loss: 1.7039e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1926 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265072.605825\n",
      "Epoch 187/250\n",
      "\n",
      "Epoch 00187: loss did not improve\n",
      "epoch time measured: 17.396888494491577\n",
      " - 17s - loss: 1.4993e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1901 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265090.003799\n",
      "Epoch 188/250\n",
      "\n",
      "Epoch 00188: loss did not improve\n",
      "epoch time measured: 17.86859679222107\n",
      " - 18s - loss: 1.7279e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1863 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578265107.8736966\n",
      "Epoch 189/250\n",
      "\n",
      "Epoch 00189: loss improved from 0.00015 to 0.00014, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.871310472488403\n",
      " - 18s - loss: 1.3606e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1848 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265125.7472012\n",
      "Epoch 190/250\n",
      "\n",
      "Epoch 00190: loss did not improve\n",
      "epoch time measured: 17.345088481903076\n",
      " - 17s - loss: 1.4298e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1837 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265143.093764\n",
      "Epoch 191/250\n",
      "\n",
      "Epoch 00191: loss did not improve\n",
      "epoch time measured: 18.050469875335693\n",
      " - 18s - loss: 1.4707e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1834 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265161.145296\n",
      "Epoch 192/250\n",
      "\n",
      "Epoch 00192: loss did not improve\n",
      "epoch time measured: 17.770522594451904\n",
      " - 18s - loss: 1.5115e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1829 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265178.916969\n",
      "Epoch 193/250\n",
      "\n",
      "Epoch 00193: loss did not improve\n",
      "epoch time measured: 17.68169665336609\n",
      " - 18s - loss: 1.7680e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1809 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265196.5997317\n",
      "Epoch 194/250\n",
      "\n",
      "Epoch 00194: loss did not improve\n",
      "epoch time measured: 17.800747394561768\n",
      " - 18s - loss: 1.3850e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1796 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265214.401738\n",
      "Epoch 195/250\n",
      "\n",
      "Epoch 00195: loss improved from 0.00014 to 0.00013, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.191757917404175\n",
      " - 17s - loss: 1.3438e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1777 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265231.5948946\n",
      "Epoch 196/250\n",
      "\n",
      "Epoch 00196: loss did not improve\n",
      "epoch time measured: 17.16277813911438\n",
      " - 17s - loss: 1.4109e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1753 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265248.7587366\n",
      "Epoch 197/250\n",
      "\n",
      "Epoch 00197: loss did not improve\n",
      "epoch time measured: 17.765310764312744\n",
      " - 18s - loss: 1.4383e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1746 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265266.5251818\n",
      "Epoch 198/250\n",
      "\n",
      "Epoch 00198: loss did not improve\n",
      "epoch time measured: 17.842252731323242\n",
      " - 18s - loss: 1.4034e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1745 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265284.3687263\n",
      "Epoch 199/250\n",
      "\n",
      "Epoch 00199: loss did not improve\n",
      "epoch time measured: 17.288107872009277\n",
      " - 17s - loss: 1.5174e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1752 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265301.6579797\n",
      "Epoch 200/250\n",
      "\n",
      "Epoch 00200: loss improved from 0.00013 to 0.00013, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.768860578536987\n",
      " - 18s - loss: 1.3092e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1761 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265319.428523\n",
      "Epoch 201/250\n",
      "\n",
      "Epoch 00201: loss did not improve\n",
      "epoch time measured: 17.72396993637085\n",
      " - 18s - loss: 1.5117e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1771 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265337.1536288\n",
      "Epoch 202/250\n",
      "\n",
      "Epoch 00202: loss improved from 0.00013 to 0.00012, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.56981897354126\n",
      " - 18s - loss: 1.2082e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1782 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265354.7247634\n",
      "Epoch 203/250\n",
      "\n",
      "Epoch 00203: loss improved from 0.00012 to 0.00012, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.632415294647217\n",
      " - 18s - loss: 1.1569e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1781 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265372.3605833\n",
      "Epoch 204/250\n",
      "\n",
      "Epoch 00204: loss improved from 0.00012 to 0.00011, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.549472332000732\n",
      " - 18s - loss: 1.0700e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1792 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265389.9115205\n",
      "Epoch 205/250\n",
      "\n",
      "Epoch 00205: loss did not improve\n",
      "epoch time measured: 17.25350832939148\n",
      " - 17s - loss: 1.3039e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1792 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578265407.1666696\n",
      "Epoch 206/250\n",
      "\n",
      "Epoch 00206: loss did not improve\n",
      "epoch time measured: 17.917020559310913\n",
      " - 18s - loss: 1.2839e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1793 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265425.0851583\n",
      "Epoch 207/250\n",
      "\n",
      "Epoch 00207: loss did not improve\n",
      "epoch time measured: 18.294764280319214\n",
      " - 18s - loss: 1.4623e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1776 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265443.3812187\n",
      "Epoch 208/250\n",
      "\n",
      "Epoch 00208: loss did not improve\n",
      "epoch time measured: 17.332148551940918\n",
      " - 17s - loss: 1.3312e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1761 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265460.7144585\n",
      "Epoch 209/250\n",
      "\n",
      "Epoch 00209: loss did not improve\n",
      "epoch time measured: 17.57573175430298\n",
      " - 18s - loss: 1.4989e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1734 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265478.2912405\n",
      "Epoch 210/250\n",
      "\n",
      "Epoch 00210: loss did not improve\n",
      "epoch time measured: 17.30244207382202\n",
      " - 17s - loss: 1.2949e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1713 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265495.5956962\n",
      "Epoch 211/250\n",
      "\n",
      "Epoch 00211: loss did not improve\n",
      "epoch time measured: 17.56665325164795\n",
      " - 18s - loss: 1.3246e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1704 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265513.1641567\n",
      "Epoch 212/250\n",
      "\n",
      "Epoch 00212: loss did not improve\n",
      "epoch time measured: 17.73396944999695\n",
      " - 18s - loss: 1.2420e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1698 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265530.8991776\n",
      "Epoch 213/250\n",
      "\n",
      "Epoch 00213: loss did not improve\n",
      "epoch time measured: 17.410695552825928\n",
      " - 17s - loss: 1.1883e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1688 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265548.3110845\n",
      "Epoch 214/250\n",
      "\n",
      "Epoch 00214: loss did not improve\n",
      "epoch time measured: 17.702725887298584\n",
      " - 18s - loss: 1.2170e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1684 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265566.0149744\n",
      "Epoch 215/250\n",
      "\n",
      "Epoch 00215: loss did not improve\n",
      "epoch time measured: 17.707469940185547\n",
      " - 18s - loss: 1.1986e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1674 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265583.7236557\n",
      "Epoch 216/250\n",
      "\n",
      "Epoch 00216: loss did not improve\n",
      "epoch time measured: 18.034776210784912\n",
      " - 18s - loss: 1.1578e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1666 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265601.75985\n",
      "Epoch 217/250\n",
      "\n",
      "Epoch 00217: loss did not improve\n",
      "epoch time measured: 17.785892486572266\n",
      " - 18s - loss: 1.2377e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1661 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265619.5472782\n",
      "Epoch 218/250\n",
      "\n",
      "Epoch 00218: loss did not improve\n",
      "epoch time measured: 17.499536991119385\n",
      " - 17s - loss: 1.1017e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1657 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265637.0478632\n",
      "Epoch 219/250\n",
      "\n",
      "Epoch 00219: loss did not improve\n",
      "epoch time measured: 17.4421546459198\n",
      " - 17s - loss: 1.3233e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1655 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265654.4912062\n",
      "Epoch 220/250\n",
      "\n",
      "Epoch 00220: loss did not improve\n",
      "epoch time measured: 17.63931107521057\n",
      " - 18s - loss: 1.1139e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1662 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265672.1316316\n",
      "Epoch 221/250\n",
      "\n",
      "Epoch 00221: loss did not improve\n",
      "epoch time measured: 17.892077207565308\n",
      " - 18s - loss: 1.2518e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1673 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265690.0248666\n",
      "Epoch 222/250\n",
      "\n",
      "Epoch 00222: loss did not improve\n",
      "epoch time measured: 17.51107120513916\n",
      " - 18s - loss: 1.4714e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1695 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265707.537028\n",
      "Epoch 223/250\n",
      "\n",
      "Epoch 00223: loss did not improve\n",
      "epoch time measured: 17.296595811843872\n",
      " - 17s - loss: 1.4680e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1726 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578265724.834852\n",
      "Epoch 224/250\n",
      "\n",
      "Epoch 00224: loss did not improve\n",
      "epoch time measured: 17.781336784362793\n",
      " - 18s - loss: 1.1324e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1753 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265742.617548\n",
      "Epoch 225/250\n",
      "\n",
      "Epoch 00225: loss improved from 0.00011 to 0.00010, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.739890813827515\n",
      " - 18s - loss: 9.7390e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1770 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265760.3591464\n",
      "Epoch 226/250\n",
      "\n",
      "Epoch 00226: loss did not improve\n",
      "epoch time measured: 17.591216802597046\n",
      " - 18s - loss: 1.3379e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1786 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265777.95158\n",
      "Epoch 227/250\n",
      "\n",
      "Epoch 00227: loss did not improve\n",
      "epoch time measured: 17.712929487228394\n",
      " - 18s - loss: 9.9492e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1788 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265795.6656868\n",
      "Epoch 228/250\n",
      "\n",
      "Epoch 00228: loss did not improve\n",
      "epoch time measured: 17.37746238708496\n",
      " - 17s - loss: 1.2312e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1783 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265813.0443869\n",
      "Epoch 229/250\n",
      "\n",
      "Epoch 00229: loss improved from 0.00010 to 0.00010, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.956348419189453\n",
      " - 18s - loss: 9.6487e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1779 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265831.0021636\n",
      "Epoch 230/250\n",
      "\n",
      "Epoch 00230: loss did not improve\n",
      "epoch time measured: 17.918808221817017\n",
      " - 18s - loss: 1.1542e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1778 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265848.9225297\n",
      "Epoch 231/250\n",
      "\n",
      "Epoch 00231: loss did not improve\n",
      "epoch time measured: 17.666780948638916\n",
      " - 18s - loss: 1.2836e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1782 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265866.5905247\n",
      "Epoch 232/250\n",
      "\n",
      "Epoch 00232: loss improved from 0.00010 to 0.00009, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.489607095718384\n",
      " - 17s - loss: 9.4180e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1788 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265884.0815272\n",
      "Epoch 233/250\n",
      "\n",
      "Epoch 00233: loss did not improve\n",
      "epoch time measured: 17.28373146057129\n",
      " - 17s - loss: 1.0856e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1785 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265901.3664818\n",
      "Epoch 234/250\n",
      "\n",
      "Epoch 00234: loss did not improve\n",
      "epoch time measured: 17.344335556030273\n",
      " - 17s - loss: 1.2766e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1781 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265918.711971\n",
      "Epoch 235/250\n",
      "\n",
      "Epoch 00235: loss did not improve\n",
      "epoch time measured: 17.441881895065308\n",
      " - 17s - loss: 9.9784e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1759 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265936.154891\n",
      "Epoch 236/250\n",
      "\n",
      "Epoch 00236: loss did not improve\n",
      "epoch time measured: 17.138620376586914\n",
      " - 17s - loss: 1.2270e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1726 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265953.2948503\n",
      "Epoch 237/250\n",
      "\n",
      "Epoch 00237: loss did not improve\n",
      "epoch time measured: 17.694904088974\n",
      " - 18s - loss: 1.0734e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1705 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265970.991023\n",
      "Epoch 238/250\n",
      "\n",
      "Epoch 00238: loss did not improve\n",
      "epoch time measured: 17.50387930870056\n",
      " - 18s - loss: 1.1026e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1671 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578265988.4960468\n",
      "Epoch 239/250\n",
      "\n",
      "Epoch 00239: loss did not improve\n",
      "epoch time measured: 17.274113416671753\n",
      " - 17s - loss: 1.0316e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1652 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266005.7713134\n",
      "Epoch 240/250\n",
      "\n",
      "Epoch 00240: loss improved from 0.00009 to 0.00008, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.27932596206665\n",
      " - 17s - loss: 8.4869e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1645 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578266023.0521011\n",
      "Epoch 241/250\n",
      "\n",
      "Epoch 00241: loss did not improve\n",
      "epoch time measured: 17.752318382263184\n",
      " - 18s - loss: 1.1890e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1643 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266040.805629\n",
      "Epoch 242/250\n",
      "\n",
      "Epoch 00242: loss did not improve\n",
      "epoch time measured: 17.73194694519043\n",
      " - 18s - loss: 1.0792e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1645 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266058.5386777\n",
      "Epoch 243/250\n",
      "\n",
      "Epoch 00243: loss did not improve\n",
      "epoch time measured: 17.528760194778442\n",
      " - 18s - loss: 9.9702e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1645 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266076.0688474\n",
      "Epoch 244/250\n",
      "\n",
      "Epoch 00244: loss did not improve\n",
      "epoch time measured: 17.405851125717163\n",
      " - 17s - loss: 1.1132e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1657 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266093.4757612\n",
      "Epoch 245/250\n",
      "\n",
      "Epoch 00245: loss did not improve\n",
      "epoch time measured: 17.21037006378174\n",
      " - 17s - loss: 1.1238e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1656 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266110.6871545\n",
      "Epoch 246/250\n",
      "\n",
      "Epoch 00246: loss did not improve\n",
      "epoch time measured: 17.323723316192627\n",
      " - 17s - loss: 1.0242e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1664 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266128.0121865\n",
      "Epoch 247/250\n",
      "\n",
      "Epoch 00247: loss did not improve\n",
      "epoch time measured: 17.331217050552368\n",
      " - 17s - loss: 1.0285e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1676 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266145.3448477\n",
      "Epoch 248/250\n",
      "\n",
      "Epoch 00248: loss did not improve\n",
      "epoch time measured: 17.939901113510132\n",
      " - 18s - loss: 9.6746e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1689 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266163.2859764\n",
      "Epoch 249/250\n",
      "\n",
      "Epoch 00249: loss did not improve\n",
      "\n",
      "Epoch 00249: ReduceLROnPlateau reducing learning rate to 0.0007937005636828516.\n",
      "epoch time measured: 17.84154176712036\n",
      " - 18s - loss: 1.0865e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1697 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266181.1288528\n",
      "Epoch 250/250\n",
      "\n",
      "Epoch 00250: loss did not improve\n",
      "epoch time measured: 17.689254999160767\n",
      " - 18s - loss: 1.0376e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1708 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "type(totalTrainingTime): <class 'numpy.float64'>\n",
      "type(convergenceEpochs): <class 'str'>\n",
      "Loading train / test dataset :  ../data/eeg_schizo_0/ ../data/eeg_schizo_0/\n",
      "x_train_path: ../data/eeg_schizo_0/X_train.npy\n",
      "Finished processing train dataset..\n",
      "Finished loading test dataset..\n",
      "\n",
      "Number of train samples :  62 Number of test samples :  17\n",
      "Number of classes :  2\n",
      "Sequence length :  7680\n",
      "y_true - 1 Tensor(\"metrics_1/tn_m/sub:0\", shape=(?, ?), dtype=float32)\n",
      "\n",
      "Evaluating : \n",
      "17/17 [==============================] - 2s 110ms/step\n",
      "predictions: [ True  True False  True  True False  True False False False  True False\n",
      " False  True False  True  True]\n",
      "truelabels: [ True  True False  True  True False  True False False False  True False\n",
      " False  True False False  True]\n",
      "TP: 16\n",
      "TN: 16\n",
      "FP: 1\n",
      "FN: 1\n",
      "\n",
      "Accuracy: 0.9411764705882353\n",
      "Precision: 0.9411764705882353\n",
      "Recall: 0.9411764705882353\n",
      "F1: 0.9411764705882353\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 16, 7680)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 7680, 16)     0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 7680, 128)    16512       permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 7680, 128)    512         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 7680, 128)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 128)          0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 128)       0           global_average_pooling1d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1, 8)         1024        reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1, 128)       1024        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 7680, 128)    0           activation_4[0][0]               \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 7680, 256)    164096      multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 7680, 256)    1024        conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 7680, 256)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 256)          0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 256)       0           global_average_pooling1d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1, 16)        4096        reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1, 256)       4096        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 7680, 256)    0           activation_5[0][0]               \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 7680, 128)    98432       multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "masking_2 (Masking)             (None, 16, 7680)     0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 7680, 128)    512         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_lstm_2 (AttentionLSTM (None, 8)            553328      masking_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7680, 128)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 8)            0           attention_lstm_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 128)          0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 136)          0           dropout_2[0][0]                  \n",
      "                                                                 global_average_pooling1d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 2)            274         concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 844,930\n",
      "Trainable params: 843,906\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "Loading train / test dataset :  ../data/eeg_schizo_1/ ../data/eeg_schizo_1/\n",
      "x_train_path: ../data/eeg_schizo_1/X_train.npy\n",
      "Finished processing train dataset..\n",
      "Finished loading test dataset..\n",
      "\n",
      "Number of train samples :  62 Number of test samples :  17\n",
      "Number of classes :  2\n",
      "Sequence length :  7680\n",
      "Class weights :  [1. 1.]\n",
      "y_true - 1 Tensor(\"metrics_2/tn_m/sub:0\", shape=(?, ?), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 62 samples, validate on 17 samples\n",
      "epoch time start: 1578266206.3088686\n",
      "Epoch 1/250\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.81585, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 20.221423149108887\n",
      " - 20s - loss: 0.8158 - acc: 0.5161 - f1_m: 0.5161 - precision_m: 0.5161 - recall_m: 0.5161 - tp_m: 32.0000 - fp_m: 30.0000 - tn_m: 32.0000 - fn_m: 30.0000 - val_loss: 0.7993 - val_acc: 0.4706 - val_f1_m: 0.4706 - val_precision_m: 0.4706 - val_recall_m: 0.4706 - val_tp_m: 8.0000 - val_fp_m: 9.0000 - val_tn_m: 8.0000 - val_fn_m: 9.0000\n",
      "epoch time start: 1578266226.5322132\n",
      "Epoch 2/250\n",
      "\n",
      "Epoch 00002: loss improved from 0.81585 to 0.66751, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.81856346130371\n",
      " - 18s - loss: 0.6675 - acc: 0.5968 - f1_m: 0.5968 - precision_m: 0.5968 - recall_m: 0.5968 - tp_m: 37.0000 - fp_m: 25.0000 - tn_m: 37.0000 - fn_m: 25.0000 - val_loss: 0.5410 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578266244.352641\n",
      "Epoch 3/250\n",
      "\n",
      "Epoch 00003: loss improved from 0.66751 to 0.57593, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.928667068481445\n",
      " - 18s - loss: 0.5759 - acc: 0.7097 - f1_m: 0.7097 - precision_m: 0.7097 - recall_m: 0.7097 - tp_m: 44.0000 - fp_m: 18.0000 - tn_m: 44.0000 - fn_m: 18.0000 - val_loss: 0.5905 - val_acc: 0.5882 - val_f1_m: 0.5882 - val_precision_m: 0.5882 - val_recall_m: 0.5882 - val_tp_m: 10.0000 - val_fp_m: 7.0000 - val_tn_m: 10.0000 - val_fn_m: 7.0000\n",
      "epoch time start: 1578266262.2829032\n",
      "Epoch 4/250\n",
      "\n",
      "Epoch 00004: loss improved from 0.57593 to 0.50744, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.56931233406067\n",
      " - 18s - loss: 0.5074 - acc: 0.7097 - f1_m: 0.7097 - precision_m: 0.7097 - recall_m: 0.7097 - tp_m: 44.0000 - fp_m: 18.0000 - tn_m: 44.0000 - fn_m: 18.0000 - val_loss: 0.7047 - val_acc: 0.5882 - val_f1_m: 0.5882 - val_precision_m: 0.5882 - val_recall_m: 0.5882 - val_tp_m: 10.0000 - val_fp_m: 7.0000 - val_tn_m: 10.0000 - val_fn_m: 7.0000\n",
      "epoch time start: 1578266279.8538013\n",
      "Epoch 5/250\n",
      "\n",
      "Epoch 00005: loss improved from 0.50744 to 0.43232, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 18.04612112045288\n",
      " - 18s - loss: 0.4323 - acc: 0.8065 - f1_m: 0.8065 - precision_m: 0.8065 - recall_m: 0.8065 - tp_m: 50.0000 - fp_m: 12.0000 - tn_m: 50.0000 - fn_m: 12.0000 - val_loss: 0.6719 - val_acc: 0.5882 - val_f1_m: 0.5882 - val_precision_m: 0.5882 - val_recall_m: 0.5882 - val_tp_m: 10.0000 - val_fp_m: 7.0000 - val_tn_m: 10.0000 - val_fn_m: 7.0000\n",
      "epoch time start: 1578266297.9015527\n",
      "Epoch 6/250\n",
      "\n",
      "Epoch 00006: loss improved from 0.43232 to 0.42461, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.555099964141846\n",
      " - 18s - loss: 0.4246 - acc: 0.8710 - f1_m: 0.8710 - precision_m: 0.8710 - recall_m: 0.8710 - tp_m: 54.0000 - fp_m: 8.0000 - tn_m: 54.0000 - fn_m: 8.0000 - val_loss: 0.4352 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578266315.4580219\n",
      "Epoch 7/250\n",
      "\n",
      "Epoch 00007: loss improved from 0.42461 to 0.36946, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.63236355781555\n",
      " - 18s - loss: 0.3695 - acc: 0.8871 - f1_m: 0.8871 - precision_m: 0.8871 - recall_m: 0.8871 - tp_m: 55.0000 - fp_m: 7.0000 - tn_m: 55.0000 - fn_m: 7.0000 - val_loss: 0.3885 - val_acc: 0.7647 - val_f1_m: 0.7647 - val_precision_m: 0.7647 - val_recall_m: 0.7647 - val_tp_m: 13.0000 - val_fp_m: 4.0000 - val_tn_m: 13.0000 - val_fn_m: 4.0000\n",
      "epoch time start: 1578266333.091848\n",
      "Epoch 8/250\n",
      "\n",
      "Epoch 00008: loss improved from 0.36946 to 0.33672, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.832333087921143\n",
      " - 18s - loss: 0.3367 - acc: 0.9194 - f1_m: 0.9194 - precision_m: 0.9194 - recall_m: 0.9194 - tp_m: 57.0000 - fp_m: 5.0000 - tn_m: 57.0000 - fn_m: 5.0000 - val_loss: 0.7026 - val_acc: 0.6471 - val_f1_m: 0.6471 - val_precision_m: 0.6471 - val_recall_m: 0.6471 - val_tp_m: 11.0000 - val_fp_m: 6.0000 - val_tn_m: 11.0000 - val_fn_m: 6.0000\n",
      "epoch time start: 1578266350.925434\n",
      "Epoch 9/250\n",
      "\n",
      "Epoch 00009: loss improved from 0.33672 to 0.28853, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.650516986846924\n",
      " - 18s - loss: 0.2885 - acc: 0.9355 - f1_m: 0.9355 - precision_m: 0.9355 - recall_m: 0.9355 - tp_m: 58.0000 - fp_m: 4.0000 - tn_m: 58.0000 - fn_m: 4.0000 - val_loss: 0.7695 - val_acc: 0.6471 - val_f1_m: 0.6471 - val_precision_m: 0.6471 - val_recall_m: 0.6471 - val_tp_m: 11.0000 - val_fp_m: 6.0000 - val_tn_m: 11.0000 - val_fn_m: 6.0000\n",
      "epoch time start: 1578266368.577364\n",
      "Epoch 10/250\n",
      "\n",
      "Epoch 00010: loss improved from 0.28853 to 0.27886, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 18.028249740600586\n",
      " - 18s - loss: 0.2789 - acc: 0.8710 - f1_m: 0.8710 - precision_m: 0.8710 - recall_m: 0.8710 - tp_m: 54.0000 - fp_m: 8.0000 - tn_m: 54.0000 - fn_m: 8.0000 - val_loss: 0.5656 - val_acc: 0.7059 - val_f1_m: 0.7059 - val_precision_m: 0.7059 - val_recall_m: 0.7059 - val_tp_m: 12.0000 - val_fp_m: 5.0000 - val_tn_m: 12.0000 - val_fn_m: 5.0000\n",
      "epoch time start: 1578266386.6073792\n",
      "Epoch 11/250\n",
      "\n",
      "Epoch 00011: loss improved from 0.27886 to 0.23222, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.829754114151\n",
      " - 18s - loss: 0.2322 - acc: 0.9516 - f1_m: 0.9516 - precision_m: 0.9516 - recall_m: 0.9516 - tp_m: 59.0000 - fp_m: 3.0000 - tn_m: 59.0000 - fn_m: 3.0000 - val_loss: 0.3695 - val_acc: 0.7647 - val_f1_m: 0.7647 - val_precision_m: 0.7647 - val_recall_m: 0.7647 - val_tp_m: 13.0000 - val_fp_m: 4.0000 - val_tn_m: 13.0000 - val_fn_m: 4.0000\n",
      "epoch time start: 1578266404.4387655\n",
      "Epoch 12/250\n",
      "\n",
      "Epoch 00012: loss improved from 0.23222 to 0.22648, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.82726001739502\n",
      " - 18s - loss: 0.2265 - acc: 0.9355 - f1_m: 0.9355 - precision_m: 0.9355 - recall_m: 0.9355 - tp_m: 58.0000 - fp_m: 4.0000 - tn_m: 58.0000 - fn_m: 4.0000 - val_loss: 0.2606 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578266422.2676013\n",
      "Epoch 13/250\n",
      "\n",
      "Epoch 00013: loss improved from 0.22648 to 0.21203, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.577346086502075\n",
      " - 18s - loss: 0.2120 - acc: 0.9355 - f1_m: 0.9355 - precision_m: 0.9355 - recall_m: 0.9355 - tp_m: 58.0000 - fp_m: 4.0000 - tn_m: 58.0000 - fn_m: 4.0000 - val_loss: 0.2451 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578266439.846339\n",
      "Epoch 14/250\n",
      "\n",
      "Epoch 00014: loss improved from 0.21203 to 0.18502, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.519365549087524\n",
      " - 18s - loss: 0.1850 - acc: 0.9516 - f1_m: 0.9516 - precision_m: 0.9516 - recall_m: 0.9516 - tp_m: 59.0000 - fp_m: 3.0000 - tn_m: 59.0000 - fn_m: 3.0000 - val_loss: 0.2434 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578266457.3670907\n",
      "Epoch 15/250\n",
      "\n",
      "Epoch 00015: loss improved from 0.18502 to 0.18261, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.985100984573364\n",
      " - 18s - loss: 0.1826 - acc: 0.9677 - f1_m: 0.9677 - precision_m: 0.9677 - recall_m: 0.9677 - tp_m: 60.0000 - fp_m: 2.0000 - tn_m: 60.0000 - fn_m: 2.0000 - val_loss: 0.3399 - val_acc: 0.7647 - val_f1_m: 0.7647 - val_precision_m: 0.7647 - val_recall_m: 0.7647 - val_tp_m: 13.0000 - val_fp_m: 4.0000 - val_tn_m: 13.0000 - val_fn_m: 4.0000\n",
      "epoch time start: 1578266475.3540235\n",
      "Epoch 16/250\n",
      "\n",
      "Epoch 00016: loss improved from 0.18261 to 0.14147, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.546756744384766\n",
      " - 18s - loss: 0.1415 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - tp_m: 61.0000 - fp_m: 1.0000 - tn_m: 61.0000 - fn_m: 1.0000 - val_loss: 0.5824 - val_acc: 0.7059 - val_f1_m: 0.7059 - val_precision_m: 0.7059 - val_recall_m: 0.7059 - val_tp_m: 12.0000 - val_fp_m: 5.0000 - val_tn_m: 12.0000 - val_fn_m: 5.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578266492.902536\n",
      "Epoch 17/250\n",
      "\n",
      "Epoch 00017: loss improved from 0.14147 to 0.13543, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.927507162094116\n",
      " - 18s - loss: 0.1354 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - tp_m: 61.0000 - fp_m: 1.0000 - tn_m: 61.0000 - fn_m: 1.0000 - val_loss: 0.7048 - val_acc: 0.7059 - val_f1_m: 0.7059 - val_precision_m: 0.7059 - val_recall_m: 0.7059 - val_tp_m: 12.0000 - val_fp_m: 5.0000 - val_tn_m: 12.0000 - val_fn_m: 5.0000\n",
      "epoch time start: 1578266510.8315995\n",
      "Epoch 18/250\n",
      "\n",
      "Epoch 00018: loss improved from 0.13543 to 0.13488, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.551703691482544\n",
      " - 18s - loss: 0.1349 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - tp_m: 61.0000 - fp_m: 1.0000 - tn_m: 61.0000 - fn_m: 1.0000 - val_loss: 0.5050 - val_acc: 0.7647 - val_f1_m: 0.7647 - val_precision_m: 0.7647 - val_recall_m: 0.7647 - val_tp_m: 13.0000 - val_fp_m: 4.0000 - val_tn_m: 13.0000 - val_fn_m: 4.0000\n",
      "epoch time start: 1578266528.3848667\n",
      "Epoch 19/250\n",
      "\n",
      "Epoch 00019: loss improved from 0.13488 to 0.12543, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.57961416244507\n",
      " - 18s - loss: 0.1254 - acc: 0.9677 - f1_m: 0.9677 - precision_m: 0.9677 - recall_m: 0.9677 - tp_m: 60.0000 - fp_m: 2.0000 - tn_m: 60.0000 - fn_m: 2.0000 - val_loss: 0.2578 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578266545.967828\n",
      "Epoch 20/250\n",
      "\n",
      "Epoch 00020: loss improved from 0.12543 to 0.12298, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.90371012687683\n",
      " - 18s - loss: 0.1230 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - tp_m: 61.0000 - fp_m: 1.0000 - tn_m: 61.0000 - fn_m: 1.0000 - val_loss: 0.2413 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266563.8729045\n",
      "Epoch 21/250\n",
      "\n",
      "Epoch 00021: loss improved from 0.12298 to 0.10226, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.430919647216797\n",
      " - 17s - loss: 0.1023 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - tp_m: 61.0000 - fp_m: 1.0000 - tn_m: 61.0000 - fn_m: 1.0000 - val_loss: 0.3751 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578266581.3054185\n",
      "Epoch 22/250\n",
      "\n",
      "Epoch 00022: loss improved from 0.10226 to 0.09041, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.382932901382446\n",
      " - 17s - loss: 0.0904 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - tp_m: 61.0000 - fp_m: 1.0000 - tn_m: 61.0000 - fn_m: 1.0000 - val_loss: 0.3149 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578266598.6900554\n",
      "Epoch 23/250\n",
      "\n",
      "Epoch 00023: loss improved from 0.09041 to 0.06070, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.42716383934021\n",
      " - 17s - loss: 0.0607 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2016 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266616.1186073\n",
      "Epoch 24/250\n",
      "\n",
      "Epoch 00024: loss did not improve\n",
      "epoch time measured: 17.59347939491272\n",
      " - 18s - loss: 0.0651 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2393 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578266633.7136092\n",
      "Epoch 25/250\n",
      "\n",
      "Epoch 00025: loss improved from 0.06070 to 0.05618, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.49902033805847\n",
      " - 17s - loss: 0.0562 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3842 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578266651.2139406\n",
      "Epoch 26/250\n",
      "\n",
      "Epoch 00026: loss improved from 0.05618 to 0.05240, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.40743136405945\n",
      " - 17s - loss: 0.0524 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.3714 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578266668.622826\n",
      "Epoch 27/250\n",
      "\n",
      "Epoch 00027: loss did not improve\n",
      "epoch time measured: 17.931758880615234\n",
      " - 18s - loss: 0.0543 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - tp_m: 61.0000 - fp_m: 1.0000 - tn_m: 61.0000 - fn_m: 1.0000 - val_loss: 0.2067 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578266686.5556552\n",
      "Epoch 28/250\n",
      "\n",
      "Epoch 00028: loss improved from 0.05240 to 0.02948, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.75499725341797\n",
      " - 18s - loss: 0.0295 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1799 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266704.3122916\n",
      "Epoch 29/250\n",
      "\n",
      "Epoch 00029: loss did not improve\n",
      "epoch time measured: 17.588099479675293\n",
      " - 18s - loss: 0.0331 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2163 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266721.9018319\n",
      "Epoch 30/250\n",
      "\n",
      "Epoch 00030: loss did not improve\n",
      "epoch time measured: 17.24158477783203\n",
      " - 17s - loss: 0.0341 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2470 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266739.1446476\n",
      "Epoch 31/250\n",
      "\n",
      "Epoch 00031: loss improved from 0.02948 to 0.02911, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.65149235725403\n",
      " - 18s - loss: 0.0291 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2039 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266756.7976694\n",
      "Epoch 32/250\n",
      "\n",
      "Epoch 00032: loss improved from 0.02911 to 0.02049, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.56534433364868\n",
      " - 18s - loss: 0.0205 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1748 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578266774.3643477\n",
      "Epoch 33/250\n",
      "\n",
      "Epoch 00033: loss did not improve\n",
      "epoch time measured: 18.004924774169922\n",
      " - 18s - loss: 0.0229 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1593 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266792.3703034\n",
      "Epoch 34/250\n",
      "\n",
      "Epoch 00034: loss improved from 0.02049 to 0.01566, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.94420289993286\n",
      " - 18s - loss: 0.0157 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1700 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578266810.31597\n",
      "Epoch 35/250\n",
      "\n",
      "Epoch 00035: loss did not improve\n",
      "epoch time measured: 17.655597925186157\n",
      " - 18s - loss: 0.0200 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1935 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578266827.9726777\n",
      "Epoch 36/250\n",
      "\n",
      "Epoch 00036: loss improved from 0.01566 to 0.01311, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.716346979141235\n",
      " - 18s - loss: 0.0131 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2174 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266845.6910808\n",
      "Epoch 37/250\n",
      "\n",
      "Epoch 00037: loss improved from 0.01311 to 0.01266, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.32876706123352\n",
      " - 17s - loss: 0.0127 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2205 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266863.0214252\n",
      "Epoch 38/250\n",
      "\n",
      "Epoch 00038: loss did not improve\n",
      "epoch time measured: 17.532662630081177\n",
      " - 18s - loss: 0.0156 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1752 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266880.555308\n",
      "Epoch 39/250\n",
      "\n",
      "Epoch 00039: loss improved from 0.01266 to 0.01207, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.760946035385132\n",
      " - 18s - loss: 0.0121 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1348 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266898.317677\n",
      "Epoch 40/250\n",
      "\n",
      "Epoch 00040: loss improved from 0.01207 to 0.01027, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.74876570701599\n",
      " - 18s - loss: 0.0103 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1311 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266916.0679834\n",
      "Epoch 41/250\n",
      "\n",
      "Epoch 00041: loss improved from 0.01027 to 0.00852, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.58031153678894\n",
      " - 18s - loss: 0.0085 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1486 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266933.649544\n",
      "Epoch 42/250\n",
      "\n",
      "Epoch 00042: loss did not improve\n",
      "epoch time measured: 17.38488507270813\n",
      " - 17s - loss: 0.0101 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1525 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266951.0355637\n",
      "Epoch 43/250\n",
      "\n",
      "Epoch 00043: loss improved from 0.00852 to 0.00831, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.51483964920044\n",
      " - 18s - loss: 0.0083 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1351 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266968.5517457\n",
      "Epoch 44/250\n",
      "\n",
      "Epoch 00044: loss improved from 0.00831 to 0.00746, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.611859798431396\n",
      " - 18s - loss: 0.0075 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1175 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578266986.1653864\n",
      "Epoch 45/250\n",
      "\n",
      "Epoch 00045: loss improved from 0.00746 to 0.00624, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.60231876373291\n",
      " - 18s - loss: 0.0062 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1072 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267003.769166\n",
      "Epoch 46/250\n",
      "\n",
      "Epoch 00046: loss improved from 0.00624 to 0.00588, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.666240692138672\n",
      " - 18s - loss: 0.0059 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1132 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267021.4367092\n",
      "Epoch 47/250\n",
      "\n",
      "Epoch 00047: loss improved from 0.00588 to 0.00469, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.715787410736084\n",
      " - 18s - loss: 0.0047 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1376 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267039.1538424\n",
      "Epoch 48/250\n",
      "\n",
      "Epoch 00048: loss improved from 0.00469 to 0.00446, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.60516595840454\n",
      " - 18s - loss: 0.0045 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1781 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578267056.7603302\n",
      "Epoch 49/250\n",
      "\n",
      "Epoch 00049: loss did not improve\n",
      "epoch time measured: 17.997292280197144\n",
      " - 18s - loss: 0.0047 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2044 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578267074.7590864\n",
      "Epoch 50/250\n",
      "\n",
      "Epoch 00050: loss improved from 0.00446 to 0.00427, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.78045344352722\n",
      " - 18s - loss: 0.0043 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2171 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578267092.5407956\n",
      "Epoch 51/250\n",
      "\n",
      "Epoch 00051: loss improved from 0.00427 to 0.00419, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.611228942871094\n",
      " - 18s - loss: 0.0042 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.2017 - val_acc: 0.8235 - val_f1_m: 0.8235 - val_precision_m: 0.8235 - val_recall_m: 0.8235 - val_tp_m: 14.0000 - val_fp_m: 3.0000 - val_tn_m: 14.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578267110.1532931\n",
      "Epoch 52/250\n",
      "\n",
      "Epoch 00052: loss improved from 0.00419 to 0.00388, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.61116647720337\n",
      " - 18s - loss: 0.0039 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1736 - val_acc: 0.8824 - val_f1_m: 0.8824 - val_precision_m: 0.8824 - val_recall_m: 0.8824 - val_tp_m: 15.0000 - val_fp_m: 2.0000 - val_tn_m: 15.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578267127.766516\n",
      "Epoch 53/250\n",
      "\n",
      "Epoch 00053: loss did not improve\n",
      "epoch time measured: 17.67543339729309\n",
      " - 18s - loss: 0.0039 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1317 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267145.4430737\n",
      "Epoch 54/250\n",
      "\n",
      "Epoch 00054: loss improved from 0.00388 to 0.00309, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.732813358306885\n",
      " - 18s - loss: 0.0031 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1017 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267163.1771584\n",
      "Epoch 55/250\n",
      "\n",
      "Epoch 00055: loss improved from 0.00309 to 0.00253, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.694583415985107\n",
      " - 18s - loss: 0.0025 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0907 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267180.8730676\n",
      "Epoch 56/250\n",
      "\n",
      "Epoch 00056: loss did not improve\n",
      "epoch time measured: 17.539506912231445\n",
      " - 18s - loss: 0.0027 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0921 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267198.413663\n",
      "Epoch 57/250\n",
      "\n",
      "Epoch 00057: loss improved from 0.00253 to 0.00222, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.88260531425476\n",
      " - 18s - loss: 0.0022 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1015 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267216.297703\n",
      "Epoch 58/250\n",
      "\n",
      "Epoch 00058: loss improved from 0.00222 to 0.00220, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.289050102233887\n",
      " - 17s - loss: 0.0022 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1126 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267233.5881045\n",
      "Epoch 59/250\n",
      "\n",
      "Epoch 00059: loss did not improve\n",
      "epoch time measured: 17.291869640350342\n",
      " - 17s - loss: 0.0025 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1214 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267250.8812551\n",
      "Epoch 60/250\n",
      "\n",
      "Epoch 00060: loss did not improve\n",
      "epoch time measured: 17.685640573501587\n",
      " - 18s - loss: 0.0024 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1262 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267268.5679002\n",
      "Epoch 61/250\n",
      "\n",
      "Epoch 00061: loss did not improve\n",
      "epoch time measured: 17.768240451812744\n",
      " - 18s - loss: 0.0023 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1276 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267286.3372803\n",
      "Epoch 62/250\n",
      "\n",
      "Epoch 00062: loss improved from 0.00220 to 0.00162, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.982534885406494\n",
      " - 18s - loss: 0.0016 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1241 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267304.3212306\n",
      "Epoch 63/250\n",
      "\n",
      "Epoch 00063: loss did not improve\n",
      "epoch time measured: 17.504855394363403\n",
      " - 18s - loss: 0.0019 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1165 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267321.8276806\n",
      "Epoch 64/250\n",
      "\n",
      "Epoch 00064: loss did not improve\n",
      "epoch time measured: 17.349945306777954\n",
      " - 17s - loss: 0.0017 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.1074 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267339.178677\n",
      "Epoch 65/250\n",
      "\n",
      "Epoch 00065: loss did not improve\n",
      "epoch time measured: 17.29487633705139\n",
      " - 17s - loss: 0.0019 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0989 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578267356.4747255\n",
      "Epoch 66/250\n",
      "\n",
      "Epoch 00066: loss did not improve\n",
      "epoch time measured: 17.68193531036377\n",
      " - 18s - loss: 0.0016 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0920 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267374.1577744\n",
      "Epoch 67/250\n",
      "\n",
      "Epoch 00067: loss improved from 0.00162 to 0.00154, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.31171941757202\n",
      " - 17s - loss: 0.0015 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0869 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267391.4712691\n",
      "Epoch 68/250\n",
      "\n",
      "Epoch 00068: loss improved from 0.00154 to 0.00149, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.877522230148315\n",
      " - 18s - loss: 0.0015 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0843 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267409.3503559\n",
      "Epoch 69/250\n",
      "\n",
      "Epoch 00069: loss improved from 0.00149 to 0.00129, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.831509590148926\n",
      " - 18s - loss: 0.0013 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0840 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267427.1833324\n",
      "Epoch 70/250\n",
      "\n",
      "Epoch 00070: loss improved from 0.00129 to 0.00115, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.831711769104004\n",
      " - 18s - loss: 0.0011 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0849 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267445.016909\n",
      "Epoch 71/250\n",
      "\n",
      "Epoch 00071: loss did not improve\n",
      "epoch time measured: 17.57761311531067\n",
      " - 18s - loss: 0.0015 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0852 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267462.595605\n",
      "Epoch 72/250\n",
      "\n",
      "Epoch 00072: loss did not improve\n",
      "epoch time measured: 17.69489574432373\n",
      " - 18s - loss: 0.0013 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0849 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267480.291633\n",
      "Epoch 73/250\n",
      "\n",
      "Epoch 00073: loss did not improve\n",
      "epoch time measured: 17.215532779693604\n",
      " - 17s - loss: 0.0014 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0843 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267497.508339\n",
      "Epoch 74/250\n",
      "\n",
      "Epoch 00074: loss did not improve\n",
      "epoch time measured: 18.023311853408813\n",
      " - 18s - loss: 0.0012 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0831 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267515.532979\n",
      "Epoch 75/250\n",
      "\n",
      "Epoch 00075: loss did not improve\n",
      "epoch time measured: 17.557416915893555\n",
      " - 18s - loss: 0.0013 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0812 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267533.09146\n",
      "Epoch 76/250\n",
      "\n",
      "Epoch 00076: loss improved from 0.00115 to 0.00109, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.549294471740723\n",
      " - 18s - loss: 0.0011 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0793 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267550.6425354\n",
      "Epoch 77/250\n",
      "\n",
      "Epoch 00077: loss did not improve\n",
      "epoch time measured: 18.11211395263672\n",
      " - 18s - loss: 0.0012 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0768 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267568.7557924\n",
      "Epoch 78/250\n",
      "\n",
      "Epoch 00078: loss improved from 0.00109 to 0.00102, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.997456073760986\n",
      " - 18s - loss: 0.0010 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0746 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267586.7545335\n",
      "Epoch 79/250\n",
      "\n",
      "Epoch 00079: loss did not improve\n",
      "epoch time measured: 17.476452350616455\n",
      " - 17s - loss: 0.0012 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0727 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267604.2321184\n",
      "Epoch 80/250\n",
      "\n",
      "Epoch 00080: loss did not improve\n",
      "epoch time measured: 17.187116861343384\n",
      " - 17s - loss: 0.0011 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0714 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267621.4203947\n",
      "Epoch 81/250\n",
      "\n",
      "Epoch 00081: loss did not improve\n",
      "epoch time measured: 17.539191246032715\n",
      " - 18s - loss: 0.0014 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0707 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267638.9607368\n",
      "Epoch 82/250\n",
      "\n",
      "Epoch 00082: loss did not improve\n",
      "epoch time measured: 17.47514247894287\n",
      " - 17s - loss: 0.0011 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0704 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578267656.4374526\n",
      "Epoch 83/250\n",
      "\n",
      "Epoch 00083: loss did not improve\n",
      "epoch time measured: 17.80473232269287\n",
      " - 18s - loss: 0.0011 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0700 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267674.24367\n",
      "Epoch 84/250\n",
      "\n",
      "Epoch 00084: loss improved from 0.00102 to 0.00102, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.743468761444092\n",
      " - 18s - loss: 0.0010 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0698 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267691.9883707\n",
      "Epoch 85/250\n",
      "\n",
      "Epoch 00085: loss did not improve\n",
      "epoch time measured: 17.61655616760254\n",
      " - 18s - loss: 0.0011 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0694 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267709.6060352\n",
      "Epoch 86/250\n",
      "\n",
      "Epoch 00086: loss improved from 0.00102 to 0.00091, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.866654634475708\n",
      " - 18s - loss: 9.1417e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0692 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267727.4744318\n",
      "Epoch 87/250\n",
      "\n",
      "Epoch 00087: loss did not improve\n",
      "epoch time measured: 17.53326678276062\n",
      " - 18s - loss: 0.0010 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0692 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267745.0092003\n",
      "Epoch 88/250\n",
      "\n",
      "Epoch 00088: loss improved from 0.00091 to 0.00091, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.79352879524231\n",
      " - 18s - loss: 9.0668e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0694 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267762.804318\n",
      "Epoch 89/250\n",
      "\n",
      "Epoch 00089: loss did not improve\n",
      "epoch time measured: 17.44564461708069\n",
      " - 17s - loss: 9.5321e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0693 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267780.2511017\n",
      "Epoch 90/250\n",
      "\n",
      "Epoch 00090: loss did not improve\n",
      "epoch time measured: 17.38320565223694\n",
      " - 17s - loss: 0.0010 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0690 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267797.635584\n",
      "Epoch 91/250\n",
      "\n",
      "Epoch 00091: loss did not improve\n",
      "epoch time measured: 17.56627869606018\n",
      " - 18s - loss: 9.1240e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0683 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578267815.2030098\n",
      "Epoch 92/250\n",
      "\n",
      "Epoch 00092: loss improved from 0.00091 to 0.00084, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.848244428634644\n",
      " - 18s - loss: 8.3543e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0674 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267833.0530517\n",
      "Epoch 93/250\n",
      "\n",
      "Epoch 00093: loss improved from 0.00084 to 0.00074, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.762518882751465\n",
      " - 18s - loss: 7.3583e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0669 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267850.8169127\n",
      "Epoch 94/250\n",
      "\n",
      "Epoch 00094: loss did not improve\n",
      "epoch time measured: 17.356146335601807\n",
      " - 17s - loss: 8.1556e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0667 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267868.1741602\n",
      "Epoch 95/250\n",
      "\n",
      "Epoch 00095: loss did not improve\n",
      "epoch time measured: 17.407971143722534\n",
      " - 17s - loss: 7.9420e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0668 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267885.5834804\n",
      "Epoch 96/250\n",
      "\n",
      "Epoch 00096: loss did not improve\n",
      "epoch time measured: 17.62369728088379\n",
      " - 18s - loss: 9.4681e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0671 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267903.2084186\n",
      "Epoch 97/250\n",
      "\n",
      "Epoch 00097: loss did not improve\n",
      "epoch time measured: 17.633668661117554\n",
      " - 18s - loss: 7.8468e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0674 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267920.843182\n",
      "Epoch 98/250\n",
      "\n",
      "Epoch 00098: loss did not improve\n",
      "epoch time measured: 18.021722316741943\n",
      " - 18s - loss: 8.1930e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0678 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267938.865982\n",
      "Epoch 99/250\n",
      "\n",
      "Epoch 00099: loss did not improve\n",
      "epoch time measured: 18.147910118103027\n",
      " - 18s - loss: 8.7264e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0683 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578267957.0149858\n",
      "Epoch 100/250\n",
      "\n",
      "Epoch 00100: loss did not improve\n",
      "epoch time measured: 17.648056983947754\n",
      " - 18s - loss: 8.5633e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0690 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267974.664178\n",
      "Epoch 101/250\n",
      "\n",
      "Epoch 00101: loss did not improve\n",
      "epoch time measured: 17.2295823097229\n",
      " - 17s - loss: 7.9052e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0696 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578267991.894799\n",
      "Epoch 102/250\n",
      "\n",
      "Epoch 00102: loss did not improve\n",
      "epoch time measured: 17.190048933029175\n",
      " - 17s - loss: 9.0472e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0698 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268009.0860188\n",
      "Epoch 103/250\n",
      "\n",
      "Epoch 00103: loss improved from 0.00074 to 0.00069, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.64992380142212\n",
      " - 18s - loss: 6.8806e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0698 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268026.7374356\n",
      "Epoch 104/250\n",
      "\n",
      "Epoch 00104: loss did not improve\n",
      "epoch time measured: 17.6531023979187\n",
      " - 18s - loss: 8.8158e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0695 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268044.3918264\n",
      "Epoch 105/250\n",
      "\n",
      "Epoch 00105: loss did not improve\n",
      "epoch time measured: 17.093491554260254\n",
      " - 17s - loss: 7.4060e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0687 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268061.4863741\n",
      "Epoch 106/250\n",
      "\n",
      "Epoch 00106: loss improved from 0.00069 to 0.00066, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.702762603759766\n",
      " - 18s - loss: 6.6252e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0680 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268079.1905174\n",
      "Epoch 107/250\n",
      "\n",
      "Epoch 00107: loss did not improve\n",
      "epoch time measured: 17.490684032440186\n",
      " - 17s - loss: 7.8739e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0674 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268096.6822515\n",
      "Epoch 108/250\n",
      "\n",
      "Epoch 00108: loss did not improve\n",
      "epoch time measured: 17.59931755065918\n",
      " - 18s - loss: 7.6179e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0669 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268114.2831092\n",
      "Epoch 109/250\n",
      "\n",
      "Epoch 00109: loss did not improve\n",
      "epoch time measured: 17.483147144317627\n",
      " - 17s - loss: 8.2262e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0669 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268131.767368\n",
      "Epoch 110/250\n",
      "\n",
      "Epoch 00110: loss did not improve\n",
      "epoch time measured: 17.868298053741455\n",
      " - 18s - loss: 6.8001e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0671 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268149.6371717\n",
      "Epoch 111/250\n",
      "\n",
      "Epoch 00111: loss did not improve\n",
      "epoch time measured: 17.171080827713013\n",
      " - 17s - loss: 8.0352e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0676 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578268166.80969\n",
      "Epoch 112/250\n",
      "\n",
      "Epoch 00112: loss improved from 0.00066 to 0.00061, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.612370014190674\n",
      " - 18s - loss: 6.1195e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0684 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578268184.4234982\n",
      "Epoch 113/250\n",
      "\n",
      "Epoch 00113: loss did not improve\n",
      "epoch time measured: 17.475544691085815\n",
      " - 17s - loss: 6.3072e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0696 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578268201.9002125\n",
      "Epoch 114/250\n",
      "\n",
      "Epoch 00114: loss improved from 0.00061 to 0.00058, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 18.169621467590332\n",
      " - 18s - loss: 5.8465e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0707 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578268220.0709877\n",
      "Epoch 115/250\n",
      "\n",
      "Epoch 00115: loss did not improve\n",
      "epoch time measured: 17.813554286956787\n",
      " - 18s - loss: 6.9076e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0716 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578268237.8858194\n",
      "Epoch 116/250\n",
      "\n",
      "Epoch 00116: loss did not improve\n",
      "epoch time measured: 17.392889499664307\n",
      " - 17s - loss: 6.6298e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0722 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578268255.2799776\n",
      "Epoch 117/250\n",
      "\n",
      "Epoch 00117: loss did not improve\n",
      "epoch time measured: 17.23207139968872\n",
      " - 17s - loss: 6.3711e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0731 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578268272.5131276\n",
      "Epoch 118/250\n",
      "\n",
      "Epoch 00118: loss did not improve\n",
      "epoch time measured: 17.730239152908325\n",
      " - 18s - loss: 6.1776e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0736 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578268290.2444541\n",
      "Epoch 119/250\n",
      "\n",
      "Epoch 00119: loss did not improve\n",
      "epoch time measured: 17.342503309249878\n",
      " - 17s - loss: 6.2902e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0733 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578268307.5883062\n",
      "Epoch 120/250\n",
      "\n",
      "Epoch 00120: loss did not improve\n",
      "epoch time measured: 17.750022172927856\n",
      " - 18s - loss: 7.7114e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0722 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578268325.339506\n",
      "Epoch 121/250\n",
      "\n",
      "Epoch 00121: loss improved from 0.00058 to 0.00051, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.545626878738403\n",
      " - 18s - loss: 5.1443e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0710 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578268342.8865292\n",
      "Epoch 122/250\n",
      "\n",
      "Epoch 00122: loss did not improve\n",
      "epoch time measured: 17.917773246765137\n",
      " - 18s - loss: 7.0112e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0694 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578268360.8057115\n",
      "Epoch 123/250\n",
      "\n",
      "Epoch 00123: loss improved from 0.00051 to 0.00042, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.75418710708618\n",
      " - 18s - loss: 4.1669e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0680 - val_acc: 0.9412 - val_f1_m: 0.9412 - val_precision_m: 0.9412 - val_recall_m: 0.9412 - val_tp_m: 16.0000 - val_fp_m: 1.0000 - val_tn_m: 16.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578268378.5616283\n",
      "Epoch 124/250\n",
      "\n",
      "Epoch 00124: loss did not improve\n",
      "epoch time measured: 17.232118368148804\n",
      " - 17s - loss: 6.2317e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0670 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268395.7949247\n",
      "Epoch 125/250\n",
      "\n",
      "Epoch 00125: loss did not improve\n",
      "epoch time measured: 17.527768850326538\n",
      " - 18s - loss: 6.1437e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0664 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268413.324262\n",
      "Epoch 126/250\n",
      "\n",
      "Epoch 00126: loss did not improve\n",
      "epoch time measured: 18.357239246368408\n",
      " - 18s - loss: 5.3873e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0661 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268431.6830304\n",
      "Epoch 127/250\n",
      "\n",
      "Epoch 00127: loss did not improve\n",
      "epoch time measured: 17.630435943603516\n",
      " - 18s - loss: 5.4152e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0659 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268449.3145413\n",
      "Epoch 128/250\n",
      "\n",
      "Epoch 00128: loss did not improve\n",
      "epoch time measured: 17.642975568771362\n",
      " - 18s - loss: 5.3939e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0658 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268466.9589791\n",
      "Epoch 129/250\n",
      "\n",
      "Epoch 00129: loss did not improve\n",
      "epoch time measured: 17.825193881988525\n",
      " - 18s - loss: 5.3947e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0658 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268484.7853243\n",
      "Epoch 130/250\n",
      "\n",
      "Epoch 00130: loss did not improve\n",
      "epoch time measured: 17.611470937728882\n",
      " - 18s - loss: 6.2730e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0655 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268502.3979495\n",
      "Epoch 131/250\n",
      "\n",
      "Epoch 00131: loss did not improve\n",
      "epoch time measured: 17.57151222229004\n",
      " - 18s - loss: 6.0871e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0649 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268519.9708314\n",
      "Epoch 132/250\n",
      "\n",
      "Epoch 00132: loss did not improve\n",
      "epoch time measured: 17.804076433181763\n",
      " - 18s - loss: 5.1007e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0645 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268537.7761354\n",
      "Epoch 133/250\n",
      "\n",
      "Epoch 00133: loss did not improve\n",
      "epoch time measured: 17.48957657814026\n",
      " - 17s - loss: 5.0173e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0643 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578268555.2667723\n",
      "Epoch 134/250\n",
      "\n",
      "Epoch 00134: loss did not improve\n",
      "epoch time measured: 17.703036308288574\n",
      " - 18s - loss: 5.4789e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0638 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268572.9710224\n",
      "Epoch 135/250\n",
      "\n",
      "Epoch 00135: loss did not improve\n",
      "epoch time measured: 17.48184633255005\n",
      " - 17s - loss: 5.5179e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0631 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268590.4540217\n",
      "Epoch 136/250\n",
      "\n",
      "Epoch 00136: loss did not improve\n",
      "epoch time measured: 17.547556400299072\n",
      " - 18s - loss: 6.5317e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0624 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268608.0032241\n",
      "Epoch 137/250\n",
      "\n",
      "Epoch 00137: loss did not improve\n",
      "epoch time measured: 17.844898462295532\n",
      " - 18s - loss: 5.2557e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0618 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268625.8493557\n",
      "Epoch 138/250\n",
      "\n",
      "Epoch 00138: loss did not improve\n",
      "epoch time measured: 17.79516625404358\n",
      " - 18s - loss: 5.4695e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0612 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268643.6456325\n",
      "Epoch 139/250\n",
      "\n",
      "Epoch 00139: loss did not improve\n",
      "epoch time measured: 17.221483945846558\n",
      " - 17s - loss: 5.2351e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0607 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268660.8683429\n",
      "Epoch 140/250\n",
      "\n",
      "Epoch 00140: loss did not improve\n",
      "epoch time measured: 17.830810546875\n",
      " - 18s - loss: 5.6466e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0603 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268678.7001486\n",
      "Epoch 141/250\n",
      "\n",
      "Epoch 00141: loss did not improve\n",
      "epoch time measured: 17.58678126335144\n",
      " - 18s - loss: 4.7978e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0600 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268696.2880764\n",
      "Epoch 142/250\n",
      "\n",
      "Epoch 00142: loss did not improve\n",
      "epoch time measured: 17.158478498458862\n",
      " - 17s - loss: 4.3860e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0596 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268713.4477232\n",
      "Epoch 143/250\n",
      "\n",
      "Epoch 00143: loss did not improve\n",
      "epoch time measured: 17.625863313674927\n",
      " - 18s - loss: 5.0819e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0593 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268731.0747957\n",
      "Epoch 144/250\n",
      "\n",
      "Epoch 00144: loss did not improve\n",
      "epoch time measured: 18.390156030654907\n",
      " - 18s - loss: 4.4876e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0590 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268749.46607\n",
      "Epoch 145/250\n",
      "\n",
      "Epoch 00145: loss did not improve\n",
      "epoch time measured: 17.451990127563477\n",
      " - 17s - loss: 4.3807e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0587 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268766.9191978\n",
      "Epoch 146/250\n",
      "\n",
      "Epoch 00146: loss did not improve\n",
      "epoch time measured: 17.60796809196472\n",
      " - 18s - loss: 5.5503e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0585 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268784.5286994\n",
      "Epoch 147/250\n",
      "\n",
      "Epoch 00147: loss improved from 0.00042 to 0.00040, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 17.457796573638916\n",
      " - 17s - loss: 3.9719e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0582 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268801.9882414\n",
      "Epoch 148/250\n",
      "\n",
      "Epoch 00148: loss did not improve\n",
      "epoch time measured: 17.515432834625244\n",
      " - 18s - loss: 5.1633e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0579 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268819.5049253\n",
      "Epoch 149/250\n",
      "\n",
      "Epoch 00149: loss did not improve\n",
      "epoch time measured: 17.275301218032837\n",
      " - 17s - loss: 5.4110e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0578 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268836.7814105\n",
      "Epoch 150/250\n",
      "\n",
      "Epoch 00150: loss did not improve\n",
      "epoch time measured: 17.346163988113403\n",
      " - 17s - loss: 4.1166e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0576 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time start: 1578268854.1287782\n",
      "Epoch 151/250\n",
      "\n",
      "Epoch 00151: loss did not improve\n",
      "epoch time measured: 17.464759349822998\n",
      " - 17s - loss: 4.1567e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0575 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268871.5949068\n",
      "Epoch 152/250\n",
      "\n",
      "Epoch 00152: loss did not improve\n",
      "epoch time measured: 17.501006364822388\n",
      " - 18s - loss: 4.4030e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0574 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268889.0970762\n",
      "Epoch 153/250\n",
      "\n",
      "Epoch 00153: loss did not improve\n",
      "epoch time measured: 17.328011512756348\n",
      " - 17s - loss: 4.7256e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0573 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268906.42626\n",
      "Epoch 154/250\n",
      "\n",
      "Epoch 00154: loss did not improve\n",
      "epoch time measured: 18.10097646713257\n",
      " - 18s - loss: 4.0349e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0572 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268924.5283597\n",
      "Epoch 155/250\n",
      "\n",
      "Epoch 00155: loss did not improve\n",
      "epoch time measured: 17.546772956848145\n",
      " - 18s - loss: 4.2654e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0572 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268942.0764644\n",
      "Epoch 156/250\n",
      "\n",
      "Epoch 00156: loss did not improve\n",
      "epoch time measured: 17.40918779373169\n",
      " - 17s - loss: 4.0938e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0572 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268959.4867618\n",
      "Epoch 157/250\n",
      "\n",
      "Epoch 00157: loss did not improve\n",
      "epoch time measured: 17.346108198165894\n",
      " - 17s - loss: 5.0854e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0573 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268976.8342838\n",
      "Epoch 158/250\n",
      "\n",
      "Epoch 00158: loss did not improve\n",
      "epoch time measured: 17.343319416046143\n",
      " - 17s - loss: 4.3535e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0574 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578268994.1787295\n",
      "Epoch 159/250\n",
      "\n",
      "Epoch 00159: loss did not improve\n",
      "epoch time measured: 17.54048776626587\n",
      " - 18s - loss: 4.6074e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 62.0000 - fp_m: 0.0000e+00 - tn_m: 62.0000 - fn_m: 0.0000e+00 - val_loss: 0.0575 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000 - val_tp_m: 17.0000 - val_fp_m: 0.0000e+00 - val_tn_m: 17.0000 - val_fn_m: 0.0000e+00\n",
      "epoch time start: 1578269011.72032\n",
      "Epoch 160/250\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'results_data_FINAL.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(filepath)\n",
    "accList=list()\n",
    "precisionList=list()\n",
    "recallList=list()\n",
    "f1List=list()\n",
    "\n",
    "for line in f:\n",
    "    if(str(line[0:13])=='Fold Accuracy'):\n",
    "        listStart1=line.find('[')\n",
    "        listEnd1=line.find(']')\n",
    "        list1=ast.literal_eval(line[listStart1:listEnd1+1])\n",
    "        accList.append(list1)\n",
    "    if(str(line[0:14])=='Fold Precision'):\n",
    "        listStart2=line.find('[')\n",
    "        listEnd2=line.find(']')\n",
    "        list2=ast.literal_eval(line[listStart2:listEnd2+1])\n",
    "        precisionList.append(list2)\n",
    "    if(str(line[0:11])=='Fold Recall'):\n",
    "        listStart3=line.find('[')\n",
    "        listEnd3=line.find(']')\n",
    "        list3=ast.literal_eval(line[listStart3:listEnd3+1])\n",
    "        recallList.append(list3)\n",
    "    if(str(line[0:7])=='Fold F1'):\n",
    "        listStart4=line.find('[')\n",
    "        listEnd4=line.find(']')\n",
    "        list4=ast.literal_eval(line[listStart4:listEnd4+1])\n",
    "        f1List.append(list4)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allAccuracies=np.array(accList)\n",
    "averageAccuracy=np.average(allAccuracies, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allPrecisions=np.array(precisionList)\n",
    "averagePrecisions=np.average(allPrecisions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRecall=np.array(recallList)\n",
    "averageRecall=np.average(allRecall, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allF1s=np.array(f1List)\n",
    "averageF1s=np.average(allF1s, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averageAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averagePrecisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averageRecall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averageF1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(resultsFilename, \"a\") as text_file:\n",
    "    print(f\"Average Accuracies List: {str(averageAccuracy)}\", file=text_file)\n",
    "    print(f\"Average Precisions List: {str(averagePrecisions)}\", file=text_file)\n",
    "    print(f\"Average Recalls List: {str(averageRecall)}\", file=text_file)\n",
    "    print(f\"Average F1 List: {str(averageF1s)}\", file=text_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
