{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('MLSTM-FCN/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsFilename='results_data_FINAL.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/paperspace/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/paperspace/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/paperspace/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/paperspace/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/paperspace/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/paperspace/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM, multiply, concatenate, Activation, Masking, Reshape\n",
    "from keras.layers import Conv1D, BatchNormalization, GlobalAveragePooling1D, Permute, Dropout\n",
    "\n",
    "from utils.constants import MAX_NB_VARIABLES, NB_CLASSES_LIST, MAX_TIMESTEPS_LIST\n",
    "from utils.keras_utils import train_model, evaluate_model, set_trainable\n",
    "from utils.layer_utils import AttentionLSTM\n",
    "\n",
    "DATASET_INDEX_0 = 52\n",
    "DATASET_INDEX_1 = 53\n",
    "DATASET_INDEX_2 = 54\n",
    "DATASET_INDEX_3 = 55\n",
    "\n",
    "MAX_TIMESTEPS = MAX_TIMESTEPS_LIST[DATASET_INDEX_0]\n",
    "MAX_NB_VARIABLES = MAX_NB_VARIABLES[DATASET_INDEX_0]\n",
    "NB_CLASS = NB_CLASSES_LIST[DATASET_INDEX_0]\n",
    "\n",
    "TRAINABLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "    ip = Input(shape=(MAX_NB_VARIABLES, MAX_TIMESTEPS))\n",
    "    # stride = 10\n",
    "\n",
    "    # x = Permute((2, 1))(ip)\n",
    "    # x = Conv1D(MAX_NB_VARIABLES // stride, 8, strides=stride, padding='same', activation='relu', use_bias=False,\n",
    "    #            kernel_initializer='he_uniform')(x)  # (None, variables / stride, timesteps)\n",
    "    # x = Permute((2, 1))(x)\n",
    "\n",
    "    #ip1 = K.reshape(ip,shape=(MAX_TIMESTEPS,MAX_NB_VARIABLES))\n",
    "    #x = Permute((2, 1))(ip)\n",
    "    x = Masking()(ip)\n",
    "    x = AttentionLSTM(8)(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "\n",
    "    y = Permute((2, 1))(ip)\n",
    "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "\n",
    "    x = concatenate([x, y])\n",
    "\n",
    "    out = Dense(NB_CLASS, activation='softmax')(x)\n",
    "\n",
    "    model = Model(ip, out)\n",
    "    model.summary()\n",
    "\n",
    "    # add load model code here to fine-tune\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_excite_block(input):\n",
    "    ''' Create a squeeze-excite block\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "        k: width factor\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    filters = input._keras_shape[-1] # channel_axis = -1 for TF\n",
    "\n",
    "    se = GlobalAveragePooling1D()(input)\n",
    "    se = Reshape((1, filters))(se)\n",
    "    se = Dense(filters // 16,  activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = multiply([input, se])\n",
    "    return se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1, 4096)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 4096, 1)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 4096, 128)    1152        permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 4096, 128)    512         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 4096, 128)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 128)       0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 8)         1024        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 128)       1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 4096, 128)    0           activation_1[0][0]               \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 4096, 256)    164096      multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 4096, 256)    1024        conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 4096, 256)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 256)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 256)       0           global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 16)        4096        reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1, 256)       4096        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 4096, 256)    0           activation_2[0][0]               \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 4096, 128)    98432       multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 1, 4096)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 4096, 128)    512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_lstm_1 (AttentionLSTM (None, 8)            295280      masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 4096, 128)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 8)            0           attention_lstm_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 128)          0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 136)          0           dropout_1[0][0]                  \n",
      "                                                                 global_average_pooling1d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            274         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 571,522\n",
      "Trainable params: 570,498\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "Loading train / test dataset :  ../data/eeg_seizure_1/ ../data/eeg_seizure_1/\n",
      "x_train_path: ../data/eeg_seizure_1/X_train.npy\n",
      "Finished processing train dataset..\n",
      "Finished loading test dataset..\n",
      "\n",
      "Number of train samples :  160 Number of test samples :  100\n",
      "Number of classes :  2\n",
      "Sequence length :  4096\n",
      "Class weights :  [1. 1.]\n",
      "y_true - 1 Tensor(\"metrics/tn_m/sub:0\", shape=(?, ?), dtype=float32)\n",
      "Train on 160 samples, validate on 100 samples\n",
      "epoch time start: 1578292161.5966325\n",
      "Epoch 1/250\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.80651, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 24.988611936569214\n",
      " - 25s - loss: 0.8065 - acc: 0.3625 - f1_m: 0.3625 - precision_m: 0.3625 - recall_m: 0.3625 - tp_m: 29.0000 - fp_m: 79.8000 - tn_m: 29.0000 - fn_m: 79.8000 - val_loss: 0.5447 - val_acc: 0.7300 - val_f1_m: 0.7300 - val_precision_m: 0.7300 - val_recall_m: 0.7300 - val_tp_m: 73.0000 - val_fp_m: 27.0000 - val_tn_m: 73.0000 - val_fn_m: 27.0000\n",
      "epoch time start: 1578292186.586694\n",
      "Epoch 2/250\n",
      "\n",
      "Epoch 00002: loss improved from 0.80651 to 0.24950, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.55534863471985\n",
      " - 24s - loss: 0.2495 - acc: 0.8812 - f1_m: 0.8812 - precision_m: 0.8812 - recall_m: 0.8812 - tp_m: 95.4000 - fp_m: 13.4000 - tn_m: 95.4000 - fn_m: 13.4000 - val_loss: 0.1855 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578292210.1437123\n",
      "Epoch 3/250\n",
      "\n",
      "Epoch 00003: loss improved from 0.24950 to 0.21616, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.6679425239563\n",
      " - 24s - loss: 0.2162 - acc: 0.8875 - f1_m: 0.8875 - precision_m: 0.8875 - recall_m: 0.8875 - tp_m: 96.8000 - fp_m: 12.0000 - tn_m: 96.8000 - fn_m: 12.0000 - val_loss: 0.1110 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292233.8131218\n",
      "Epoch 4/250\n",
      "\n",
      "Epoch 00004: loss improved from 0.21616 to 0.15780, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.181467056274414\n",
      " - 23s - loss: 0.1578 - acc: 0.9062 - f1_m: 0.9062 - precision_m: 0.9062 - recall_m: 0.9062 - tp_m: 98.6000 - fp_m: 10.2000 - tn_m: 98.6000 - fn_m: 10.2000 - val_loss: 0.0925 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292256.9958143\n",
      "Epoch 5/250\n",
      "\n",
      "Epoch 00005: loss improved from 0.15780 to 0.14697, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.12114381790161\n",
      " - 23s - loss: 0.1470 - acc: 0.9375 - f1_m: 0.9375 - precision_m: 0.9375 - recall_m: 0.9375 - tp_m: 103.8000 - fp_m: 5.0000 - tn_m: 103.8000 - fn_m: 5.0000 - val_loss: 0.0792 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578292280.1182213\n",
      "Epoch 6/250\n",
      "\n",
      "Epoch 00006: loss improved from 0.14697 to 0.13622, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.068535327911377\n",
      " - 23s - loss: 0.1362 - acc: 0.9375 - f1_m: 0.9375 - precision_m: 0.9375 - recall_m: 0.9375 - tp_m: 102.0000 - fp_m: 6.8000 - tn_m: 102.0000 - fn_m: 6.8000 - val_loss: 0.0790 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578292303.1884842\n",
      "Epoch 7/250\n",
      "\n",
      "Epoch 00007: loss improved from 0.13622 to 0.10504, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.238505601882935\n",
      " - 23s - loss: 0.1050 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 107.0000 - fp_m: 1.8000 - tn_m: 107.0000 - fn_m: 1.8000 - val_loss: 0.0774 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578292326.4282205\n",
      "Epoch 8/250\n",
      "\n",
      "Epoch 00008: loss improved from 0.10504 to 0.10281, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.509897232055664\n",
      " - 24s - loss: 0.1028 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.2000 - fp_m: 1.6000 - tn_m: 107.2000 - fn_m: 1.6000 - val_loss: 0.0757 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578292349.9396071\n",
      "Epoch 9/250\n",
      "\n",
      "Epoch 00009: loss improved from 0.10281 to 0.09180, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.4771249294281\n",
      " - 23s - loss: 0.0918 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 108.2000 - fp_m: 0.6000 - tn_m: 108.2000 - fn_m: 0.6000 - val_loss: 0.0731 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292373.41812\n",
      "Epoch 10/250\n",
      "\n",
      "Epoch 00010: loss did not improve\n",
      "epoch time measured: 23.904894828796387\n",
      " - 24s - loss: 0.0934 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.2000 - fp_m: 1.6000 - tn_m: 107.2000 - fn_m: 1.6000 - val_loss: 0.0716 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292397.3243725\n",
      "Epoch 11/250\n",
      "\n",
      "Epoch 00011: loss did not improve\n",
      "epoch time measured: 23.01165461540222\n",
      " - 23s - loss: 0.0940 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 107.0000 - fp_m: 1.8000 - tn_m: 107.0000 - fn_m: 1.8000 - val_loss: 0.0677 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292420.3373163\n",
      "Epoch 12/250\n",
      "\n",
      "Epoch 00012: loss improved from 0.09180 to 0.07421, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.09999370574951\n",
      " - 23s - loss: 0.0742 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0660 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292443.4389203\n",
      "Epoch 13/250\n",
      "\n",
      "Epoch 00013: loss improved from 0.07421 to 0.07137, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.13416028022766\n",
      " - 23s - loss: 0.0714 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0643 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292466.5746899\n",
      "Epoch 14/250\n",
      "\n",
      "Epoch 00014: loss did not improve\n",
      "epoch time measured: 23.176671504974365\n",
      " - 23s - loss: 0.0815 - acc: 0.9750 - f1_m: 0.9750 - precision_m: 0.9750 - recall_m: 0.9750 - tp_m: 106.8000 - fp_m: 2.0000 - tn_m: 106.8000 - fn_m: 2.0000 - val_loss: 0.0631 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292489.7525244\n",
      "Epoch 15/250\n",
      "\n",
      "Epoch 00015: loss did not improve\n",
      "epoch time measured: 23.111725330352783\n",
      " - 23s - loss: 0.0724 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0625 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292512.8657079\n",
      "Epoch 16/250\n",
      "\n",
      "Epoch 00016: loss did not improve\n",
      "epoch time measured: 22.77060890197754\n",
      " - 23s - loss: 0.0789 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 107.6000 - fp_m: 1.2000 - tn_m: 107.6000 - fn_m: 1.2000 - val_loss: 0.0621 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292535.6378531\n",
      "Epoch 17/250\n",
      "\n",
      "Epoch 00017: loss improved from 0.07137 to 0.05669, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.421584129333496\n",
      " - 23s - loss: 0.0567 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.2000 - fp_m: 1.6000 - tn_m: 107.2000 - fn_m: 1.6000 - val_loss: 0.0606 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292559.0612643\n",
      "Epoch 18/250\n",
      "\n",
      "Epoch 00018: loss did not improve\n",
      "epoch time measured: 23.20314884185791\n",
      " - 23s - loss: 0.0593 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 108.4000 - fp_m: 0.4000 - tn_m: 108.4000 - fn_m: 0.4000 - val_loss: 0.0590 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292582.2655761\n",
      "Epoch 19/250\n",
      "\n",
      "Epoch 00019: loss did not improve\n",
      "epoch time measured: 23.075769424438477\n",
      " - 23s - loss: 0.0630 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.0588 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292605.3425639\n",
      "Epoch 20/250\n",
      "\n",
      "Epoch 00020: loss did not improve\n",
      "epoch time measured: 23.161072969436646\n",
      " - 23s - loss: 0.0586 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.2000 - fp_m: 1.6000 - tn_m: 107.2000 - fn_m: 1.6000 - val_loss: 0.0581 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292628.504896\n",
      "Epoch 21/250\n",
      "\n",
      "Epoch 00021: loss did not improve\n",
      "epoch time measured: 23.349783658981323\n",
      " - 23s - loss: 0.0621 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.0580 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292651.8558764\n",
      "Epoch 22/250\n",
      "\n",
      "Epoch 00022: loss did not improve\n",
      "epoch time measured: 23.04451298713684\n",
      " - 23s - loss: 0.0734 - acc: 0.9750 - f1_m: 0.9750 - precision_m: 0.9750 - recall_m: 0.9750 - tp_m: 106.2000 - fp_m: 2.6000 - tn_m: 106.2000 - fn_m: 2.6000 - val_loss: 0.0583 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292674.901638\n",
      "Epoch 23/250\n",
      "\n",
      "Epoch 00023: loss improved from 0.05669 to 0.04619, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.08191227912903\n",
      " - 23s - loss: 0.0462 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.2000 - fp_m: 1.6000 - tn_m: 107.2000 - fn_m: 1.6000 - val_loss: 0.0581 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292697.9848359\n",
      "Epoch 24/250\n",
      "\n",
      "Epoch 00024: loss did not improve\n",
      "epoch time measured: 22.972702741622925\n",
      " - 23s - loss: 0.0569 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.0570 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292720.9587188\n",
      "Epoch 25/250\n",
      "\n",
      "Epoch 00025: loss did not improve\n",
      "epoch time measured: 23.06851291656494\n",
      " - 23s - loss: 0.0645 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.0557 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292744.0284815\n",
      "Epoch 26/250\n",
      "\n",
      "Epoch 00026: loss did not improve\n",
      "epoch time measured: 23.038377285003662\n",
      " - 23s - loss: 0.0528 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 108.4000 - fp_m: 0.4000 - tn_m: 108.4000 - fn_m: 0.4000 - val_loss: 0.0549 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292767.0680096\n",
      "Epoch 27/250\n",
      "\n",
      "Epoch 00027: loss improved from 0.04619 to 0.04274, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 22.93732237815857\n",
      " - 23s - loss: 0.0427 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.0562 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292790.0066035\n",
      "Epoch 28/250\n",
      "\n",
      "Epoch 00028: loss improved from 0.04274 to 0.03731, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 22.833531618118286\n",
      " - 23s - loss: 0.0373 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0586 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292812.841782\n",
      "Epoch 29/250\n",
      "\n",
      "Epoch 00029: loss did not improve\n",
      "epoch time measured: 23.029305458068848\n",
      " - 23s - loss: 0.0460 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0578 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292835.872163\n",
      "Epoch 30/250\n",
      "\n",
      "Epoch 00030: loss did not improve\n",
      "epoch time measured: 23.014292001724243\n",
      " - 23s - loss: 0.0374 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0552 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578292858.887603\n",
      "Epoch 31/250\n",
      "\n",
      "Epoch 00031: loss improved from 0.03731 to 0.03009, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.524235248565674\n",
      " - 24s - loss: 0.0301 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0531 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578292882.4130685\n",
      "Epoch 32/250\n",
      "\n",
      "Epoch 00032: loss did not improve\n",
      "epoch time measured: 22.872316360473633\n",
      " - 23s - loss: 0.0411 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.0517 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578292905.2866645\n",
      "Epoch 33/250\n",
      "\n",
      "Epoch 00033: loss did not improve\n",
      "epoch time measured: 22.71120595932007\n",
      " - 23s - loss: 0.0446 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0511 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292927.9989643\n",
      "Epoch 34/250\n",
      "\n",
      "Epoch 00034: loss improved from 0.03009 to 0.02775, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.605416774749756\n",
      " - 24s - loss: 0.0278 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0504 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292951.605885\n",
      "Epoch 35/250\n",
      "\n",
      "Epoch 00035: loss did not improve\n",
      "epoch time measured: 23.272844791412354\n",
      " - 23s - loss: 0.0381 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0501 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292974.8799162\n",
      "Epoch 36/250\n",
      "\n",
      "Epoch 00036: loss did not improve\n",
      "epoch time measured: 23.31539034843445\n",
      " - 23s - loss: 0.0489 - acc: 0.9750 - f1_m: 0.9750 - precision_m: 0.9750 - recall_m: 0.9750 - tp_m: 107.4000 - fp_m: 1.4000 - tn_m: 107.4000 - fn_m: 1.4000 - val_loss: 0.0509 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578292998.1963575\n",
      "Epoch 37/250\n",
      "\n",
      "Epoch 00037: loss did not improve\n",
      "epoch time measured: 23.526350736618042\n",
      " - 24s - loss: 0.0313 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0529 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293021.7237802\n",
      "Epoch 38/250\n",
      "\n",
      "Epoch 00038: loss did not improve\n",
      "epoch time measured: 23.665297508239746\n",
      " - 24s - loss: 0.0281 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0551 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293045.390167\n",
      "Epoch 39/250\n",
      "\n",
      "Epoch 00039: loss improved from 0.02775 to 0.02757, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.152904510498047\n",
      " - 23s - loss: 0.0276 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0563 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293068.5444596\n",
      "Epoch 40/250\n",
      "\n",
      "Epoch 00040: loss did not improve\n",
      "epoch time measured: 23.589253425598145\n",
      " - 24s - loss: 0.0450 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 107.0000 - fp_m: 1.8000 - tn_m: 107.0000 - fn_m: 1.8000 - val_loss: 0.0570 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293092.1347802\n",
      "Epoch 41/250\n",
      "\n",
      "Epoch 00041: loss did not improve\n",
      "epoch time measured: 23.495519161224365\n",
      " - 23s - loss: 0.0283 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0568 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293115.6313927\n",
      "Epoch 42/250\n",
      "\n",
      "Epoch 00042: loss improved from 0.02757 to 0.02507, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.518735647201538\n",
      " - 24s - loss: 0.0251 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0560 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293139.1516178\n",
      "Epoch 43/250\n",
      "\n",
      "Epoch 00043: loss did not improve\n",
      "epoch time measured: 22.842230319976807\n",
      " - 23s - loss: 0.0301 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0547 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293161.995067\n",
      "Epoch 44/250\n",
      "\n",
      "Epoch 00044: loss did not improve\n",
      "epoch time measured: 22.972442626953125\n",
      " - 23s - loss: 0.0336 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0534 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293184.968638\n",
      "Epoch 45/250\n",
      "\n",
      "Epoch 00045: loss did not improve\n",
      "epoch time measured: 23.021262645721436\n",
      " - 23s - loss: 0.0596 - acc: 0.9750 - f1_m: 0.9750 - precision_m: 0.9750 - recall_m: 0.9750 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0513 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293207.991389\n",
      "Epoch 46/250\n",
      "\n",
      "Epoch 00046: loss did not improve\n",
      "epoch time measured: 23.115379571914673\n",
      " - 23s - loss: 0.0276 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0470 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293231.1078675\n",
      "Epoch 47/250\n",
      "\n",
      "Epoch 00047: loss did not improve\n",
      "epoch time measured: 23.255391359329224\n",
      " - 23s - loss: 0.0319 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0460 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578293254.3646803\n",
      "Epoch 48/250\n",
      "\n",
      "Epoch 00048: loss did not improve\n",
      "epoch time measured: 23.612637281417847\n",
      " - 24s - loss: 0.0357 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.2000 - fp_m: 1.6000 - tn_m: 107.2000 - fn_m: 1.6000 - val_loss: 0.0465 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578293277.9786553\n",
      "Epoch 49/250\n",
      "\n",
      "Epoch 00049: loss did not improve\n",
      "epoch time measured: 23.44491481781006\n",
      " - 23s - loss: 0.0433 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 107.6000 - fp_m: 1.2000 - tn_m: 107.6000 - fn_m: 1.2000 - val_loss: 0.0459 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578293301.4247525\n",
      "Epoch 50/250\n",
      "\n",
      "Epoch 00050: loss did not improve\n",
      "epoch time measured: 23.110651969909668\n",
      " - 23s - loss: 0.0374 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0439 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578293324.5369275\n",
      "Epoch 51/250\n",
      "\n",
      "Epoch 00051: loss did not improve\n",
      "epoch time measured: 22.869211435317993\n",
      " - 23s - loss: 0.0319 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.0425 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293347.4071617\n",
      "Epoch 52/250\n",
      "\n",
      "Epoch 00052: loss improved from 0.02507 to 0.02026, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.071824073791504\n",
      " - 23s - loss: 0.0203 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0429 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293370.481343\n",
      "Epoch 53/250\n",
      "\n",
      "Epoch 00053: loss did not improve\n",
      "epoch time measured: 23.030966997146606\n",
      " - 23s - loss: 0.0203 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0441 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293393.5134466\n",
      "Epoch 54/250\n",
      "\n",
      "Epoch 00054: loss did not improve\n",
      "epoch time measured: 23.97191619873047\n",
      " - 24s - loss: 0.0217 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0450 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293417.486626\n",
      "Epoch 55/250\n",
      "\n",
      "Epoch 00055: loss did not improve\n",
      "epoch time measured: 23.374910831451416\n",
      " - 23s - loss: 0.0279 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.2000 - fp_m: 1.6000 - tn_m: 107.2000 - fn_m: 1.6000 - val_loss: 0.0449 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293440.8627112\n",
      "Epoch 56/250\n",
      "\n",
      "Epoch 00056: loss did not improve\n",
      "epoch time measured: 22.981780290603638\n",
      " - 23s - loss: 0.0250 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0447 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293463.84574\n",
      "Epoch 57/250\n",
      "\n",
      "Epoch 00057: loss did not improve\n",
      "epoch time measured: 23.370752811431885\n",
      " - 23s - loss: 0.0438 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 107.0000 - fp_m: 1.8000 - tn_m: 107.0000 - fn_m: 1.8000 - val_loss: 0.0434 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293487.2177832\n",
      "Epoch 58/250\n",
      "\n",
      "Epoch 00058: loss did not improve\n",
      "epoch time measured: 23.616411924362183\n",
      " - 24s - loss: 0.0233 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0429 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293510.8354144\n",
      "Epoch 59/250\n",
      "\n",
      "Epoch 00059: loss did not improve\n",
      "epoch time measured: 23.0764217376709\n",
      " - 23s - loss: 0.0223 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0425 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293533.9130232\n",
      "Epoch 60/250\n",
      "\n",
      "Epoch 00060: loss did not improve\n",
      "epoch time measured: 22.834603786468506\n",
      " - 23s - loss: 0.0288 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 108.4000 - fp_m: 0.4000 - tn_m: 108.4000 - fn_m: 0.4000 - val_loss: 0.0414 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293556.7486963\n",
      "Epoch 61/250\n",
      "\n",
      "Epoch 00061: loss did not improve\n",
      "epoch time measured: 23.25684928894043\n",
      " - 23s - loss: 0.0342 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.0406 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293580.0066905\n",
      "Epoch 62/250\n",
      "\n",
      "Epoch 00062: loss improved from 0.02026 to 0.01802, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.84017562866211\n",
      " - 24s - loss: 0.0180 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0402 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293603.8483636\n",
      "Epoch 63/250\n",
      "\n",
      "Epoch 00063: loss did not improve\n",
      "epoch time measured: 23.657891511917114\n",
      " - 24s - loss: 0.0182 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0399 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293627.5074313\n",
      "Epoch 64/250\n",
      "\n",
      "Epoch 00064: loss improved from 0.01802 to 0.01623, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.229172229766846\n",
      " - 23s - loss: 0.0162 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0398 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293650.737845\n",
      "Epoch 65/250\n",
      "\n",
      "Epoch 00065: loss did not improve\n",
      "epoch time measured: 22.69858407974243\n",
      " - 23s - loss: 0.0227 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0395 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293673.4375956\n",
      "Epoch 66/250\n",
      "\n",
      "Epoch 00066: loss improved from 0.01623 to 0.01242, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 22.921194314956665\n",
      " - 23s - loss: 0.0124 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0386 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293696.3601308\n",
      "Epoch 67/250\n",
      "\n",
      "Epoch 00067: loss did not improve\n",
      "epoch time measured: 22.768324375152588\n",
      " - 23s - loss: 0.0180 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0379 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293719.1295671\n",
      "Epoch 68/250\n",
      "\n",
      "Epoch 00068: loss did not improve\n",
      "epoch time measured: 23.74201989173889\n",
      " - 24s - loss: 0.0179 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0375 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293742.8736584\n",
      "Epoch 69/250\n",
      "\n",
      "Epoch 00069: loss did not improve\n",
      "epoch time measured: 23.334743976593018\n",
      " - 23s - loss: 0.0228 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0377 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578293766.2094786\n",
      "Epoch 70/250\n",
      "\n",
      "Epoch 00070: loss did not improve\n",
      "epoch time measured: 23.044313430786133\n",
      " - 23s - loss: 0.0141 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0381 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293789.255038\n",
      "Epoch 71/250\n",
      "\n",
      "Epoch 00071: loss did not improve\n",
      "epoch time measured: 22.724583864212036\n",
      " - 23s - loss: 0.0135 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0388 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293811.9806945\n",
      "Epoch 72/250\n",
      "\n",
      "Epoch 00072: loss did not improve\n",
      "epoch time measured: 23.179006099700928\n",
      " - 23s - loss: 0.0166 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0386 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293835.1608655\n",
      "Epoch 73/250\n",
      "\n",
      "Epoch 00073: loss did not improve\n",
      "epoch time measured: 22.823285341262817\n",
      " - 23s - loss: 0.0151 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0372 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293857.98547\n",
      "Epoch 74/250\n",
      "\n",
      "Epoch 00074: loss did not improve\n",
      "epoch time measured: 22.816700220108032\n",
      " - 23s - loss: 0.0182 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293880.8033206\n",
      "Epoch 75/250\n",
      "\n",
      "Epoch 00075: loss improved from 0.01242 to 0.01213, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.450501203536987\n",
      " - 23s - loss: 0.0121 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578293904.2554057\n",
      "Epoch 76/250\n",
      "\n",
      "Epoch 00076: loss improved from 0.01213 to 0.01153, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.827486515045166\n",
      " - 24s - loss: 0.0115 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293928.0841715\n",
      "Epoch 77/250\n",
      "\n",
      "Epoch 00077: loss did not improve\n",
      "epoch time measured: 22.849388360977173\n",
      " - 23s - loss: 0.0127 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0338 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293950.9346523\n",
      "Epoch 78/250\n",
      "\n",
      "Epoch 00078: loss did not improve\n",
      "epoch time measured: 23.460047245025635\n",
      " - 23s - loss: 0.0140 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0335 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293974.3958817\n",
      "Epoch 79/250\n",
      "\n",
      "Epoch 00079: loss improved from 0.01153 to 0.00960, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.412569761276245\n",
      " - 23s - loss: 0.0096 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578293997.8097022\n",
      "Epoch 80/250\n",
      "\n",
      "Epoch 00080: loss did not improve\n",
      "epoch time measured: 23.48864769935608\n",
      " - 23s - loss: 0.0125 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0336 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294021.29948\n",
      "Epoch 81/250\n",
      "\n",
      "Epoch 00081: loss did not improve\n",
      "epoch time measured: 23.458956956863403\n",
      " - 23s - loss: 0.0130 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0354 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294044.7594016\n",
      "Epoch 82/250\n",
      "\n",
      "Epoch 00082: loss did not improve\n",
      "epoch time measured: 23.124317169189453\n",
      " - 23s - loss: 0.0129 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0386 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294067.8850205\n",
      "Epoch 83/250\n",
      "\n",
      "Epoch 00083: loss improved from 0.00960 to 0.00803, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.564786434173584\n",
      " - 24s - loss: 0.0080 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0412 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294091.4513066\n",
      "Epoch 84/250\n",
      "\n",
      "Epoch 00084: loss improved from 0.00803 to 0.00598, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.10331964492798\n",
      " - 23s - loss: 0.0060 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0431 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294114.5560265\n",
      "Epoch 85/250\n",
      "\n",
      "Epoch 00085: loss did not improve\n",
      "epoch time measured: 22.92205286026001\n",
      " - 23s - loss: 0.0135 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0438 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294137.4791992\n",
      "Epoch 86/250\n",
      "\n",
      "Epoch 00086: loss did not improve\n",
      "epoch time measured: 22.865731239318848\n",
      " - 23s - loss: 0.0102 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0433 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294160.3460274\n",
      "Epoch 87/250\n",
      "\n",
      "Epoch 00087: loss did not improve\n",
      "epoch time measured: 23.266881704330444\n",
      " - 23s - loss: 0.0103 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0420 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294183.6139967\n",
      "Epoch 88/250\n",
      "\n",
      "Epoch 00088: loss did not improve\n",
      "epoch time measured: 23.261576414108276\n",
      " - 23s - loss: 0.0115 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0411 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294206.8773654\n",
      "Epoch 89/250\n",
      "\n",
      "Epoch 00089: loss did not improve\n",
      "epoch time measured: 22.868089199066162\n",
      " - 23s - loss: 0.0096 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0407 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294229.7467608\n",
      "Epoch 90/250\n",
      "\n",
      "Epoch 00090: loss improved from 0.00598 to 0.00579, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.10493016242981\n",
      " - 23s - loss: 0.0058 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0405 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294252.8533084\n",
      "Epoch 91/250\n",
      "\n",
      "Epoch 00091: loss did not improve\n",
      "epoch time measured: 23.70308828353882\n",
      " - 24s - loss: 0.0072 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0396 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294276.5574608\n",
      "Epoch 92/250\n",
      "\n",
      "Epoch 00092: loss did not improve\n",
      "epoch time measured: 22.70222806930542\n",
      " - 23s - loss: 0.0137 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0380 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294299.2609663\n",
      "Epoch 93/250\n",
      "\n",
      "Epoch 00093: loss did not improve\n",
      "epoch time measured: 23.11340045928955\n",
      " - 23s - loss: 0.0077 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294322.375619\n",
      "Epoch 94/250\n",
      "\n",
      "Epoch 00094: loss did not improve\n",
      "epoch time measured: 23.09469985961914\n",
      " - 23s - loss: 0.0308 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 108.4000 - fp_m: 0.4000 - tn_m: 108.4000 - fn_m: 0.4000 - val_loss: 0.0381 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294345.4713106\n",
      "Epoch 95/250\n",
      "\n",
      "Epoch 00095: loss did not improve\n",
      "epoch time measured: 23.576908349990845\n",
      " - 24s - loss: 0.0550 - acc: 0.9750 - f1_m: 0.9750 - precision_m: 0.9750 - recall_m: 0.9750 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0401 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294369.0493183\n",
      "Epoch 96/250\n",
      "\n",
      "Epoch 00096: loss did not improve\n",
      "epoch time measured: 23.06164240837097\n",
      " - 23s - loss: 0.0111 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0389 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294392.1120007\n",
      "Epoch 97/250\n",
      "\n",
      "Epoch 00097: loss did not improve\n",
      "epoch time measured: 22.866316318511963\n",
      " - 23s - loss: 0.0087 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0390 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294414.9795814\n",
      "Epoch 98/250\n",
      "\n",
      "Epoch 00098: loss did not improve\n",
      "epoch time measured: 22.98601460456848\n",
      " - 23s - loss: 0.0164 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0400 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294437.966857\n",
      "Epoch 99/250\n",
      "\n",
      "Epoch 00099: loss did not improve\n",
      "epoch time measured: 23.33059024810791\n",
      " - 23s - loss: 0.0162 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0412 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294461.29861\n",
      "Epoch 100/250\n",
      "\n",
      "Epoch 00100: loss did not improve\n",
      "epoch time measured: 22.990691900253296\n",
      " - 23s - loss: 0.0135 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0421 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578294484.2905338\n",
      "Epoch 101/250\n",
      "\n",
      "Epoch 00101: loss did not improve\n",
      "epoch time measured: 23.038075923919678\n",
      " - 23s - loss: 0.0128 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0434 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294507.3297722\n",
      "Epoch 102/250\n",
      "\n",
      "Epoch 00102: loss did not improve\n",
      "epoch time measured: 23.137856006622314\n",
      " - 23s - loss: 0.0160 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0458 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578294530.4687316\n",
      "Epoch 103/250\n",
      "\n",
      "Epoch 00103: loss did not improve\n",
      "epoch time measured: 23.27134108543396\n",
      " - 23s - loss: 0.0258 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0502 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578294553.741243\n",
      "Epoch 104/250\n",
      "\n",
      "Epoch 00104: loss did not improve\n",
      "epoch time measured: 23.09318971633911\n",
      " - 23s - loss: 0.0176 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0542 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578294576.8354616\n",
      "Epoch 105/250\n",
      "\n",
      "Epoch 00105: loss did not improve\n",
      "epoch time measured: 23.042911052703857\n",
      " - 23s - loss: 0.0189 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0523 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578294599.8794684\n",
      "Epoch 106/250\n",
      "\n",
      "Epoch 00106: loss did not improve\n",
      "epoch time measured: 23.08461046218872\n",
      " - 23s - loss: 0.0225 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0472 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578294622.9653904\n",
      "Epoch 107/250\n",
      "\n",
      "Epoch 00107: loss did not improve\n",
      "epoch time measured: 22.964990615844727\n",
      " - 23s - loss: 0.0199 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0435 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578294645.9318378\n",
      "Epoch 108/250\n",
      "\n",
      "Epoch 00108: loss did not improve\n",
      "epoch time measured: 23.415623903274536\n",
      " - 23s - loss: 0.0102 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0430 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294669.3488991\n",
      "Epoch 109/250\n",
      "\n",
      "Epoch 00109: loss did not improve\n",
      "epoch time measured: 22.511969804763794\n",
      " - 23s - loss: 0.0114 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0437 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294691.8623273\n",
      "Epoch 110/250\n",
      "\n",
      "Epoch 00110: loss did not improve\n",
      "epoch time measured: 23.213414669036865\n",
      " - 23s - loss: 0.0199 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.0437 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294715.0771866\n",
      "Epoch 111/250\n",
      "\n",
      "Epoch 00111: loss did not improve\n",
      "epoch time measured: 23.916725158691406\n",
      " - 24s - loss: 0.0292 - acc: 0.9813 - f1_m: 0.9812 - precision_m: 0.9813 - recall_m: 0.9813 - tp_m: 107.6000 - fp_m: 1.2000 - tn_m: 107.6000 - fn_m: 1.2000 - val_loss: 0.0432 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578294738.9951239\n",
      "Epoch 112/250\n",
      "\n",
      "Epoch 00112: loss did not improve\n",
      "epoch time measured: 23.039960622787476\n",
      " - 23s - loss: 0.0097 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0458 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578294762.036263\n",
      "Epoch 113/250\n",
      "\n",
      "Epoch 00113: loss did not improve\n",
      "epoch time measured: 23.319774389266968\n",
      " - 23s - loss: 0.0348 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 108.4000 - fp_m: 0.4000 - tn_m: 108.4000 - fn_m: 0.4000 - val_loss: 0.0447 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294785.357138\n",
      "Epoch 114/250\n",
      "\n",
      "Epoch 00114: loss did not improve\n",
      "epoch time measured: 23.37663984298706\n",
      " - 23s - loss: 0.0241 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 108.4000 - fp_m: 0.4000 - tn_m: 108.4000 - fn_m: 0.4000 - val_loss: 0.0401 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294808.7349305\n",
      "Epoch 115/250\n",
      "\n",
      "Epoch 00115: loss did not improve\n",
      "epoch time measured: 22.96825408935547\n",
      " - 23s - loss: 0.0135 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0390 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578294831.7044766\n",
      "Epoch 116/250\n",
      "\n",
      "Epoch 00116: loss did not improve\n",
      "epoch time measured: 23.806129932403564\n",
      " - 24s - loss: 0.0105 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0405 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294855.5121458\n",
      "Epoch 117/250\n",
      "\n",
      "Epoch 00117: loss did not improve\n",
      "epoch time measured: 23.619735717773438\n",
      " - 24s - loss: 0.0189 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0415 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294879.132988\n",
      "Epoch 118/250\n",
      "\n",
      "Epoch 00118: loss did not improve\n",
      "epoch time measured: 23.04085922241211\n",
      " - 23s - loss: 0.0191 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0400 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294902.1749046\n",
      "Epoch 119/250\n",
      "\n",
      "Epoch 00119: loss did not improve\n",
      "epoch time measured: 23.671410083770752\n",
      " - 24s - loss: 0.0130 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0381 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294925.8474324\n",
      "Epoch 120/250\n",
      "\n",
      "Epoch 00120: loss did not improve\n",
      "epoch time measured: 22.774165868759155\n",
      " - 23s - loss: 0.0280 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0383 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578294948.6229122\n",
      "Epoch 121/250\n",
      "\n",
      "Epoch 00121: loss improved from 0.00579 to 0.00571, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.300391674041748\n",
      " - 23s - loss: 0.0057 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0393 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578294971.9249392\n",
      "Epoch 122/250\n",
      "\n",
      "Epoch 00122: loss did not improve\n",
      "epoch time measured: 23.026347637176514\n",
      " - 23s - loss: 0.0073 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0402 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578294994.9524777\n",
      "Epoch 123/250\n",
      "\n",
      "Epoch 00123: loss did not improve\n",
      "epoch time measured: 22.66947603225708\n",
      " - 23s - loss: 0.0113 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0407 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295017.623001\n",
      "Epoch 124/250\n",
      "\n",
      "Epoch 00124: loss did not improve\n",
      "epoch time measured: 23.705495357513428\n",
      " - 24s - loss: 0.0085 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0413 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295041.3296802\n",
      "Epoch 125/250\n",
      "\n",
      "Epoch 00125: loss did not improve\n",
      "epoch time measured: 23.113945245742798\n",
      " - 23s - loss: 0.0134 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0409 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295064.4447386\n",
      "Epoch 126/250\n",
      "\n",
      "Epoch 00126: loss did not improve\n",
      "epoch time measured: 23.03188133239746\n",
      " - 23s - loss: 0.0077 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0407 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295087.478249\n",
      "Epoch 127/250\n",
      "\n",
      "Epoch 00127: loss did not improve\n",
      "epoch time measured: 23.494332790374756\n",
      " - 23s - loss: 0.0124 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0401 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295110.97358\n",
      "Epoch 128/250\n",
      "\n",
      "Epoch 00128: loss did not improve\n",
      "epoch time measured: 23.238995790481567\n",
      " - 23s - loss: 0.0123 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0391 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295134.2138116\n",
      "Epoch 129/250\n",
      "\n",
      "Epoch 00129: loss did not improve\n",
      "epoch time measured: 22.90231704711914\n",
      " - 23s - loss: 0.0238 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.0398 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578295157.1172447\n",
      "Epoch 130/250\n",
      "\n",
      "Epoch 00130: loss did not improve\n",
      "epoch time measured: 23.28862977027893\n",
      " - 23s - loss: 0.0085 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0450 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295180.4075027\n",
      "Epoch 131/250\n",
      "\n",
      "Epoch 00131: loss did not improve\n",
      "epoch time measured: 22.839946031570435\n",
      " - 23s - loss: 0.0094 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0513 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295203.2485306\n",
      "Epoch 132/250\n",
      "\n",
      "Epoch 00132: loss did not improve\n",
      "epoch time measured: 23.447060108184814\n",
      " - 23s - loss: 0.0156 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0529 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295226.6969361\n",
      "Epoch 133/250\n",
      "\n",
      "Epoch 00133: loss did not improve\n",
      "epoch time measured: 22.426408052444458\n",
      " - 22s - loss: 0.0138 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0501 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295249.1243668\n",
      "Epoch 134/250\n",
      "\n",
      "Epoch 00134: loss did not improve\n",
      "epoch time measured: 23.962613821029663\n",
      " - 24s - loss: 0.0233 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0462 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295273.0880146\n",
      "Epoch 135/250\n",
      "\n",
      "Epoch 00135: loss did not improve\n",
      "epoch time measured: 23.39831566810608\n",
      " - 23s - loss: 0.0161 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0426 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295296.4874449\n",
      "Epoch 136/250\n",
      "\n",
      "Epoch 00136: loss did not improve\n",
      "epoch time measured: 23.259727478027344\n",
      " - 23s - loss: 0.0092 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0399 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295319.7483494\n",
      "Epoch 137/250\n",
      "\n",
      "Epoch 00137: loss did not improve\n",
      "epoch time measured: 23.506665229797363\n",
      " - 24s - loss: 0.0214 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 108.4000 - fp_m: 0.4000 - tn_m: 108.4000 - fn_m: 0.4000 - val_loss: 0.0399 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295343.2562153\n",
      "Epoch 138/250\n",
      "\n",
      "Epoch 00138: loss did not improve\n",
      "epoch time measured: 23.903954029083252\n",
      " - 24s - loss: 0.0121 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0430 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295367.1613097\n",
      "Epoch 139/250\n",
      "\n",
      "Epoch 00139: loss did not improve\n",
      "epoch time measured: 23.216717004776\n",
      " - 23s - loss: 0.0173 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0466 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295390.3790917\n",
      "Epoch 140/250\n",
      "\n",
      "Epoch 00140: loss did not improve\n",
      "epoch time measured: 22.705100536346436\n",
      " - 23s - loss: 0.0104 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0488 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295413.08529\n",
      "Epoch 141/250\n",
      "\n",
      "Epoch 00141: loss did not improve\n",
      "epoch time measured: 23.57945442199707\n",
      " - 24s - loss: 0.0153 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0509 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295436.6661463\n",
      "Epoch 142/250\n",
      "\n",
      "Epoch 00142: loss did not improve\n",
      "epoch time measured: 23.55241823196411\n",
      " - 24s - loss: 0.0071 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0534 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295460.219503\n",
      "Epoch 143/250\n",
      "\n",
      "Epoch 00143: loss did not improve\n",
      "epoch time measured: 23.26276993751526\n",
      " - 23s - loss: 0.0075 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0546 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295483.483563\n",
      "Epoch 144/250\n",
      "\n",
      "Epoch 00144: loss did not improve\n",
      "epoch time measured: 23.37963581085205\n",
      " - 23s - loss: 0.0065 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0549 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295506.864525\n",
      "Epoch 145/250\n",
      "\n",
      "Epoch 00145: loss did not improve\n",
      "epoch time measured: 23.409101486206055\n",
      " - 23s - loss: 0.0150 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0520 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295530.2749379\n",
      "Epoch 146/250\n",
      "\n",
      "Epoch 00146: loss did not improve\n",
      "epoch time measured: 23.337115049362183\n",
      " - 23s - loss: 0.0336 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0493 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295553.6133826\n",
      "Epoch 147/250\n",
      "\n",
      "Epoch 00147: loss did not improve\n",
      "epoch time measured: 23.442195177078247\n",
      " - 23s - loss: 0.0077 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0489 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295577.0567303\n",
      "Epoch 148/250\n",
      "\n",
      "Epoch 00148: loss did not improve\n",
      "epoch time measured: 22.454832077026367\n",
      " - 22s - loss: 0.0087 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0516 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295599.5132687\n",
      "Epoch 149/250\n",
      "\n",
      "Epoch 00149: loss did not improve\n",
      "epoch time measured: 22.740065097808838\n",
      " - 23s - loss: 0.0076 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0549 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295622.2547216\n",
      "Epoch 150/250\n",
      "\n",
      "Epoch 00150: loss did not improve\n",
      "epoch time measured: 23.8745539188385\n",
      " - 24s - loss: 0.0095 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0577 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295646.1304145\n",
      "Epoch 151/250\n",
      "\n",
      "Epoch 00151: loss improved from 0.00571 to 0.00561, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.374913930892944\n",
      " - 23s - loss: 0.0056 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0589 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295669.506776\n",
      "Epoch 152/250\n",
      "\n",
      "Epoch 00152: loss did not improve\n",
      "epoch time measured: 23.125732421875\n",
      " - 23s - loss: 0.0064 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0585 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295692.63375\n",
      "Epoch 153/250\n",
      "\n",
      "Epoch 00153: loss did not improve\n",
      "epoch time measured: 22.62759304046631\n",
      " - 23s - loss: 0.0057 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0564 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295715.2624183\n",
      "Epoch 154/250\n",
      "\n",
      "Epoch 00154: loss did not improve\n",
      "epoch time measured: 23.13041853904724\n",
      " - 23s - loss: 0.0107 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0523 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295738.3941963\n",
      "Epoch 155/250\n",
      "\n",
      "Epoch 00155: loss did not improve\n",
      "epoch time measured: 23.538861513137817\n",
      " - 24s - loss: 0.0084 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0495 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295761.9340758\n",
      "Epoch 156/250\n",
      "\n",
      "Epoch 00156: loss did not improve\n",
      "epoch time measured: 23.11251735687256\n",
      " - 23s - loss: 0.0120 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0507 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295785.0477312\n",
      "Epoch 157/250\n",
      "\n",
      "Epoch 00157: loss did not improve\n",
      "epoch time measured: 23.383547067642212\n",
      " - 23s - loss: 0.0063 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0520 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295808.4328952\n",
      "Epoch 158/250\n",
      "\n",
      "Epoch 00158: loss improved from 0.00561 to 0.00527, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.42978262901306\n",
      " - 23s - loss: 0.0053 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0540 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295831.864167\n",
      "Epoch 159/250\n",
      "\n",
      "Epoch 00159: loss did not improve\n",
      "epoch time measured: 22.926054000854492\n",
      " - 23s - loss: 0.0106 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0578 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295854.7914171\n",
      "Epoch 160/250\n",
      "\n",
      "Epoch 00160: loss did not improve\n",
      "epoch time measured: 22.905425310134888\n",
      " - 23s - loss: 0.0075 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0584 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295877.697834\n",
      "Epoch 161/250\n",
      "\n",
      "Epoch 00161: loss improved from 0.00527 to 0.00373, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.24210214614868\n",
      " - 23s - loss: 0.0037 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0587 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295900.941135\n",
      "Epoch 162/250\n",
      "\n",
      "Epoch 00162: loss did not improve\n",
      "epoch time measured: 23.39005732536316\n",
      " - 23s - loss: 0.0063 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0594 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295924.3327672\n",
      "Epoch 163/250\n",
      "\n",
      "Epoch 00163: loss did not improve\n",
      "epoch time measured: 22.756382703781128\n",
      " - 23s - loss: 0.0042 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0597 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295947.0902455\n",
      "Epoch 164/250\n",
      "\n",
      "Epoch 00164: loss improved from 0.00373 to 0.00251, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 22.902634143829346\n",
      " - 23s - loss: 0.0025 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0600 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295969.9942274\n",
      "Epoch 165/250\n",
      "\n",
      "Epoch 00165: loss did not improve\n",
      "epoch time measured: 23.596975088119507\n",
      " - 24s - loss: 0.0067 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0629 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578295993.5923777\n",
      "Epoch 166/250\n",
      "\n",
      "Epoch 00166: loss did not improve\n",
      "epoch time measured: 23.477294206619263\n",
      " - 23s - loss: 0.0043 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0662 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296017.0706923\n",
      "Epoch 167/250\n",
      "\n",
      "Epoch 00167: loss did not improve\n",
      "epoch time measured: 23.408223390579224\n",
      " - 23s - loss: 0.0050 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0676 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296040.4802978\n",
      "Epoch 168/250\n",
      "\n",
      "Epoch 00168: loss did not improve\n",
      "epoch time measured: 23.280031204223633\n",
      " - 23s - loss: 0.0033 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0657 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296063.7617662\n",
      "Epoch 169/250\n",
      "\n",
      "Epoch 00169: loss did not improve\n",
      "epoch time measured: 23.131541967391968\n",
      " - 23s - loss: 0.0037 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0631 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296086.894371\n",
      "Epoch 170/250\n",
      "\n",
      "Epoch 00170: loss improved from 0.00251 to 0.00249, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 22.672923803329468\n",
      " - 23s - loss: 0.0025 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0605 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296109.5688133\n",
      "Epoch 171/250\n",
      "\n",
      "Epoch 00171: loss did not improve\n",
      "epoch time measured: 22.846017837524414\n",
      " - 23s - loss: 0.0036 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0573 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296132.415914\n",
      "Epoch 172/250\n",
      "\n",
      "Epoch 00172: loss did not improve\n",
      "epoch time measured: 23.307218074798584\n",
      " - 23s - loss: 0.0036 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0543 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296155.7244675\n",
      "Epoch 173/250\n",
      "\n",
      "Epoch 00173: loss did not improve\n",
      "epoch time measured: 23.214099168777466\n",
      " - 23s - loss: 0.0036 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0516 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296178.9396186\n",
      "Epoch 174/250\n",
      "\n",
      "Epoch 00174: loss did not improve\n",
      "epoch time measured: 23.192417860031128\n",
      " - 23s - loss: 0.0055 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0513 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296202.1335151\n",
      "Epoch 175/250\n",
      "\n",
      "Epoch 00175: loss did not improve\n",
      "epoch time measured: 22.76628017425537\n",
      " - 23s - loss: 0.0033 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0529 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296224.9009948\n",
      "Epoch 176/250\n",
      "\n",
      "Epoch 00176: loss did not improve\n",
      "epoch time measured: 23.7034969329834\n",
      " - 24s - loss: 0.0052 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0517 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296248.6058753\n",
      "Epoch 177/250\n",
      "\n",
      "Epoch 00177: loss did not improve\n",
      "epoch time measured: 23.332334756851196\n",
      " - 23s - loss: 0.0078 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0525 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296271.9392939\n",
      "Epoch 178/250\n",
      "\n",
      "Epoch 00178: loss did not improve\n",
      "epoch time measured: 23.019060373306274\n",
      " - 23s - loss: 0.0045 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0588 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296294.9596977\n",
      "Epoch 179/250\n",
      "\n",
      "Epoch 00179: loss did not improve\n",
      "epoch time measured: 22.910290956497192\n",
      " - 23s - loss: 0.0164 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0612 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296317.871355\n",
      "Epoch 180/250\n",
      "\n",
      "Epoch 00180: loss did not improve\n",
      "epoch time measured: 23.11630916595459\n",
      " - 23s - loss: 0.0028 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0601 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296340.9888208\n",
      "Epoch 181/250\n",
      "\n",
      "Epoch 00181: loss did not improve\n",
      "epoch time measured: 23.21687889099121\n",
      " - 23s - loss: 0.0079 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0581 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296364.2070282\n",
      "Epoch 182/250\n",
      "\n",
      "Epoch 00182: loss did not improve\n",
      "epoch time measured: 23.181766748428345\n",
      " - 23s - loss: 0.0048 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0560 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296387.389857\n",
      "Epoch 183/250\n",
      "\n",
      "Epoch 00183: loss did not improve\n",
      "epoch time measured: 23.066428661346436\n",
      " - 23s - loss: 0.0114 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0535 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296410.4576468\n",
      "Epoch 184/250\n",
      "\n",
      "Epoch 00184: loss did not improve\n",
      "epoch time measured: 24.108115673065186\n",
      " - 24s - loss: 0.0059 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0531 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296434.5670998\n",
      "Epoch 185/250\n",
      "\n",
      "Epoch 00185: loss did not improve\n",
      "epoch time measured: 23.08925151824951\n",
      " - 23s - loss: 0.0076 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0565 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296457.6574845\n",
      "Epoch 186/250\n",
      "\n",
      "Epoch 00186: loss did not improve\n",
      "epoch time measured: 22.855897188186646\n",
      " - 23s - loss: 0.0051 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0615 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296480.5144536\n",
      "Epoch 187/250\n",
      "\n",
      "Epoch 00187: loss did not improve\n",
      "epoch time measured: 23.220893621444702\n",
      " - 23s - loss: 0.0035 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0654 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296503.7364142\n",
      "Epoch 188/250\n",
      "\n",
      "Epoch 00188: loss did not improve\n",
      "epoch time measured: 23.638346910476685\n",
      " - 24s - loss: 0.0032 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0677 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296527.376208\n",
      "Epoch 189/250\n",
      "\n",
      "Epoch 00189: loss did not improve\n",
      "epoch time measured: 22.980838298797607\n",
      " - 23s - loss: 0.0039 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0671 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296550.358328\n",
      "Epoch 190/250\n",
      "\n",
      "Epoch 00190: loss did not improve\n",
      "epoch time measured: 23.117859840393066\n",
      " - 23s - loss: 0.0148 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0657 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296573.4774635\n",
      "Epoch 191/250\n",
      "\n",
      "Epoch 00191: loss did not improve\n",
      "epoch time measured: 23.317493200302124\n",
      " - 23s - loss: 0.0036 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0650 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296596.7962487\n",
      "Epoch 192/250\n",
      "\n",
      "Epoch 00192: loss did not improve\n",
      "epoch time measured: 22.913694143295288\n",
      " - 23s - loss: 0.0075 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0573 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296619.711037\n",
      "Epoch 193/250\n",
      "\n",
      "Epoch 00193: loss did not improve\n",
      "epoch time measured: 22.808563947677612\n",
      " - 23s - loss: 0.0149 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0413 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296642.5211077\n",
      "Epoch 194/250\n",
      "\n",
      "Epoch 00194: loss did not improve\n",
      "epoch time measured: 23.555110931396484\n",
      " - 24s - loss: 0.0038 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296666.077554\n",
      "Epoch 195/250\n",
      "\n",
      "Epoch 00195: loss did not improve\n",
      "epoch time measured: 23.067055702209473\n",
      " - 23s - loss: 0.0142 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0321 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296689.1461601\n",
      "Epoch 196/250\n",
      "\n",
      "Epoch 00196: loss did not improve\n",
      "epoch time measured: 23.229633808135986\n",
      " - 23s - loss: 0.0201 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 108.4000 - fp_m: 0.4000 - tn_m: 108.4000 - fn_m: 0.4000 - val_loss: 0.0354 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296712.3771014\n",
      "Epoch 197/250\n",
      "\n",
      "Epoch 00197: loss did not improve\n",
      "epoch time measured: 23.183030128479004\n",
      " - 23s - loss: 0.0056 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0434 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296735.5611525\n",
      "Epoch 198/250\n",
      "\n",
      "Epoch 00198: loss did not improve\n",
      "epoch time measured: 23.536070346832275\n",
      " - 24s - loss: 0.0029 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0514 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296759.0983279\n",
      "Epoch 199/250\n",
      "\n",
      "Epoch 00199: loss did not improve\n",
      "epoch time measured: 23.018476486206055\n",
      " - 23s - loss: 0.0085 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0632 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296782.1179647\n",
      "Epoch 200/250\n",
      "\n",
      "Epoch 00200: loss did not improve\n",
      "epoch time measured: 23.228790760040283\n",
      " - 23s - loss: 0.0039 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0791 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296805.3477879\n",
      "Epoch 201/250\n",
      "\n",
      "Epoch 00201: loss did not improve\n",
      "epoch time measured: 23.074669122695923\n",
      " - 23s - loss: 0.0043 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0909 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296828.4235058\n",
      "Epoch 202/250\n",
      "\n",
      "Epoch 00202: loss did not improve\n",
      "epoch time measured: 23.07998561859131\n",
      " - 23s - loss: 0.0053 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0940 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296851.504608\n",
      "Epoch 203/250\n",
      "\n",
      "Epoch 00203: loss did not improve\n",
      "epoch time measured: 22.995290756225586\n",
      " - 23s - loss: 0.0061 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0855 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296874.5010476\n",
      "Epoch 204/250\n",
      "\n",
      "Epoch 00204: loss did not improve\n",
      "epoch time measured: 23.471410512924194\n",
      " - 23s - loss: 0.0031 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0766 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296897.9735289\n",
      "Epoch 205/250\n",
      "\n",
      "Epoch 00205: loss did not improve\n",
      "epoch time measured: 22.822225332260132\n",
      " - 23s - loss: 0.0107 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0711 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296920.7969258\n",
      "Epoch 206/250\n",
      "\n",
      "Epoch 00206: loss did not improve\n",
      "epoch time measured: 23.355067014694214\n",
      " - 23s - loss: 0.0034 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0659 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296944.153113\n",
      "Epoch 207/250\n",
      "\n",
      "Epoch 00207: loss did not improve\n",
      "epoch time measured: 22.875666618347168\n",
      " - 23s - loss: 0.0029 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0600 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296967.030072\n",
      "Epoch 208/250\n",
      "\n",
      "Epoch 00208: loss improved from 0.00249 to 0.00233, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.320838451385498\n",
      " - 23s - loss: 0.0023 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0550 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578296990.3523517\n",
      "Epoch 209/250\n",
      "\n",
      "Epoch 00209: loss did not improve\n",
      "epoch time measured: 23.11129331588745\n",
      " - 23s - loss: 0.0030 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0516 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578297013.4655204\n",
      "Epoch 210/250\n",
      "\n",
      "Epoch 00210: loss did not improve\n",
      "epoch time measured: 22.53885245323181\n",
      " - 23s - loss: 0.0035 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0502 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578297036.0056317\n",
      "Epoch 211/250\n",
      "\n",
      "Epoch 00211: loss did not improve\n",
      "epoch time measured: 23.004490613937378\n",
      " - 23s - loss: 0.0035 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0501 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578297059.0112267\n",
      "Epoch 212/250\n",
      "\n",
      "Epoch 00212: loss did not improve\n",
      "epoch time measured: 23.316962242126465\n",
      " - 23s - loss: 0.0170 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 108.4000 - fp_m: 0.4000 - tn_m: 108.4000 - fn_m: 0.4000 - val_loss: 0.0527 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578297082.3296409\n",
      "Epoch 213/250\n",
      "\n",
      "Epoch 00213: loss did not improve\n",
      "epoch time measured: 22.766782760620117\n",
      " - 23s - loss: 0.0153 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 108.4000 - fp_m: 0.4000 - tn_m: 108.4000 - fn_m: 0.4000 - val_loss: 0.0540 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578297105.0974946\n",
      "Epoch 214/250\n",
      "\n",
      "Epoch 00214: loss did not improve\n",
      "epoch time measured: 23.273766040802002\n",
      " - 23s - loss: 0.0065 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0478 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578297128.3723528\n",
      "Epoch 215/250\n",
      "\n",
      "Epoch 00215: loss did not improve\n",
      "epoch time measured: 23.518603086471558\n",
      " - 24s - loss: 0.0197 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0519 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578297151.8922057\n",
      "Epoch 216/250\n",
      "\n",
      "Epoch 00216: loss did not improve\n",
      "epoch time measured: 22.739484548568726\n",
      " - 23s - loss: 0.0068 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0655 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578297174.6330287\n",
      "Epoch 217/250\n",
      "\n",
      "Epoch 00217: loss did not improve\n",
      "epoch time measured: 23.48801851272583\n",
      " - 23s - loss: 0.0046 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0771 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578297198.1220863\n",
      "Epoch 218/250\n",
      "\n",
      "Epoch 00218: loss did not improve\n",
      "epoch time measured: 23.39610457420349\n",
      " - 23s - loss: 0.0068 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0869 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578297221.519455\n",
      "Epoch 219/250\n",
      "\n",
      "Epoch 00219: loss did not improve\n",
      "epoch time measured: 23.311190843582153\n",
      " - 23s - loss: 0.0121 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0907 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578297244.8318536\n",
      "Epoch 220/250\n",
      "\n",
      "Epoch 00220: loss did not improve\n",
      "epoch time measured: 23.242931127548218\n",
      " - 23s - loss: 0.0159 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0856 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578297268.0759578\n",
      "Epoch 221/250\n",
      "\n",
      "Epoch 00221: loss did not improve\n",
      "epoch time measured: 22.72685146331787\n",
      " - 23s - loss: 0.0207 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 108.4000 - fp_m: 0.4000 - tn_m: 108.4000 - fn_m: 0.4000 - val_loss: 0.0713 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578297290.8039036\n",
      "Epoch 222/250\n",
      "\n",
      "Epoch 00222: loss did not improve\n",
      "epoch time measured: 23.227043390274048\n",
      " - 23s - loss: 0.0151 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0500 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578297314.03301\n",
      "Epoch 223/250\n",
      "\n",
      "Epoch 00223: loss did not improve\n",
      "epoch time measured: 23.683799028396606\n",
      " - 24s - loss: 0.0040 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0364 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578297337.7179382\n",
      "Epoch 224/250\n",
      "\n",
      "Epoch 00224: loss did not improve\n",
      "epoch time measured: 23.118533849716187\n",
      " - 23s - loss: 0.0029 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578297360.8376455\n",
      "Epoch 225/250\n",
      "\n",
      "Epoch 00225: loss did not improve\n",
      "epoch time measured: 22.956115007400513\n",
      " - 23s - loss: 0.0029 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0273 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578297383.7951527\n",
      "Epoch 226/250\n",
      "\n",
      "Epoch 00226: loss did not improve\n",
      "epoch time measured: 23.16194772720337\n",
      " - 23s - loss: 0.0110 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0260 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578297406.9581323\n",
      "Epoch 227/250\n",
      "\n",
      "Epoch 00227: loss did not improve\n",
      "epoch time measured: 23.046038389205933\n",
      " - 23s - loss: 0.0057 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0241 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578297430.0053163\n",
      "Epoch 228/250\n",
      "\n",
      "Epoch 00228: loss did not improve\n",
      "epoch time measured: 23.502028465270996\n",
      " - 24s - loss: 0.0043 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0228 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578297453.5084646\n",
      "Epoch 229/250\n",
      "\n",
      "Epoch 00229: loss did not improve\n",
      "epoch time measured: 22.58587408065796\n",
      " - 23s - loss: 0.0028 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0226 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578297476.0955298\n",
      "Epoch 230/250\n",
      "\n",
      "Epoch 00230: loss did not improve\n",
      "epoch time measured: 23.950202226638794\n",
      " - 24s - loss: 0.0034 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0230 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578297500.0468874\n",
      "Epoch 231/250\n",
      "\n",
      "Epoch 00231: loss did not improve\n",
      "epoch time measured: 23.23390793800354\n",
      " - 23s - loss: 0.0039 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0239 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578297523.2818763\n",
      "Epoch 232/250\n",
      "\n",
      "Epoch 00232: loss did not improve\n",
      "epoch time measured: 23.556298971176147\n",
      " - 24s - loss: 0.0032 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0248 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578297546.8392832\n",
      "Epoch 233/250\n",
      "\n",
      "Epoch 00233: loss improved from 0.00233 to 0.00191, saving model to ./weights/eeg2_attention_weights.h5\n",
      "epoch time measured: 23.170084953308105\n",
      " - 23s - loss: 0.0019 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0259 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578297570.0110354\n",
      "Epoch 234/250\n",
      "\n",
      "Epoch 00234: loss did not improve\n",
      "epoch time measured: 23.0826256275177\n",
      " - 23s - loss: 0.0143 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0257 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578297593.0947464\n",
      "Epoch 235/250\n",
      "\n",
      "Epoch 00235: loss did not improve\n",
      "epoch time measured: 23.294320821762085\n",
      " - 23s - loss: 0.0347 - acc: 0.9750 - f1_m: 0.9750 - precision_m: 0.9750 - recall_m: 0.9750 - tp_m: 108.0000 - fp_m: 0.8000 - tn_m: 108.0000 - fn_m: 0.8000 - val_loss: 0.0266 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578297616.390408\n",
      "Epoch 236/250\n",
      "\n",
      "Epoch 00236: loss did not improve\n",
      "epoch time measured: 23.106131315231323\n",
      " - 23s - loss: 0.0059 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0382 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578297639.4981024\n",
      "Epoch 237/250\n",
      "\n",
      "Epoch 00237: loss did not improve\n",
      "epoch time measured: 23.287989616394043\n",
      " - 23s - loss: 0.0121 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0490 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578297662.7871513\n",
      "Epoch 238/250\n",
      "\n",
      "Epoch 00238: loss did not improve\n",
      "epoch time measured: 23.316436767578125\n",
      " - 23s - loss: 0.0141 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0507 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578297686.1047246\n",
      "Epoch 239/250\n",
      "\n",
      "Epoch 00239: loss did not improve\n",
      "epoch time measured: 22.895753622055054\n",
      " - 23s - loss: 0.0169 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0497 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578297709.0016425\n",
      "Epoch 240/250\n",
      "\n",
      "Epoch 00240: loss did not improve\n",
      "epoch time measured: 23.1121826171875\n",
      " - 23s - loss: 0.0249 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - tp_m: 107.8000 - fp_m: 1.0000 - tn_m: 107.8000 - fn_m: 1.0000 - val_loss: 0.0477 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578297732.1149483\n",
      "Epoch 241/250\n",
      "\n",
      "Epoch 00241: loss did not improve\n",
      "epoch time measured: 22.94389057159424\n",
      " - 23s - loss: 0.0100 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0441 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578297755.0600271\n",
      "Epoch 242/250\n",
      "\n",
      "Epoch 00242: loss did not improve\n",
      "epoch time measured: 23.430532932281494\n",
      " - 23s - loss: 0.0118 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578297778.4916246\n",
      "Epoch 243/250\n",
      "\n",
      "Epoch 00243: loss did not improve\n",
      "epoch time measured: 23.461657285690308\n",
      " - 23s - loss: 0.0147 - acc: 0.9938 - f1_m: 0.9937 - precision_m: 0.9938 - recall_m: 0.9938 - tp_m: 108.6000 - fp_m: 0.2000 - tn_m: 108.6000 - fn_m: 0.2000 - val_loss: 0.0316 - val_acc: 0.9700 - val_f1_m: 0.9700 - val_precision_m: 0.9700 - val_recall_m: 0.9700 - val_tp_m: 97.0000 - val_fp_m: 3.0000 - val_tn_m: 97.0000 - val_fn_m: 3.0000\n",
      "epoch time start: 1578297801.9548194\n",
      "Epoch 244/250\n",
      "\n",
      "Epoch 00244: loss did not improve\n",
      "epoch time measured: 23.518723964691162\n",
      " - 24s - loss: 0.0051 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0290 - val_acc: 0.9800 - val_f1_m: 0.9800 - val_precision_m: 0.9800 - val_recall_m: 0.9800 - val_tp_m: 98.0000 - val_fp_m: 2.0000 - val_tn_m: 98.0000 - val_fn_m: 2.0000\n",
      "epoch time start: 1578297825.4746807\n",
      "Epoch 245/250\n",
      "\n",
      "Epoch 00245: loss did not improve\n",
      "epoch time measured: 23.13651967048645\n",
      " - 23s - loss: 0.0052 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0267 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578297848.612332\n",
      "Epoch 246/250\n",
      "\n",
      "Epoch 00246: loss did not improve\n",
      "epoch time measured: 22.72098159790039\n",
      " - 23s - loss: 0.0067 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578297871.334973\n",
      "Epoch 247/250\n",
      "\n",
      "Epoch 00247: loss did not improve\n",
      "epoch time measured: 23.196751356124878\n",
      " - 23s - loss: 0.0119 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0254 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578297894.5327644\n",
      "Epoch 248/250\n",
      "\n",
      "Epoch 00248: loss did not improve\n",
      "epoch time measured: 23.3268883228302\n",
      " - 23s - loss: 0.0066 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0248 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578297917.860791\n",
      "Epoch 249/250\n",
      "\n",
      "Epoch 00249: loss did not improve\n",
      "epoch time measured: 21.178178071975708\n",
      " - 21s - loss: 0.0070 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0245 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "epoch time start: 1578297939.0399823\n",
      "Epoch 250/250\n",
      "\n",
      "Epoch 00250: loss did not improve\n",
      "epoch time measured: 21.023259162902832\n",
      " - 21s - loss: 0.0047 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - tp_m: 108.8000 - fp_m: 0.0000e+00 - tn_m: 108.8000 - fn_m: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900 - val_tp_m: 99.0000 - val_fp_m: 1.0000 - val_tn_m: 99.0000 - val_fn_m: 1.0000\n",
      "type(totalTrainingTime): <class 'numpy.float64'>\n",
      "type(convergenceEpochs): <class 'str'>\n",
      "Loading train / test dataset :  ../data/eeg_seizure_1/ ../data/eeg_seizure_1/\n",
      "x_train_path: ../data/eeg_seizure_1/X_train.npy\n",
      "Finished processing train dataset..\n",
      "Finished loading test dataset..\n",
      "\n",
      "Number of train samples :  160 Number of test samples :  100\n",
      "Number of classes :  2\n",
      "Sequence length :  4096\n",
      "y_true - 1 Tensor(\"metrics_1/tn_m/sub:0\", shape=(?, ?), dtype=float32)\n",
      "\n",
      "Evaluating : \n",
      "100/100 [==============================] - 4s 40ms/step\n",
      "predictions: [False  True  True  True  True False  True  True  True  True False  True\n",
      " False  True  True  True  True False  True  True  True False  True  True\n",
      "  True False  True  True  True  True  True  True False  True  True  True\n",
      " False  True  True False  True  True False  True  True  True False  True\n",
      " False  True  True False False False  True False  True False False  True\n",
      "  True  True  True  True  True  True  True  True False  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False  True  True]\n",
      "truelabels: [False  True  True  True  True False  True  True  True  True False  True\n",
      "  True  True  True  True  True False  True  True  True False  True  True\n",
      "  True False  True  True  True  True  True  True False  True  True  True\n",
      " False  True  True False  True  True False  True  True  True False  True\n",
      " False  True  True False False False  True False  True False False  True\n",
      "  True  True  True  True  True  True  True  True False  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False  True  True]\n",
      "TP: 79\n",
      "TN: 20\n",
      "FP: 0\n",
      "FN: 1\n",
      "\n",
      "Accuracy: 0.99\n",
      "Precision: 1.0\n",
      "Recall: 0.9875\n",
      "F1: 0.9937106918238994\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    with open(resultsFilename, \"a\") as text_file:\n",
    "        print(f\"Current Fold: 0\", file=text_file)\n",
    "    model = generate_model_2()\n",
    "    train_model(model, DATASET_INDEX_0, dataset_prefix='eeg2_attention', epochs=n_epochs, batch_size=128)\n",
    "    evaluate_model(model, DATASET_INDEX_0, dataset_prefix='eeg2_attention', batch_size=128)\n",
    "    with open(resultsFilename, \"a\") as text_file:\n",
    "        print(f\"Current Fold: 1\", file=text_file)\n",
    "    model = generate_model_2()\n",
    "    train_model(model, DATASET_INDEX_1, dataset_prefix='eeg2_attention', epochs=n_epochs, batch_size=128)\n",
    "    evaluate_model(model, DATASET_INDEX_1, dataset_prefix='eeg2_attention', batch_size=128)  \n",
    "    with open(resultsFilename, \"a\") as text_file:\n",
    "        print(f\"Current Fold: 2\", file=text_file)\n",
    "    model = generate_model_2()\n",
    "    train_model(model, DATASET_INDEX_2, dataset_prefix='eeg2_attention', epochs=n_epochs, batch_size=128)\n",
    "    evaluate_model(model, DATASET_INDEX_2, dataset_prefix='eeg2_attention', batch_size=128)\n",
    "    with open(resultsFilename, \"a\") as text_file:\n",
    "        print(f\"Current Fold: 3\", file=text_file)\n",
    "    model = generate_model_2()\n",
    "    train_model(model, DATASET_INDEX_3, dataset_prefix='eeg2_attention', epochs=n_epochs, batch_size=128)\n",
    "    evaluate_model(model, DATASET_INDEX_3, dataset_prefix='eeg2_attention', batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'results_data_FINAL.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(filepath)\n",
    "accList=list()\n",
    "precisionList=list()\n",
    "recallList=list()\n",
    "f1List=list()\n",
    "\n",
    "for line in f:\n",
    "    if(str(line[0:13])=='Fold Accuracy'):\n",
    "        listStart1=line.find('[')\n",
    "        listEnd1=line.find(']')\n",
    "        list1=ast.literal_eval(line[listStart1:listEnd1+1])\n",
    "        accList.append(list1)\n",
    "    if(str(line[0:14])=='Fold Precision'):\n",
    "        listStart2=line.find('[')\n",
    "        listEnd2=line.find(']')\n",
    "        list2=ast.literal_eval(line[listStart2:listEnd2+1])\n",
    "        precisionList.append(list2)\n",
    "    if(str(line[0:11])=='Fold Recall'):\n",
    "        listStart3=line.find('[')\n",
    "        listEnd3=line.find(']')\n",
    "        list3=ast.literal_eval(line[listStart3:listEnd3+1])\n",
    "        recallList.append(list3)\n",
    "    if(str(line[0:7])=='Fold F1'):\n",
    "        listStart4=line.find('[')\n",
    "        listEnd4=line.find(']')\n",
    "        list4=ast.literal_eval(line[listStart4:listEnd4+1])\n",
    "        f1List.append(list4)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allAccuracies=np.array(accList)\n",
    "averageAccuracy=np.average(allAccuracies, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allPrecisions=np.array(precisionList)\n",
    "averagePrecisions=np.average(allPrecisions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRecall=np.array(recallList)\n",
    "averageRecall=np.average(allRecall, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allF1s=np.array(f1List)\n",
    "averageF1s=np.average(allF1s, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(resultsFilename, \"a\") as text_file:\n",
    "    print(f\"Average Accuracies List: {str(averageAccuracy)}\", file=text_file)\n",
    "    print(f\"Average Precisions List: {str(averagePrecisions)}\", file=text_file)\n",
    "    print(f\"Average Recalls List: {str(averageRecall)}\", file=text_file)\n",
    "    print(f\"Average F1 List: {str(averageF1s)}\", file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
