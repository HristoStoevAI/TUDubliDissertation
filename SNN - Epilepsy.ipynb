{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union, Tuple, List, Sequence, Iterable\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from time import time as t\n",
    "import h5py\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from bindsnet.network.monitors import Monitor\n",
    "from bindsnet.network.nodes import Input, LIFNodes, DiehlAndCookNodes, AdaptiveLIFNodes\n",
    "from bindsnet.network import Network\n",
    "from bindsnet.network.topology import Connection\n",
    "from bindsnet.network.nodes import Input, LIFNodes, AdaptiveLIFNodes\n",
    "\n",
    "from bindsnet.learning import PostPre\n",
    "from bindsnet.evaluation import all_activity, proportion_weighting, assign_labels\n",
    "from bindsnet.analysis.plotting import (\n",
    "    plot_input,\n",
    "    plot_assignments,\n",
    "    plot_performance,\n",
    "    plot_weights,\n",
    "    plot_spikes,\n",
    "    plot_voltages,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 4\n",
    "test_size = 0.2\n",
    "seed = 0\n",
    "n_neurons = 100\n",
    "n_clamp = 1\n",
    "exc = 2.5\n",
    "inh = 22.5\n",
    "time = 4096\n",
    "n_dim = 1\n",
    "dt = 1.0\n",
    "progress_interval = 10\n",
    "update_interval = 25\n",
    "train = True\n",
    "plot = True\n",
    "gpu = False\n",
    "n_class = 2\n",
    "lr_pre = 1\n",
    "lr_post = 1\n",
    "nu = [lr_pre, lr_post]\n",
    "norm = 0.1\n",
    "theta_plus = 0.05,\n",
    "tc_theta_decay = 1e7\n",
    "n_epochs = 1\n",
    "percentage_of_test_set=1\n",
    "if gpu:\n",
    "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "else:\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "from bindsnet.network import load\n",
    "from bindsnet.learning import NoOp\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# In[4]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "test_size = 0.2\n",
    "n_folds = 4\n",
    "n_epochs = 1\n",
    "\n",
    "\n",
    "# In[5]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGSeizureDatasetBalanced(Dataset):\n",
    "    \"\"\"EEG Train dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, testingByDatapoint, returnObservation=None, observationsSize=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            none.\n",
    "        \"\"\"\n",
    "        self.testingByDatapoint = testingByDatapoint\n",
    "        self.returnObservation = returnObservation\n",
    "        self.observationsSize = observationsSize\n",
    "        h5f = h5py.File('seizure_spikes_unbalanced.h5', 'r')\n",
    "        self.spikes_seizure_eeg = h5f['dataset_seizure_spikes_unbalanced'][:]\n",
    "        self.spikes_seizure_eeg=np.swapaxes(self.spikes_seizure_eeg,1,2)\n",
    "        h5f.close()\n",
    "\n",
    "        h5f = h5py.File('seizure_labels_unbalanced.h5', 'r')\n",
    "        self.labels_seizure_eeg = h5f['dataset_seizure_labels_unbalanced'][:]\n",
    "        print(str(np.sum(self.labels_seizure_eeg)) + '/' + str(len(self.labels_seizure_eeg)))\n",
    "        h5f.close()\n",
    "\n",
    "    def get_data(self):\n",
    "        # all folds\n",
    "        dataArray = list()\n",
    "        sss = StratifiedShuffleSplit(n_splits=n_folds, train_size=train_size, test_size=test_size*percentage_of_test_set, random_state=0)\n",
    "        for train_index, test_index in sss.split(self.spikes_seizure_eeg, self.labels_seizure_eeg):\n",
    "\n",
    "            trainLabels = self.labels_seizure_eeg[train_index]\n",
    "            trainValues = self.spikes_seizure_eeg[train_index]\n",
    "            testLabels = self.labels_seizure_eeg[test_index]\n",
    "            testValues = self.spikes_seizure_eeg[test_index]\n",
    "\n",
    "            # BALANCING TRAINING DATA\n",
    "            positivesIndices = trainLabels == 1\n",
    "            positiveEEGs = trainValues[positivesIndices]\n",
    "            negativeEEGs = trainValues[~positivesIndices]\n",
    "            print('positiveEEGs: ' + str(len(positiveEEGs)))\n",
    "            print('negativeEEGs: ' + str(len(negativeEEGs)))\n",
    "\n",
    "            n = np.min([len(positiveEEGs), len(negativeEEGs)])\n",
    "            print(n)\n",
    "\n",
    "            trainValues = (np.concatenate((positiveEEGs[0:n], negativeEEGs[0:n]), axis=0))\n",
    "            trainLabels = (np.concatenate((np.full((n), 1), np.full((n), 0)), axis=0))\n",
    "\n",
    "            shuffle = np.random.RandomState(seed=0).permutation(len(trainValues))\n",
    "            trainValues = trainValues[shuffle]\n",
    "            trainLabels = trainLabels[shuffle]\n",
    "            if (self.testingByDatapoint == True):\n",
    "                trainValues = trainValues[self.returnObservation * self.observationsSize:\n",
    "                                          self.returnObservation * self.observationsSize + self.observationsSize]\n",
    "                # trainValues=trainValues.reshape((1,trainValues.shape[0],trainValues.shape[1]))\n",
    "                print('trainLabels: ' + str(trainLabels))\n",
    "                trainLabels = trainLabels[self.returnObservation * self.observationsSize:\n",
    "                                          self.returnObservation * self.observationsSize + self.observationsSize]\n",
    "                print('trainLabels: ' + str(trainLabels))\n",
    "\n",
    "            currentSplit = {'X_train': torch.tensor(trainValues), 'X_test': torch.tensor(testValues),\n",
    "                            'y_train': torch.tensor(trainLabels), 'y_test': torch.tensor(testLabels)}\n",
    "            dataArray.append(currentSplit)\n",
    "        return dataArray\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.spikes_seizure_eeg)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        eeg = torch.tensor(self.spikes_seizure_eeg[idx])\n",
    "        print('eeg size (in getitem): ' + str(eeg.size()))\n",
    "        label = self.labels_seizure_eeg[idx]\n",
    "\n",
    "        sample = {'eeg': eeg, 'label': label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "# In[6]:\n",
    "\n",
    "\n",
    "dataset = EEGSeizureDatasetBalanced(testingByDatapoint=False)\n",
    "# Create a dataloader to iterate and batch data\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=0, pin_memory=gpu)\n",
    "\n",
    "dataArray = dataset.get_data()\n",
    "n_train = dataArray[0]['X_train'].shape[0]\n",
    "n_test = dataArray[0]['X_test'].shape[0]\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "model = 'diehl_and_cook_2015'\n",
    "data = 'seizure_snn'\n",
    "\n",
    "data_path = os.path.join('data', 'seizure')\n",
    "params_path = os.path.join('params', data, model)\n",
    "spikes_path = os.path.join('spikes', data, model)\n",
    "curves_path = os.path.join('curves', data, model)\n",
    "results_path = os.path.join('results', data, model)\n",
    "confusion_path = os.path.join('confusion', data, model)\n",
    "\n",
    "for path in [params_path, spikes_path, curves_path, results_path, confusion_path]:\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[9]:\n",
    "\n",
    "\n",
    "class NewNetwork(Network):\n",
    "    # language=rst\n",
    "    \"\"\"\n",
    "    Implements the spiking neural network architecture from `(Diehl & Cook 2015)\n",
    "    <https://www.frontiersin.org/articles/10.3389/fncom.2015.00099/full>`_.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_inpt: int,\n",
    "            n_neurons: int = 100,\n",
    "            exc: float = 22.5,\n",
    "            inh: float = 17.5,\n",
    "            dt: float = 1.0,\n",
    "            nu: Optional[Union[float, Sequence[float]]] = (1e-4, 1e-2),\n",
    "            reduction: Optional[callable] = None,\n",
    "            wmin: float = 0.0,\n",
    "            wmax: float = 1.0,\n",
    "            norm: float = 78.4,\n",
    "            theta_plus: float = 0.05,\n",
    "            tc_theta_decay: float = 1e7,\n",
    "            inpt_shape: Optional[Iterable[int]] = None,\n",
    "    ) -> None:\n",
    "        # language=rst\n",
    "        \"\"\"\n",
    "        Constructor for class ``DiehlAndCook2015``.\n",
    "        :param n_inpt: Number of input neurons. Matches the 1D size of the input data.\n",
    "        :param n_neurons: Number of excitatory, inhibitory neurons.\n",
    "        :param exc: Strength of synapse weights from excitatory to inhibitory layer.\n",
    "        :param inh: Strength of synapse weights from inhibitory to excitatory layer.\n",
    "        :param dt: Simulation time step.\n",
    "        :param nu: Single or pair of learning rates for pre- and post-synaptic events,\n",
    "            respectively.\n",
    "        :param reduction: Method for reducing parameter updates along the minibatch\n",
    "            dimension.\n",
    "        :param wmin: Minimum allowed weight on input to excitatory synapses.\n",
    "        :param wmax: Maximum allowed weight on input to excitatory synapses.\n",
    "        :param norm: Input to excitatory layer connection weights normalization\n",
    "            constant.\n",
    "        :param theta_plus: On-spike increment of ``DiehlAndCookNodes`` membrane\n",
    "            threshold potential.\n",
    "        :param tc_theta_decay: Time constant of ``DiehlAndCookNodes`` threshold\n",
    "            potential decay.\n",
    "        :param inpt_shape: The dimensionality of the input layer.\n",
    "        \"\"\"\n",
    "        super().__init__(dt=dt)\n",
    "\n",
    "        self.n_inpt = n_inpt\n",
    "        self.inpt_shape = inpt_shape\n",
    "        self.n_neurons = n_neurons\n",
    "        self.exc = exc\n",
    "        self.inh = inh\n",
    "        self.dt = dt\n",
    "\n",
    "        # Layers\n",
    "        input_layer = Input(\n",
    "            n=self.n_inpt, shape=self.inpt_shape, traces=True, tc_trace=20.0\n",
    "        )\n",
    "        exc_layer = DiehlAndCookNodes(\n",
    "            n=self.n_neurons,\n",
    "            traces=True,\n",
    "            rest=-65.0,\n",
    "            reset=-60.0,\n",
    "            thresh=-52.0,\n",
    "            refrac=5,\n",
    "            tc_decay=100.0,\n",
    "            tc_trace=20.0,\n",
    "            theta_plus=theta_plus,\n",
    "            tc_theta_decay=tc_theta_decay,\n",
    "        )\n",
    "        inh_layer = LIFNodes(\n",
    "            n=self.n_neurons,\n",
    "            traces=False,\n",
    "            rest=-60.0,\n",
    "            reset=-45.0,\n",
    "            thresh=-40.0,\n",
    "            tc_decay=10.0,\n",
    "            refrac=2,\n",
    "            tc_trace=20.0,\n",
    "        )\n",
    "\n",
    "        # Connections\n",
    "        w = 0.3 * torch.rand(self.n_inpt, self.n_neurons)\n",
    "        input_exc_conn = Connection(\n",
    "            source=input_layer,\n",
    "            target=exc_layer,\n",
    "            w=w,\n",
    "            update_rule=PostPre,\n",
    "            nu=nu,\n",
    "            reduction=reduction,\n",
    "            wmin=wmin,\n",
    "            wmax=wmax,\n",
    "            norm=norm,\n",
    "        )\n",
    "        w = self.exc * torch.diag(torch.ones(self.n_neurons))\n",
    "        exc_inh_conn = Connection(\n",
    "            source=exc_layer, target=inh_layer, w=w, wmin=0, wmax=self.exc\n",
    "        )\n",
    "        w = -self.inh * (\n",
    "                torch.ones(self.n_neurons, self.n_neurons)\n",
    "                - torch.diag(torch.ones(self.n_neurons))\n",
    "        )\n",
    "        inh_exc_conn = Connection(\n",
    "            source=inh_layer, target=exc_layer, w=w, wmin=-self.inh, wmax=0\n",
    "        )\n",
    "\n",
    "        # Add to network\n",
    "        self.add_layer(input_layer, name=\"X\")\n",
    "        self.add_layer(exc_layer, name=\"Ae\")\n",
    "        self.add_layer(inh_layer, name=\"Ai\")\n",
    "        self.add_connection(input_exc_conn, source=\"X\", target=\"Ae\")\n",
    "        self.add_connection(exc_inh_conn, source=\"Ae\", target=\"Ai\")\n",
    "        self.add_connection(inh_exc_conn, source=\"Ai\", target=\"Ae\")\n",
    "\n",
    "\n",
    "# In[29]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSNN(seed=0, singleSample=False, n_neurons=n_neurons, n_train=n_train, n_test=n_test, inh=inh, exc=exc,\n",
    "              lr_pre=lr_pre,\n",
    "              lr_post=lr_post, time=time, dt=dt, norm=norm, intensity=30, progress_interval=progress_interval,\n",
    "              update_interval=update_interval, plot=True, train=True, gpu=False, current_fold=0, current_epoch=0):\n",
    "    n_sqrt = int(np.ceil(np.sqrt(n_neurons)))\n",
    "    per_class = int(n_neurons / n_class)\n",
    "\n",
    "    params = [\n",
    "        seed, n_neurons, inh, exc, lr_pre, lr_post, time, dt, norm,\n",
    "        intensity, progress_interval, current_fold\n",
    "    ]\n",
    "    print('params: ' + str(params))\n",
    "\n",
    "    model_name = '_'.join([str(x) for x in params])\n",
    "\n",
    "    dataset = EEGSeizureDatasetBalanced(testingByDatapoint=singleSample, returnObservation=current_epoch, observationsSize=n_train)\n",
    "    # Create a dataloader to iterate and batch data\n",
    "    totalTrainingTimeSecs = list()\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=0, pin_memory=gpu)\n",
    "    dataArray = dataset.get_data()\n",
    "\n",
    "\n",
    "    # nu: Single or pair of learning rates for pre- and post-synaptic events, respectively.\n",
    "    if (train == True):\n",
    "        if (current_epoch == 0):\n",
    "            print('starting training (new network): ')\n",
    "\n",
    "            network = NewNetwork(\n",
    "                n_inpt=n_dim,\n",
    "                n_neurons=n_neurons,\n",
    "                exc=exc,\n",
    "                inh=inh,\n",
    "                dt=dt,\n",
    "                norm=norm,\n",
    "                nu=[lr_pre, lr_post],\n",
    "                inpt_shape=(n_dim, 1, 1))\n",
    "            print('NewNetwork: ' + str(network))\n",
    "        else:\n",
    "            print('continuing training (loading network): ')\n",
    "            print('loading model from: ' + str(os.path.join(params_path, model_name + '.pt')))\n",
    "\n",
    "            network = load(os.path.join(params_path, model_name + '.pt'), learning=True)\n",
    "\n",
    "    else:\n",
    "        print('starting testing: ')\n",
    "        if os.path.exists(os.path.join(params_path, model_name + '.pt')):\n",
    "            print('loading model from: ' + str(os.path.join(params_path, model_name + '.pt')))\n",
    "            network = load(os.path.join(params_path, model_name + '.pt'), learning=False)\n",
    "            network.connections['X', 'Ae'].update_rule = NoOp(\n",
    "                connection=network.connections['X', 'Ae'], nu=network.connections['X', 'Ae'].nu\n",
    "            )\n",
    "            network.layers['Ae'].tc_theta_decay = torch.Tensor([0])\n",
    "            network.layers['Ae'].theta_plus = torch.Tensor([0])\n",
    "\n",
    "            network.connections['Ae', 'Ai'].update_rule = NoOp(\n",
    "                connection=network.connections['Ae', 'Ai'], nu=network.connections['Ae', 'Ai'].nu\n",
    "            )\n",
    "            network.layers['Ai'].tc_theta_decay = torch.Tensor([0])\n",
    "            network.layers['Ai'].theta_plus = torch.Tensor([0])\n",
    "\n",
    "            network.connections['Ai', 'Ae'].update_rule = NoOp(\n",
    "                connection=network.connections['Ai', 'Ae'], nu=network.connections['Ai', 'Ae'].nu\n",
    "            )\n",
    "        else:\n",
    "            network = NewNetwork(\n",
    "                n_inpt=n_dim,\n",
    "                n_neurons=n_neurons,\n",
    "                exc=exc,\n",
    "                inh=inh,\n",
    "                dt=dt,\n",
    "                norm=norm,\n",
    "                nu=[lr_pre, lr_post],\n",
    "                inpt_shape=(n_dim, 1, 1))\n",
    "            print('NewNetwork: ' + str(network))\n",
    "    # network.to(\"cuda\")\n",
    "\n",
    "    if (train == False):\n",
    "        update_interval = n_test\n",
    "\n",
    "    # Voltage recording for excitatory and inhibitory layers.\n",
    "    exc_voltage_monitor = Monitor(network.layers[\"Ae\"], [\"v\"], time=time)\n",
    "    inh_voltage_monitor = Monitor(network.layers[\"Ai\"], [\"v\"], time=time)\n",
    "    network.add_monitor(exc_voltage_monitor, name=\"exc_voltage\")\n",
    "    network.add_monitor(inh_voltage_monitor, name=\"inh_voltage\")\n",
    "\n",
    "    # Record spikes during the simulation.\n",
    "    spike_record = torch.zeros(update_interval, time, n_neurons)\n",
    "\n",
    "    # Neuron assignments and spike proportions.\n",
    "    assignments = -torch.ones_like(torch.Tensor(n_neurons))\n",
    "    proportions = torch.zeros_like(torch.Tensor(n_neurons, n_class))\n",
    "    rates = torch.zeros_like(torch.Tensor(n_neurons, n_class))\n",
    "\n",
    "    # Neuron assignments and spike proportions.\n",
    "    if (train == True):\n",
    "        if (current_epoch == 0):\n",
    "            assignments = -torch.ones_like(torch.Tensor(n_neurons))\n",
    "            proportions = torch.zeros_like(torch.Tensor(n_neurons, n_class))\n",
    "            rates = torch.zeros_like(torch.Tensor(n_neurons, n_class))\n",
    "        else:\n",
    "            path = os.path.join(params_path, '_'.join(['auxiliary', model_name]) + '.pt')\n",
    "            assignments, proportions, rates = torch.load(open(path, 'rb'))\n",
    "    else:\n",
    "        if os.path.exists(os.path.join(params_path, '_'.join(['auxiliary', model_name]) + '.pt')):\n",
    "            path = os.path.join(params_path, '_'.join(['auxiliary', model_name]) + '.pt')\n",
    "            assignments, proportions, rates = torch.load(open(path, 'rb'))\n",
    "        else:\n",
    "            assignments = -torch.ones_like(torch.Tensor(n_neurons))\n",
    "            proportions = torch.zeros_like(torch.Tensor(n_neurons, n_class))\n",
    "            rates = torch.zeros_like(torch.Tensor(n_neurons, n_class))\n",
    "\n",
    "    # Sequence of accuracy estimates.\n",
    "    accuracy = {\"all\": [], \"proportion\": []}\n",
    "    batchTime =0\n",
    "\n",
    "    spikes = {}\n",
    "    for layer in set(network.layers) - {\"X\"}:\n",
    "        spikes[layer] = Monitor(network.layers[layer], state_vars=[\"s\"], time=time)\n",
    "        network.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)\n",
    "\n",
    "    for epoch in np.arange(n_epochs):\n",
    "        print('epoch: ' + str(epoch))\n",
    "\n",
    "        if train:\n",
    "            images = dataArray[current_fold]['X_train']\n",
    "            images *= intensity\n",
    "            labels = dataArray[current_fold]['y_train']\n",
    "            print('\\nBegin training.\\n')\n",
    "            n_examples = n_train\n",
    "            print('n_examples: ' + str(n_examples))\n",
    "        else:\n",
    "            images = dataArray[current_fold]['X_test']\n",
    "            images *= intensity\n",
    "            labels = dataArray[current_fold]['y_test']\n",
    "            print('\\nBegin testing.\\n')\n",
    "            n_examples = n_test\n",
    "            print('n_examples: ' + str(n_examples))\n",
    "\n",
    "        all_dataset_predictions_all = np.zeros(shape=(n_examples))\n",
    "        all_dataset_predictions_prop = np.zeros(shape=(n_examples))\n",
    "        startOfModelTime = t()\n",
    "        for i in range(n_examples):\n",
    "            startOfBatchTime = t()\n",
    "            print('n_examples: ' + str(n_examples))\n",
    "            print('i: ' + str(i))\n",
    "            print('update_interval: ' + str(update_interval))\n",
    "            if train:\n",
    "                print(\"Train progress: (%d / %d)\" % (i, n_examples))\n",
    "            else:\n",
    "                print(\"Test progress: (%d / %d)\" % (i, n_examples))\n",
    "            print('len(images): ' + str(len(images)))\n",
    "            print('(images).shape: ' + str((images).shape))\n",
    "\n",
    "            image = images[i % len(images)]\n",
    "            print('len(labels): ' + str(len(labels)))\n",
    "\n",
    "            label = labels[i % len(labels)]\n",
    "\n",
    "            # print('Current (i, dataPoint): '+str((i, dataPoint)))\n",
    "            if (train == True):\n",
    "                if i > n_train:\n",
    "                    break\n",
    "            else:\n",
    "                if i > n_test:\n",
    "                    break\n",
    "            # image = dataPoint[\"eeg\"]\n",
    "            # label = dataPoint[\"label\"]\n",
    "            print('current label: ' + str(label))\n",
    "\n",
    "            # Optionally plot various simulation information.\n",
    "\n",
    "            # Run the network on the input.\n",
    "            choice = np.random.choice(int(n_neurons / n_class), size=n_clamp, replace=False)\n",
    "            clamp = {\"Ae\": per_class * label.long() + torch.Tensor(choice).long()}\n",
    "            inputs = {\"X\": image.view(time, n_dim, 1, 1)}\n",
    "\n",
    "            network.run(inputs=inputs, time=time, clamp=clamp)\n",
    "            print(\"Model Time Elapsed (secs): \" + str((t() - startOfModelTime)))\n",
    "\n",
    "            # Get voltage recording.\n",
    "            exc_voltages = exc_voltage_monitor.get(\"v\")\n",
    "            inh_voltages = inh_voltage_monitor.get(\"v\")\n",
    "\n",
    "            voltages = {\"Ae\": exc_voltages, \"Ai\": inh_voltages}\n",
    "\n",
    "            print('spikes[\"Ae\"]: ' + str(spikes[\"Ae\"]))\n",
    "            spike_record[i % update_interval] = spikes[\"Ae\"].get(\"s\").view(time, n_neurons)\n",
    "\n",
    "            # print('all_labels_in_batch before network reset '+str(all_labels_in_batch))\n",
    "\n",
    "            network.reset_state_variables()  # Reset state variables.\n",
    "\n",
    "            if ((i) % update_interval == 0 and train==True) or ((i+1) % (update_interval) == 0 and train==False ):\n",
    "                if (train):\n",
    "                    update_labels = label\n",
    "                else:\n",
    "                    update_labels = labels\n",
    "                print('(i) % update_interval: ' + str(i))\n",
    "                # Get network predictions.\n",
    "                all_activity_pred = all_activity(spike_record, assignments, n_class)\n",
    "                print('predictions: ' + str(all_activity_pred))\n",
    "                print('labels: ' + str(update_labels.long()))\n",
    "                proportion_pred = proportion_weighting(\n",
    "                    spike_record, assignments, proportions, n_class\n",
    "                )\n",
    "\n",
    "                # Compute network accuracy according to available classification strategies.\n",
    "                accuracy[\"all\"].append(\n",
    "                    100 * torch.sum(update_labels.long() == all_activity_pred.cpu()).item() / update_interval\n",
    "                )\n",
    "                accuracy[\"proportion\"].append(\n",
    "                    100 * torch.sum(update_labels.long() == proportion_pred.cpu()).item() / update_interval\n",
    "                )\n",
    "\n",
    "                print(\n",
    "                    \"\\nAll activity accuracy: %.2f (last), %.2f (average), %.2f (best)\"\n",
    "                    % (accuracy[\"all\"][-1], np.mean(accuracy[\"all\"]), np.max(accuracy[\"all\"]))\n",
    "                )\n",
    "                print(\n",
    "                    \"Proportion weighting accuracy: %.2f (last), %.2f (average), %.2f (best)\\n\"\n",
    "                    % (\n",
    "                        accuracy[\"proportion\"][-1],\n",
    "                        np.mean(accuracy[\"proportion\"]),\n",
    "                        np.max(accuracy[\"proportion\"]),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                # Assign labels to excitatory layer neurons.\n",
    "                print('updating assignments: ')\n",
    "                print('spike_record: ' + str(spike_record))\n",
    "                print('rates: ' + str(rates))\n",
    "\n",
    "                assignments, proportions, rates = assign_labels(spike_record, label.view(1), 2, rates, 1)\n",
    "            # print('network layers: '+str(network.layers))\n",
    "            if(train==True):\n",
    "                batchTime=(t() - startOfBatchTime)\n",
    "                totalTrainingTimeSecs.append(batchTime)\n",
    "                print('appending time...')\n",
    "                print('totalTrainingTimeSecs: '+str(totalTrainingTimeSecs))\n",
    "\n",
    "\n",
    "        # print(\"Progress: %d / %d \\n\" % (n_train, n_train))\n",
    "        print(\"Training complete.\\n\")\n",
    "\n",
    "    # Save network to disk.\n",
    "    if train:\n",
    "        print('saving model to: ' + str(os.path.join(params_path, model_name + '.pt')))\n",
    "        network.save(os.path.join(params_path, model_name + '.pt'))\n",
    "        path = os.path.join(params_path, '_'.join(['auxiliary', model_name]) + '.pt')\n",
    "        torch.save((assignments, proportions, rates), open(path, 'wb'))\n",
    "\n",
    "    if(train==False):\n",
    "        # Compute confusion matrices .\n",
    "        confusions = {}\n",
    "        confusions['prop'] = confusion_matrix(labels.cpu(), proportion_pred)\n",
    "        confusions['all'] = confusion_matrix(labels.cpu(), all_activity_pred)\n",
    "        print('all confusion_matrix(labels, all_activity_pred): ' + str(\n",
    "            confusion_matrix(labels, all_activity_pred)))\n",
    "        print('prop confusion_matrix(labels, proportion_pred): ' + str(\n",
    "            confusion_matrix(labels, proportion_pred)))\n",
    "        return confusions, totalTrainingTimeSecs\n",
    "    else:\n",
    "        return 0, totalTrainingTimeSecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neurons': [5, 10], 'lr_pre': [0.1, 1], 'lr_post': [0.1, 1], 'exc': [5, 25, 125],\n",
    "              'inh': [5, 25, 125], 'update_interval': [1], 'n_epochs': [1]}\n",
    "\n",
    "param_grid = {'n_neurons': [5], 'lr_pre': [0.1], 'lr_post': [0.1], 'exc': [5], 'inh': [5], 'update_interval': [1], 'n_epochs': [1]}\n",
    "#optimal params\n",
    "\n",
    "grid = ParameterGrid(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "Results file exists\n",
      "Begin training for fold 0\n",
      "\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "starting training (new network): \n",
      "NewNetwork: NewNetwork(\n",
      "  (X): Input()\n",
      "  (Ae): DiehlAndCookNodes()\n",
      "  (Ai): LIFNodes()\n",
      "  (X_to_Ae): Connection(\n",
      "    (source): Input()\n",
      "    (target): DiehlAndCookNodes()\n",
      "  )\n",
      "  (Ae_to_Ai): Connection(\n",
      "    (source): DiehlAndCookNodes()\n",
      "    (target): LIFNodes()\n",
      "  )\n",
      "  (Ai_to_Ae): Connection(\n",
      "    (source): LIFNodes()\n",
      "    (target): DiehlAndCookNodes()\n",
      "  )\n",
      ")\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(0)\n",
      "Model Time Elapsed (secs): 5.363293647766113\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8e2b38>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [5.387018203735352]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "Training complete for index: 0\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.66915225982666\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.24047064781189\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 10.850929021835327\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 14.505181789398193\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 18.039021253585815\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 21.74318289756775\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 25.32272434234619\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 28.979057550430298\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 32.693971395492554\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 36.32556176185608\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 40.00868606567383\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 43.64981508255005\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 47.286380767822266\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 50.9528226852417\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 55.0227632522583\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 60.00027418136597\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 65.02389216423035\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 69.9392740726471\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 74.94475054740906\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 80.01096892356873\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 85.15577173233032\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 90.29586338996887\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 95.46201920509338\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 100.52129030227661\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 105.62155771255493\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 110.64488005638123\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 115.25154566764832\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 118.97225093841553\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 122.77375292778015\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 126.52245616912842\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 130.20489144325256\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 133.95273995399475\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 138.26476764678955\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 143.45252871513367\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 148.63215017318726\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 152.79156255722046\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 156.35957741737366\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 159.97352766990662\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 163.51195287704468\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 167.21219968795776\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 170.8714153766632\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 174.50012183189392\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 178.14147090911865\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 182.8808126449585\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 186.59846997261047\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 190.36678624153137\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 193.91676354408264\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 197.61750745773315\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 201.32391023635864\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 205.13149881362915\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 209.11292099952698\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 212.97639417648315\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 216.76719093322754\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 220.53517055511475\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 224.35916352272034\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 228.1164038181305\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 231.8342616558075\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 236.049729347229\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 240.2122528553009\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 244.85719466209412\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 249.0893576145172\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 252.7299246788025\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 256.4593679904938\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 260.0717628002167\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 263.70243287086487\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 267.5013816356659\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 271.23033595085144\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 274.88898611068726\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 278.63552951812744\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 282.342814207077\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 286.0732922554016\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 289.75420475006104\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 293.47643399238586\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 297.2217891216278\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 301.0078203678131\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 304.77978563308716\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 308.6122636795044\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 312.26178646087646\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 315.9339232444763\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 319.62058877944946\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 323.34312987327576\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 326.97767877578735\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 330.71530532836914\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 334.5104115009308\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 338.32357597351074\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 342.2055416107178\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 346.0394198894501\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 349.88718247413635\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 353.71551179885864\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 357.53382182121277\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 361.3530185222626\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 365.2657742500305\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 369.1769292354584\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 373.0790693759918\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 376.93617963790894\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 380.795583486557\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 384.6671402454376\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 388.55423402786255\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 392.47215461730957\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 396.3474771976471\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "\n",
      "All activity accuracy: 91.00 (last), 91.00 (average), 91.00 (best)\n",
      "Proportion weighting accuracy: 80.00 (last), 80.00 (average), 80.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 1., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [4.0960e+03, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [ 9 11]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [20  0]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 4.865388870239258\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c8c29d630>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [4.0960e+03, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [4.8874218463897705]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "Training complete for index: 1\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.7238261699676514\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.492466926574707\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 11.262746572494507\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 14.996495962142944\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 18.70840549468994\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.396236658096313\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 26.071378469467163\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 29.752540826797485\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 33.48229455947876\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 37.150041341781616\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 40.83651375770569\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 44.49336838722229\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 48.18134379386902\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 51.87883639335632\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 55.52094912528992\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 59.09683561325073\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 62.67187213897705\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 66.2744493484497\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 69.95190095901489\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 73.70073986053467\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 77.35072422027588\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 80.96677350997925\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 84.6118814945221\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 88.31699728965759\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 91.99897241592407\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 95.68139696121216\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 99.31992316246033\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 102.87959051132202\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 106.56356263160706\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 110.32532072067261\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 114.07942986488342\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 117.85461735725403\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 121.53172159194946\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 125.14625763893127\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 128.75740599632263\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 132.37454223632812\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 136.13274788856506\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 139.83976125717163\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 143.5470371246338\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 147.26692962646484\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 151.00475454330444\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 154.74434399604797\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 158.4891905784607\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 162.17831707000732\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 165.87864470481873\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 169.49759531021118\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 173.11089754104614\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 176.7969388961792\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 180.4631543159485\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 184.11236214637756\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 187.7810423374176\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 191.4556701183319\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 195.1350758075714\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 198.81064414978027\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 202.51787424087524\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 206.21276998519897\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 209.9070827960968\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 213.53817343711853\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 217.24108791351318\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 220.9328808784485\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 224.6637966632843\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 228.3372082710266\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 232.060124874115\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 235.7551383972168\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 239.4036054611206\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 243.17261004447937\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 246.85982465744019\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 250.64747023582458\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 254.41452074050903\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 258.1717336177826\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 261.96169686317444\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 265.81058049201965\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 269.5919463634491\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 273.42236614227295\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 277.2627317905426\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 281.02533888816833\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 284.7959623336792\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 288.57551646232605\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 292.31829714775085\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 296.06652069091797\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 299.78572607040405\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 303.47827315330505\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 307.186425447464\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 310.9691936969757\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 314.70801639556885\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 318.5259819030762\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 322.3652708530426\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 326.16578245162964\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 329.97477650642395\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 333.7738332748413\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 337.48208832740784\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 341.17525601387024\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 344.89135932922363\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 348.58264994621277\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 352.27603030204773\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 355.9504165649414\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 359.677001953125\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 363.3051428794861\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 366.9201195240021\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 370.52064990997314\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da58>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "\n",
      "All activity accuracy: 80.00 (last), 80.00 (average), 80.00 (best)\n",
      "Proportion weighting accuracy: 80.00 (last), 80.00 (average), 80.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [8.1920e+03, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [20  0]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [20  0]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 4.894525766372681\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057438>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [8.1920e+03, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [4.916100025177002]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "Training complete for index: 2\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.776373863220215\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.6658830642700195\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 11.51772165298462\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 15.343085765838623\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 19.1621675491333\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.96545672416687\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 26.655505895614624\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 30.426856994628906\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 34.19679236412048\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 37.89890003204346\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 41.60871171951294\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 45.38680815696716\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 49.185683727264404\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 52.90957045555115\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 56.597922563552856\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 60.31332540512085\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 64.00058913230896\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 67.6551923751831\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 71.2702157497406\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 74.91844844818115\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 78.5437982082367\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 82.15388870239258\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 85.88616251945496\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 89.61778402328491\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 93.31003427505493\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 96.9887523651123\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 100.69323348999023\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 104.39876866340637\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 108.13950037956238\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 111.8550968170166\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 115.58948040008545\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 119.30987501144409\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 123.030690908432\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 126.73860001564026\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 130.57186245918274\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 134.37304639816284\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 138.20937490463257\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 142.04877066612244\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 145.82617831230164\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 149.63519763946533\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 153.33148050308228\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 157.04889369010925\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 160.77927207946777\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 164.5035102367401\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 168.19130682945251\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 172.01658177375793\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 175.74971771240234\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 179.46721243858337\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 183.22894310951233\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 187.01223969459534\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 190.79650354385376\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 194.61301445960999\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 198.31626200675964\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 202.0397617816925\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 205.66874504089355\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 209.27544856071472\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 212.94191527366638\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 216.59509992599487\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 220.17617392539978\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 223.903395652771\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 227.65862131118774\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 231.4127233028412\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 235.16411471366882\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 238.99012207984924\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 242.74814820289612\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 246.48103499412537\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 250.23155665397644\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 253.994726896286\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 257.80384826660156\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 261.52164912223816\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 265.2003700733185\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 268.91529083251953\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 272.7136344909668\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 276.4824392795563\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 280.3612332344055\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 284.1585772037506\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 287.8952293395996\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 291.50023102760315\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 295.11190605163574\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 298.8068301677704\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 302.5748145580292\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 306.2531216144562\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 309.916134595871\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 313.569536447525\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 317.1990432739258\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 320.79593658447266\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 324.41857743263245\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 328.05058240890503\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 331.6603081226349\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 335.2469639778137\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 338.8448865413666\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 342.5014624595642\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 346.197571516037\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 349.78323101997375\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 353.43123054504395\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 357.11793303489685\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 360.8310718536377\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 364.69728779792786\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 368.4977855682373\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 372.3015341758728\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2470>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "\n",
      "All activity accuracy: 80.00 (last), 80.00 (average), 80.00 (best)\n",
      "Proportion weighting accuracy: 80.00 (last), 80.00 (average), 80.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.2288e+04, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [20  0]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [20  0]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 4.947269678115845\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582860>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 0.00 (last), 0.00 (average), 0.00 (best)\n",
      "Proportion weighting accuracy: 0.00 (last), 0.00 (average), 0.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.2288e+04, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [4.970169544219971]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "Training complete for index: 3\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.7301878929138184\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.497545957565308\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 11.335597515106201\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 15.137394666671753\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 18.836899995803833\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.46840524673462\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 26.08417296409607\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 29.697613954544067\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 33.36774277687073\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 36.954007387161255\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 40.54385852813721\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 44.205525398254395\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 47.8582022190094\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 51.47877645492554\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 55.289390325546265\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 58.99269127845764\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 62.67829704284668\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 66.35374736785889\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 70.13320994377136\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 73.89013814926147\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 77.5816261768341\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 81.27161574363708\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 85.66429686546326\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 90.72313642501831\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 95.83306121826172\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 100.99353909492493\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 105.02475881576538\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 108.74025630950928\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 112.4631986618042\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 116.22043466567993\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 119.96044754981995\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 123.67797470092773\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 127.23458051681519\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 130.79012989997864\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 134.41042256355286\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 137.98351049423218\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 141.5667850971222\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 145.25570249557495\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 148.91913080215454\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 152.58830285072327\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 156.25433683395386\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 159.90286350250244\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 163.54695081710815\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 167.24444770812988\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 170.85730648040771\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 174.52481508255005\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 178.16511130332947\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 181.79363298416138\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 185.4765386581421\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 189.09394001960754\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 192.7579653263092\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 196.38510012626648\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 200.16723537445068\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 203.8689820766449\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 207.6073567867279\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 211.29373455047607\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 214.9716408252716\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 218.6338768005371\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 222.2869565486908\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 225.99875283241272\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 229.81258726119995\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 233.49169731140137\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 237.10271620750427\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 240.69367027282715\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 244.30979752540588\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 247.88449692726135\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 251.4859640598297\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 255.04022479057312\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 258.77384781837463\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 262.4178903102875\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 265.9842987060547\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 269.7113857269287\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 273.30585622787476\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 276.93425035476685\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 280.654244184494\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 284.2290165424347\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 287.96863555908203\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 291.7635462284088\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 295.4550666809082\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 299.1358745098114\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 302.7530343532562\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 306.2916190624237\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 309.86913681030273\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 313.5376515388489\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 317.14336585998535\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 320.74390292167664\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 324.37039828300476\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 327.9690043926239\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 331.59749698638916\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 335.3584702014923\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 339.04278898239136\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 342.71330761909485\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 346.4169099330902\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 350.0926444530487\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 353.7703583240509\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 357.5121719837189\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 361.24638986587524\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 364.9232907295227\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 368.74563217163086\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 372.41235160827637\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "\n",
      "All activity accuracy: 91.00 (last), 91.00 (average), 91.00 (best)\n",
      "Proportion weighting accuracy: 91.00 (last), 91.00 (average), 91.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 1., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 4.0960e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [ 9 11]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [ 9 11]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 4.961463689804077\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2518>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 4.0960e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [4.986013174057007]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "Training complete for index: 4\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.6443068981170654\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 8.197568893432617\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 13.126852750778198\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 18.05430793762207\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.95788550376892\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 26.60613775253296\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 30.160058975219727\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 33.7308464050293\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 37.28320026397705\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 40.85853695869446\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 44.408074378967285\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 48.07179594039917\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 51.68951225280762\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 55.36578989028931\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 59.06349802017212\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 62.742050647735596\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 66.41388773918152\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 70.17457103729248\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 73.84014415740967\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 77.56984186172485\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 81.2357668876648\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 84.85516357421875\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 88.54005861282349\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 92.1524908542633\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 95.89448380470276\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 99.63945174217224\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 103.42714476585388\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 107.22763800621033\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 111.04903984069824\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 115.31638312339783\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 118.9341402053833\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 122.55542087554932\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 126.24697661399841\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 129.9473114013672\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 133.72057461738586\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 137.39365100860596\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 141.0638566017151\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 144.79970264434814\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 148.5185854434967\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 152.24477887153625\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 156.13882064819336\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 159.86116075515747\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 163.56520700454712\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 167.34490036964417\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 170.92871832847595\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 174.5676989555359\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 178.18527698516846\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 181.79655241966248\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 185.47442483901978\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 189.14924383163452\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 192.80906558036804\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 196.5403974056244\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 200.20365500450134\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 203.8934361934662\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 207.5900399684906\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 211.26631832122803\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 214.9144606590271\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 218.6522397994995\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 222.29044890403748\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 225.96382689476013\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 229.58446145057678\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 233.24785494804382\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 236.90404152870178\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 240.82697558403015\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 244.5002784729004\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 248.28429555892944\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 252.08922243118286\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 255.82352256774902\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 259.5363562107086\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 263.27339720726013\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 266.9238200187683\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 270.480233669281\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 274.0383086204529\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 277.5909614562988\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 281.2618989944458\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 284.97837352752686\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 288.7515823841095\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 292.50889325141907\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 296.46169996261597\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 300.2197275161743\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 304.03069734573364\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 307.73289251327515\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 311.44531178474426\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 315.12949228286743\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 318.798761844635\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 322.46449041366577\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 326.2316002845764\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 329.9152398109436\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 333.60822916030884\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 337.3022229671478\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 340.85653710365295\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 344.4358985424042\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 349.42812275886536\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 354.34066796302795\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 357.98856139183044\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 361.6008722782135\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 365.2458276748657\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 368.8772556781769\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 372.6305480003357\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 376.31252431869507\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "\n",
      "All activity accuracy: 94.00 (last), 94.00 (average), 94.00 (best)\n",
      "Proportion weighting accuracy: 94.00 (last), 94.00 (average), 94.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [ 6 14]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [ 6 14]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 5.148444175720215\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [5.1731603145599365]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "Training complete for index: 5\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 4.015322208404541\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 9.149127006530762\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 14.330608606338501\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 19.470566987991333\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 24.540971994400024\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 29.600157737731934\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 34.67096519470215\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 38.369874238967896\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 42.1522798538208\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 45.836177825927734\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 49.5295672416687\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 53.20115613937378\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 56.84569430351257\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 60.50141954421997\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 64.2116904258728\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 67.88747000694275\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 71.60916948318481\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 75.36257243156433\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 79.05940318107605\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 82.71982908248901\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 86.46472597122192\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 90.19474339485168\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 93.82816958427429\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 98.27575826644897\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 101.9436047077179\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 105.63509702682495\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 109.27769327163696\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 112.90112566947937\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 116.57586193084717\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 120.21179938316345\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 123.92217421531677\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 127.67911767959595\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 131.29785227775574\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 134.9283652305603\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 138.55039405822754\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 142.19306540489197\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 145.85007190704346\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 149.56892681121826\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 153.20326042175293\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 156.82306003570557\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 160.4417963027954\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 164.09254670143127\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 167.73570370674133\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 171.4051637649536\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 175.04832458496094\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 178.73512053489685\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 182.4375603199005\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 187.15722250938416\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 191.1202733516693\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 194.92980766296387\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 198.62461471557617\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 202.32332038879395\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 206.16818118095398\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 209.8950068950653\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 213.61793971061707\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 217.30576515197754\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 220.97565007209778\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 224.65376353263855\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 228.3689296245575\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 232.08719658851624\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 235.8797092437744\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 239.57585740089417\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 243.27066373825073\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 246.92480540275574\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 250.56749963760376\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 254.2014241218567\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 257.8212208747864\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 261.45294213294983\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 265.55653047561646\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 269.23273277282715\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 272.8419773578644\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 276.4557800292969\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 280.0718686580658\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 283.6552529335022\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 287.2848570346832\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 290.9350492954254\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 294.5910482406616\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 298.3015031814575\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 301.93013525009155\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 305.5538799762726\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 309.15053629875183\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 312.738977432251\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 316.37033891677856\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 320.0414454936981\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 323.65706038475037\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 327.2425992488861\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 330.81793570518494\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 335.41699481010437\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 339.67177295684814\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 343.3223659992218\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 346.92204666137695\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 350.5233817100525\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 354.157377243042\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 357.8043746948242\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 362.705486536026\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 367.64931774139404\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 372.53572821617126\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 377.42563676834106\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 382.38135981559753\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 387.4383044242859\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "\n",
      "All activity accuracy: 92.00 (last), 92.00 (average), 92.00 (best)\n",
      "Proportion weighting accuracy: 92.00 (last), 92.00 (average), 92.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[4.0970e+03, 0.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [ 8 12]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [ 8 12]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 5.111056327819824\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[4.0970e+03, 0.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [5.13834810256958]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "Training complete for index: 6\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.758007526397705\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.427205324172974\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 11.260272741317749\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 14.868876218795776\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 18.4990394115448\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.257513999938965\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 25.9682457447052\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 29.634637355804443\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 33.30228638648987\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 36.98682236671448\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 40.78588271141052\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 44.53263854980469\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 48.23892426490784\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 51.94365930557251\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 55.65593385696411\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 59.262574195861816\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 62.929829120635986\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 66.68832230567932\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 70.35937547683716\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 74.03095126152039\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 77.71380400657654\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 81.37621188163757\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 85.07001423835754\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 88.8367269039154\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 92.55789971351624\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 96.30427265167236\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 100.05310487747192\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 103.71882796287537\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 107.46333241462708\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 111.06639289855957\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 114.87921142578125\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 118.66327166557312\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 122.4060115814209\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 126.13359332084656\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 130.02407503128052\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 133.87017178535461\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 137.63682913780212\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 141.3858778476715\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 145.11970901489258\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 148.85915994644165\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 152.66300463676453\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 156.40604043006897\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 160.16035771369934\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 163.9535539150238\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 167.741450548172\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 171.55445003509521\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 175.39086508750916\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 179.16516971588135\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 182.93465423583984\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 186.67982697486877\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 190.40636038780212\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 194.16979432106018\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 197.99015879631042\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 201.753888130188\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 205.54104804992676\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 209.3138782978058\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 213.08144187927246\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 216.88747119903564\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 220.62087035179138\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 224.34445929527283\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 228.0717203617096\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 231.85180473327637\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 235.60555338859558\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 239.4352512359619\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 243.12302994728088\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 246.74242329597473\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 250.4017312526703\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 254.0796926021576\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 257.7801959514618\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 261.67828345298767\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 265.52111530303955\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 269.3549783229828\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 273.1636242866516\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 276.98151326179504\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 280.7325077056885\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 284.5467574596405\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 288.31603956222534\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 292.2141261100769\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 296.0161964893341\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 299.7250247001648\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 303.47588086128235\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 307.27298045158386\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 311.0626745223999\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 314.8859040737152\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 318.65697407722473\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 322.39700174331665\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 326.25155234336853\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 330.0421550273895\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 333.8976933956146\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 337.7498633861542\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 341.6554379463196\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 345.53933334350586\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 349.4961884021759\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 353.3797118663788\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 357.2492210865021\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 361.0988771915436\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 364.8595886230469\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 368.62141513824463\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 372.5649061203003\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 376.3866548538208\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c91422550>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "\n",
      "All activity accuracy: 87.00 (last), 87.00 (average), 87.00 (best)\n",
      "Proportion weighting accuracy: 87.00 (last), 87.00 (average), 87.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[8.1930e+03, 0.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [13  7]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [13  7]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 4.875200510025024\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 0.00 (last), 0.00 (average), 0.00 (best)\n",
      "Proportion weighting accuracy: 0.00 (last), 0.00 (average), 0.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "rates: tensor([[8.1930e+03, 0.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [4.895769357681274]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "Training complete for index: 7\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.7881035804748535\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.570969581604004\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 11.361888885498047\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 15.235348224639893\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 19.029306173324585\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.825838327407837\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 26.522634029388428\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 30.27354121208191\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 34.03840136528015\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 37.76585364341736\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 41.46206760406494\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 45.178706407547\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 48.916388750076294\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 52.695040225982666\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 56.44524025917053\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 60.171241998672485\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 63.91501808166504\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 67.73070454597473\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 71.45916223526001\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 75.19178652763367\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 78.97556972503662\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 82.70390915870667\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 86.5181474685669\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 90.31797409057617\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 94.07203555107117\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 97.84021615982056\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 101.63247561454773\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 105.32595920562744\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 109.02323198318481\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 112.70942330360413\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 116.40240359306335\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 120.08912301063538\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 123.76574945449829\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 127.46018505096436\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 131.1495168209076\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 134.8670506477356\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 138.52757024765015\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 142.2095663547516\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 145.83993792533875\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 149.46697115898132\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 153.1218762397766\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 156.7797200679779\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 160.4511604309082\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 164.2338936328888\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 167.93668603897095\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 171.72270917892456\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 175.4933741092682\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 179.2059669494629\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 182.88832831382751\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 186.53099989891052\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 190.10861587524414\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 193.825843334198\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 198.16184973716736\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 203.31845569610596\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 208.50721335411072\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 213.74812030792236\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 218.96633434295654\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 224.1511573791504\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 229.32760190963745\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 234.47789192199707\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 238.9211926460266\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 242.6993372440338\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 246.46328711509705\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 250.15682744979858\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 253.8903443813324\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 257.6191830635071\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 261.41214871406555\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 265.1404116153717\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 268.8588287830353\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 272.5862863063812\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 276.3517711162567\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 280.10961961746216\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 283.89127254486084\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 287.60220646858215\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 291.31281781196594\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 295.04586267471313\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 298.8152811527252\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 302.55708146095276\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 306.40505599975586\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 310.184485912323\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 313.9522120952606\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 317.70596051216125\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 321.4755012989044\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 325.2430999279022\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 329.03482937812805\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 332.7809431552887\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 336.46838665008545\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 340.13340616226196\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 343.76168489456177\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 347.4818913936615\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 351.1248757839203\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 354.7565507888794\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 358.39847707748413\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 362.04773592948914\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 365.65684700012207\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 369.33652114868164\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 372.9586498737335\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 376.56975173950195\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 380.17930483818054\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 383.6665005683899\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05827b8>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 1., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[8.1930e+03, 1.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [1.0000e+00, 4.0960e+03],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 4.772399425506592\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05829e8>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[8.1930e+03, 1.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [1.0000e+00, 4.0960e+03],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [4.80033278465271]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "Training complete for index: 8\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.7990684509277344\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.543055295944214\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 11.398852586746216\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 15.147134065628052\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 18.820887088775635\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.59165644645691\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 26.406389951705933\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 30.20308518409729\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 33.997042417526245\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 37.817835330963135\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 41.60221195220947\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 45.46197462081909\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 49.211883544921875\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 52.96977996826172\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 56.73698830604553\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 60.48170495033264\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 64.16342306137085\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 67.95419430732727\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 71.68617510795593\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 75.40469026565552\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 79.11834859848022\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 82.85905814170837\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 86.59211349487305\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 90.34013867378235\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 94.01169538497925\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 97.66016912460327\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 101.28328895568848\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 104.99636387825012\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 108.61095714569092\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 112.28377747535706\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 115.94044947624207\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 119.69924712181091\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 123.39798521995544\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 127.17230725288391\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 130.86317110061646\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 134.58199548721313\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 138.2778024673462\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 142.03470420837402\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 145.7838099002838\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 149.47747468948364\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 153.17447328567505\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 156.76082134246826\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 160.41289949417114\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 164.0171251296997\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 167.71891832351685\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 171.40395879745483\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 175.08756923675537\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 178.72215461730957\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 182.3778784275055\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 186.08330726623535\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 189.75909113883972\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 193.3613588809967\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 196.9951102733612\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 200.61012864112854\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 204.23600125312805\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 207.80368304252625\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 211.41125059127808\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 215.09757232666016\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 218.86127519607544\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 222.5700764656067\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 226.3008258342743\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 230.0340600013733\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 233.76907324790955\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 237.55582475662231\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 241.3068516254425\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 245.09636688232422\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 248.9115641117096\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 252.72314858436584\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 256.49964690208435\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 260.3274734020233\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 264.12064838409424\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 267.91961455345154\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 271.599977016449\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 275.29166173934937\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 279.0037124156952\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 282.7856619358063\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 286.4737915992737\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 290.1339945793152\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 293.8263909816742\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 297.435494184494\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 301.06368470191956\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 304.7184019088745\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 308.38900232315063\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 312.78202652931213\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 317.89558148384094\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 323.0854318141937\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 328.23569083213806\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 333.4287314414978\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 338.5722017288208\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 343.7022223472595\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 347.42081332206726\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 351.11011695861816\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 354.8830523490906\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 358.5461573600769\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 362.278582572937\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 366.01144886016846\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 369.75082325935364\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 373.476021528244\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 377.31084752082825\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 381.055890083313\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203dc50>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[1.2289e+04, 1.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [2.0000e+00, 4.0960e+03],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 5.228846788406372\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057ba8>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[1.2289e+04, 1.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [2.0000e+00, 4.0960e+03],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [5.2538557052612305]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "Training complete for index: 9\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.5978243350982666\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.190154075622559\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 10.906752347946167\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 14.697516441345215\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 18.398568630218506\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.059045791625977\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 25.65841245651245\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 29.265242099761963\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 32.80408263206482\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 36.46685862541199\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 40.6360387802124\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 44.23948860168457\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 47.83393383026123\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 51.368802309036255\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 55.18452978134155\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 58.840564250946045\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 62.485825300216675\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 66.24606513977051\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 70.93130373954773\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 75.57053518295288\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 79.2716634273529\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 82.87629103660583\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 86.52865362167358\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 90.16934370994568\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 93.92826008796692\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 97.69585275650024\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 101.5362012386322\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 105.38796639442444\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 109.16966271400452\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 112.86061000823975\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 116.96482253074646\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 120.68482089042664\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 124.47950768470764\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 128.28361582756042\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 132.03131914138794\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 135.79588150978088\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 139.60948514938354\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 143.37494373321533\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 147.1654760837555\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 150.9240460395813\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 154.63113951683044\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 158.3375301361084\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 162.07486534118652\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 165.90298748016357\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 169.62062406539917\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 173.3010609149933\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 176.9574854373932\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 180.60409688949585\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 184.2730896472931\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 188.03172659873962\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 191.7413408756256\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 195.4582028388977\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 199.179368019104\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 202.85336303710938\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 206.54869985580444\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 210.33828902244568\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 214.06174182891846\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 217.7299246788025\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 221.40374398231506\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 225.10362672805786\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 228.78934931755066\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 232.52417731285095\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 236.14407300949097\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 239.72560286521912\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 243.30247449874878\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 246.9037435054779\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 250.48870420455933\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 254.129469871521\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 257.71908497810364\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 261.3130531311035\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 264.8817210197449\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 268.4621021747589\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 272.11787939071655\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 275.7181942462921\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 279.33115315437317\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 282.92205810546875\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 286.5278341770172\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 290.1041555404663\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 293.77108097076416\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 297.37727522850037\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 300.95613527297974\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 304.5554413795471\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 308.2219789028168\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 311.8386833667755\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 315.62508749961853\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 319.36280727386475\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 323.1075973510742\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 326.8066713809967\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 330.5262005329132\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 334.2850248813629\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 338.0103409290314\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 341.6451873779297\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 345.31730461120605\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 348.9655556678772\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 352.5409052371979\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 356.1771123409271\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 360.3330729007721\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 364.02884125709534\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 367.7132694721222\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 371.34595584869385\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[1.6385e+04, 1.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [2.0000e+00, 4.0960e+03],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 4.784897327423096\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057438>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[1.6385e+04, 1.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [2.0000e+00, 4.0960e+03],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [4.812408685684204]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "Training complete for index: 10\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.8045501708984375\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.473849534988403\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 11.123414039611816\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 14.8260018825531\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 18.539063930511475\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.26721715927124\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 26.048760652542114\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 29.79337215423584\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 33.471858501434326\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 37.500903606414795\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 42.591745138168335\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 47.71484923362732\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 52.86128830909729\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 57.879435777664185\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 62.86507320404053\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 67.72120904922485\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 71.28066778182983\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 74.83495807647705\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 78.34417533874512\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 81.81141948699951\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 85.31844973564148\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 89.51745462417603\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 94.43420338630676\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 99.3721923828125\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 103.0192620754242\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 106.61453437805176\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 110.23869323730469\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 113.91967582702637\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 117.63067746162415\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 121.397545337677\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 125.08114361763\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 128.78017282485962\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 132.5621418952942\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 136.30028748512268\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 140.0552749633789\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 144.91807889938354\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 150.11426830291748\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 155.19378113746643\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 160.2429826259613\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 165.31967854499817\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 170.37633323669434\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 175.49352145195007\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 179.39714288711548\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 182.93155717849731\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 186.44403767585754\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 190.040589094162\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 193.71936917304993\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 197.3220112323761\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 200.9164798259735\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 204.47881364822388\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 207.98903393745422\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 211.65523099899292\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 215.36862182617188\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 219.0211160182953\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 222.7211410999298\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 226.36268043518066\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 229.90032362937927\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 233.42602038383484\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 237.03637862205505\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 240.5622341632843\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 244.0615749359131\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 247.60864329338074\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 251.13160729408264\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 254.6669054031372\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 258.24332666397095\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 262.135550737381\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 266.94678497314453\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 271.8371524810791\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 276.74698400497437\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 281.7308540344238\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 286.78204679489136\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 291.57275390625\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 295.21781635284424\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 298.8277497291565\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 302.4297397136688\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 305.9787383079529\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 309.474814414978\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 312.9529423713684\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 316.44404125213623\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 319.9564571380615\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 323.47188234329224\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 327.1186647415161\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 330.83824825286865\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 334.4790496826172\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 338.12467789649963\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 341.77708411216736\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 345.4072208404541\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 349.1218316555023\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 352.75490403175354\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 356.3907332420349\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 360.0449516773224\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 363.67881059646606\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 367.33270835876465\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 370.95763659477234\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 374.44912123680115\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 377.98652696609497\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 382.7679007053375\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 387.7507174015045\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 392.6641917228699\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 396.2803113460541\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[1.6386e+04, 1.0000e+00],\n",
      "        [1.6384e+04, 1.0000e+00],\n",
      "        [2.0000e+00, 4.0960e+03],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 4.884588241577148\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f4e0>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[1.6386e+04, 1.0000e+00],\n",
      "        [1.6384e+04, 1.0000e+00],\n",
      "        [2.0000e+00, 4.0960e+03],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [4.909786939620972]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "Training complete for index: 11\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.6594622135162354\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.500588417053223\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 11.201324701309204\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 15.007289171218872\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 18.69615340232849\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.33527684211731\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 25.93932580947876\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 29.577759265899658\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 33.22045302391052\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 36.969953298568726\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 40.67628049850464\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 44.46267557144165\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 48.183409690856934\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 51.88116931915283\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 55.52346324920654\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 59.299739837646484\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 63.02988243103027\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 66.75733351707458\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 70.50579524040222\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 74.14321660995483\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 77.81515407562256\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 81.54165315628052\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 85.25663948059082\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 88.94491457939148\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 92.72031593322754\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 96.44786238670349\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 100.28128552436829\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 104.0149974822998\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 107.69439625740051\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 111.43082237243652\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 115.08403873443604\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 118.72919750213623\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 122.42061352729797\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 126.05623817443848\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 129.70405316352844\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 133.3401792049408\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 136.9463827610016\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 140.5459544658661\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 144.20548391342163\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 147.8201184272766\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 151.42058753967285\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 155.03566098213196\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 158.73995685577393\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 162.39506673812866\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 166.05125093460083\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 169.79074549674988\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 173.44956302642822\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 177.153892993927\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 180.86050009727478\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 184.68032026290894\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 188.39897537231445\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 192.02194333076477\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 195.66014885902405\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 199.28845524787903\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 202.9079933166504\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 206.6434211730957\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 210.36663222312927\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 214.65926671028137\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 219.5655233860016\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 223.74985933303833\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 227.2943012714386\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 230.92317652702332\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 234.50789880752563\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 238.12904500961304\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 241.7760934829712\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 245.433691740036\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 249.08542585372925\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 252.74974298477173\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 257.1479420661926\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 262.0419626235962\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 266.97657775878906\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 271.8992054462433\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 276.7766993045807\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 281.7180347442627\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 286.59012055397034\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 291.4583795070648\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 296.3274772167206\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 301.2312853336334\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 306.12997603416443\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 309.69049310684204\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 313.1521408557892\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 316.5984899997711\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 320.09685802459717\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 323.59267497062683\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 327.86018919944763\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 332.8144829273224\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 337.8293685913086\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 342.834335565567\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 347.7567493915558\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 352.6213798522949\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 357.6321337223053\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 362.58837127685547\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 367.52416348457336\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 372.47249007225037\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 377.3722822666168\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 382.2803256511688\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 387.2614755630493\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 392.1616897583008\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 397.0770754814148\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 401.9687693119049\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c6f847518>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[2.0482e+04, 1.0000e+00],\n",
      "        [1.6385e+04, 1.0000e+00],\n",
      "        [2.0000e+00, 4.0960e+03],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 4.939869165420532\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2358>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "rates: tensor([[2.0482e+04, 1.0000e+00],\n",
      "        [1.6385e+04, 1.0000e+00],\n",
      "        [2.0000e+00, 4.0960e+03],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [4.964598655700684]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "Training complete for index: 12\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.6841232776641846\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.303577184677124\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 11.002214193344116\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 14.724431276321411\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 18.418009519577026\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.116344451904297\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 25.879106283187866\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 29.613600730895996\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 33.37575149536133\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 37.11776280403137\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 40.86108708381653\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 44.62158823013306\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 48.41904139518738\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 52.166029930114746\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 55.941558837890625\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 59.67497229576111\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 63.458327770233154\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 67.24287390708923\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 71.07711124420166\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 74.81687712669373\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 78.59577918052673\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 82.36998558044434\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 86.13991522789001\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 89.93393158912659\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 93.79497814178467\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 97.58360385894775\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 101.36336994171143\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 105.13842248916626\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 108.93601560592651\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 112.78110408782959\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 116.61419677734375\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 120.41947293281555\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 124.21600675582886\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 128.027095079422\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 132.6233570575714\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 137.6023006439209\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 141.26377248764038\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 144.87578058242798\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 148.45846438407898\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 152.02367734909058\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 155.82634925842285\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 159.6522126197815\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 163.37450194358826\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 167.07648348808289\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 170.75703048706055\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 174.36383366584778\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 177.9334363937378\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 181.59902930259705\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 185.18675351142883\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 188.83427906036377\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 192.4992973804474\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 196.13730359077454\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 199.76903200149536\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 203.4565463066101\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 207.09861207008362\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 210.75104999542236\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 214.40772891044617\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 218.03346824645996\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 221.73711347579956\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 225.37064623832703\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 229.01995754241943\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 232.73589253425598\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 236.43439030647278\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 240.13725399971008\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 243.9594178199768\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 247.74526596069336\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 251.55055284500122\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 255.3140881061554\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 259.11027455329895\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 262.84055733680725\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 266.6089265346527\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 270.29309129714966\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 273.98295402526855\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 277.65480637550354\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 281.34267592430115\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 285.02365589141846\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 288.76602125167847\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 292.424369096756\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 296.0760164260864\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 299.6791787147522\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 303.23053526878357\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 306.8127238750458\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 310.484384059906\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 314.14315938949585\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 317.78698229789734\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 321.4536409378052\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 325.1167240142822\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 328.87052631378174\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 332.6140959262848\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 336.3598461151123\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 340.19525361061096\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 343.90743231773376\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 347.6857807636261\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 351.5182514190674\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 355.3009707927704\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 359.01495265960693\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 362.71343779563904\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 366.41785621643066\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 370.1130950450897\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 373.77814078330994\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057f978>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[2.0482e+04, 2.0000e+00],\n",
      "        [1.6385e+04, 1.0000e+00],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 4.918464422225952\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203df60>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[2.0482e+04, 2.0000e+00],\n",
      "        [1.6385e+04, 1.0000e+00],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [4.940676927566528]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "Training complete for index: 13\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.717391014099121\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.4676353931427\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 11.163530349731445\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 14.939015865325928\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 18.899540662765503\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.801444053649902\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 26.659331560134888\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 30.519402265548706\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 34.38957643508911\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 38.31187176704407\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 42.09918761253357\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 45.82927060127258\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 49.505422830581665\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 53.131763219833374\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 56.787468671798706\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 60.47961068153381\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 64.08184123039246\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 67.69077157974243\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 71.31078910827637\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 74.93162107467651\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 78.57712173461914\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 82.27636504173279\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 85.93224596977234\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 89.55736804008484\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 93.23320508003235\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 96.88855814933777\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 100.5094051361084\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 104.20315718650818\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 107.90283632278442\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 111.65799522399902\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 115.36951065063477\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 119.09518527984619\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 122.8921103477478\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 126.59765434265137\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 130.30612540245056\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 134.04283475875854\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 137.7385721206665\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 141.42661809921265\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 145.16933298110962\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 148.88061356544495\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 152.59612655639648\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 156.28157877922058\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 160.00811672210693\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 163.6947615146637\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 167.40145230293274\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 171.0696575641632\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 174.7318811416626\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 178.37885642051697\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 182.05240988731384\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 185.72219371795654\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 189.46049523353577\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 193.116849899292\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 196.77325296401978\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 200.43754863739014\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 204.0941138267517\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 207.73946595191956\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 211.37029790878296\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 214.9301815032959\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 218.52404618263245\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 222.1682906150818\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 225.7808494567871\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 229.51038932800293\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 233.21048426628113\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 237.26559376716614\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 240.95686793327332\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 244.65536403656006\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 248.31893110275269\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 251.9559473991394\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 255.5209264755249\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 259.12935614585876\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 262.7670953273773\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 266.37868189811707\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 269.98051834106445\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 274.16022992134094\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 278.1298682689667\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 281.79995608329773\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 285.47386860847473\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 289.078604221344\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 292.67908120155334\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 296.3151926994324\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 299.87845063209534\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 303.40677070617676\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 306.9831819534302\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 311.15844917297363\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 316.257132768631\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 321.3182315826416\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 326.34759736061096\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 331.3595325946808\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 336.3793020248413\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 341.24313282966614\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 345.10463976860046\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 348.8422095775604\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 352.5597114562988\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 357.01013827323914\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 361.915584564209\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 365.6391053199768\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 369.38011384010315\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 373.0530548095703\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 376.8085172176361\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 380.46385169029236\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d470>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[2.4578e+04, 2.0000e+00],\n",
      "        [1.6385e+04, 1.0000e+00],\n",
      "        [3.0000e+00, 8.1920e+03],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 4.671725273132324\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[2.4578e+04, 2.0000e+00],\n",
      "        [1.6385e+04, 1.0000e+00],\n",
      "        [3.0000e+00, 8.1920e+03],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [4.698374271392822]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "Training complete for index: 14\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_0.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 4.264594793319702\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.993661880493164\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 11.636431217193604\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 15.319554567337036\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 18.98277187347412\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.61408519744873\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 26.29314637184143\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 30.06909942626953\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 33.79927849769592\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 37.506375312805176\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 41.22959780693054\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 44.93596076965332\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 48.656397342681885\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 52.25959801673889\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 55.854024171829224\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 59.466094732284546\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 63.1195592880249\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 66.79764294624329\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 70.57763814926147\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 74.35091924667358\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 78.13581085205078\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 81.90249752998352\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 85.6974766254425\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 89.45169520378113\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 93.28501892089844\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 97.05264616012573\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 100.8520987033844\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 104.6395571231842\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 108.40882921218872\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 112.20220184326172\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 116.07302832603455\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 119.8681914806366\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 123.63121747970581\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 127.36377334594727\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 131.06632709503174\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 134.887060880661\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 139.7321491241455\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 144.7827227115631\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 149.74100756645203\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 154.7189028263092\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 159.69201469421387\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 164.72560214996338\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 169.7022979259491\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 173.58568620681763\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 177.17620658874512\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 180.8310844898224\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 184.3823206424713\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 187.95908188819885\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 191.51842260360718\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 195.05252027511597\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 198.60299730300903\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 202.16908073425293\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 205.76606154441833\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 209.4130048751831\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 212.98810577392578\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 216.55075669288635\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 220.14984560012817\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 223.72775626182556\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 227.24849772453308\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 230.82378339767456\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 234.30935144424438\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 237.78560423851013\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 241.279287815094\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 244.80438542366028\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 248.52111053466797\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 252.3593714237213\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 256.10378909111023\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 259.73399114608765\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 263.3945641517639\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 267.0466425418854\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 270.79252672195435\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 274.53206729888916\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 278.23998498916626\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 281.9280128479004\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 285.8634147644043\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 290.84512424468994\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 295.90655732154846\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 300.77563548088074\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 304.4165346622467\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 308.1148166656494\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 311.810706615448\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 315.4959526062012\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 319.20510721206665\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 322.85319805145264\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 326.47779607772827\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 330.0897035598755\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 333.70536041259766\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 337.32092094421387\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 340.9941415786743\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 344.60536789894104\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 348.20709681510925\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 351.8164451122284\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 355.4328029155731\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 359.10802149772644\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 362.729211807251\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 366.35904335975647\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 370.01382279396057\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 373.67647647857666\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 377.4073610305786\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 381.21282148361206\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0569160>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[2.4579e+04, 2.0000e+00],\n",
      "        [2.0481e+04, 1.0000e+00],\n",
      "        [3.0000e+00, 8.1920e+03],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "Begin training for fold 1\n",
      "\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "starting training (new network): \n",
      "NewNetwork: NewNetwork(\n",
      "  (X): Input()\n",
      "  (Ae): DiehlAndCookNodes()\n",
      "  (Ai): LIFNodes()\n",
      "  (X_to_Ae): Connection(\n",
      "    (source): Input()\n",
      "    (target): DiehlAndCookNodes()\n",
      "  )\n",
      "  (Ae_to_Ai): Connection(\n",
      "    (source): DiehlAndCookNodes()\n",
      "    (target): LIFNodes()\n",
      "  )\n",
      "  (Ai_to_Ae): Connection(\n",
      "    (source): LIFNodes()\n",
      "    (target): DiehlAndCookNodes()\n",
      "  )\n",
      ")\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 4.958292245864868\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057cc0>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [4.983176231384277]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "Training complete for index: 0\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.629852056503296\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.205446720123291\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 10.7928466796875\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 14.334741830825806\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 17.953296661376953\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 21.44553804397583\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 24.930463314056396\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 28.44649839401245\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 32.00109267234802\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 35.71929478645325\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 39.3207426071167\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 42.93600058555603\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 46.48317885398865\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 50.09224224090576\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 53.792174339294434\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 57.576231241226196\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 61.31669855117798\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 65.03401589393616\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 68.7398464679718\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 72.46530961990356\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 76.20374584197998\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 79.95952844619751\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 83.6574957370758\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 87.41633915901184\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 91.136559009552\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 94.8606424331665\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 98.59566879272461\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 102.40174078941345\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 106.56929302215576\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 110.59480285644531\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 114.24825620651245\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 117.92274236679077\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 121.57972884178162\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 125.34679746627808\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 129.02111434936523\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 132.70151448249817\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 136.37177228927612\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 140.03831887245178\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 143.76863646507263\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 147.4954216480255\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 151.1727488040924\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 154.87651586532593\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 158.6300961971283\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 162.38541102409363\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 166.20924043655396\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 170.0018756389618\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 173.7272698879242\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 177.80927515029907\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 181.48329877853394\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 185.08728575706482\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 188.76164865493774\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 192.3686327934265\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 196.0009696483612\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 199.63293552398682\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 203.3037166595459\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 206.95051765441895\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 210.65884566307068\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 214.32274460792542\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 217.94067883491516\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 221.62425231933594\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 225.30366396903992\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 228.9747564792633\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 232.81011319160461\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 236.54733800888062\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 240.29839158058167\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 244.04795169830322\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 247.8323233127594\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 251.64649748802185\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 255.36318945884705\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 259.10235691070557\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 262.8369827270508\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 266.5767867565155\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 270.3351194858551\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 274.1499698162079\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 277.9131450653076\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 281.62706184387207\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 285.3765206336975\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 289.16678380966187\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 292.93950366973877\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 296.75580763816833\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 300.5299687385559\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 304.30155897140503\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 308.07888984680176\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 311.8492658138275\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 315.6153914928436\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 319.44362139701843\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 323.19941234588623\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 326.91760540008545\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 330.6712017059326\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 334.40023016929626\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 338.1368815898895\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 341.9353036880493\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 345.6781759262085\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 349.4198453426361\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 353.1612045764923\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 356.9174294471741\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 360.7452073097229\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 364.48712944984436\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 368.25517416000366\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 372.01225209236145\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05693c8>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "labels: tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "\n",
      "All activity accuracy: 80.00 (last), 80.00 (average), 80.00 (best)\n",
      "Proportion weighting accuracy: 80.00 (last), 80.00 (average), 80.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [4.0960e+03, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [20  0]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [20  0]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 6.196500062942505\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf05690b8>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [4.0960e+03, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [6.219081163406372]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "Training complete for index: 1\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.6310973167419434\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.276240825653076\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 11.27188229560852\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 14.815211772918701\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 18.418519735336304\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.032562494277954\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 25.658480405807495\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 29.35520362854004\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 33.40971064567566\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 37.34201455116272\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 41.241907835006714\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 44.95648550987244\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 48.65883255004883\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 52.437335729599\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 56.19112825393677\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 59.90370321273804\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 63.55505013465881\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 67.4786479473114\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 71.1244044303894\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 74.6888120174408\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 78.26292276382446\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 81.8295521736145\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 85.40621590614319\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 88.98381972312927\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 92.61166882514954\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 96.19507765769958\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 99.77012300491333\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 103.34146070480347\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 106.89197278022766\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 110.53893494606018\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 114.1995792388916\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 117.84881210327148\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 121.43612027168274\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 125.00011682510376\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 128.53636717796326\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 132.06963324546814\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 135.694988489151\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 139.2453637123108\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 142.805508852005\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 146.3967158794403\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 149.9843294620514\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 153.57339477539062\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 157.21609926223755\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 160.78658723831177\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 164.37273502349854\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 168.0522906780243\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 171.7155568599701\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 175.47568440437317\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 179.1368227005005\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 182.77228498458862\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 186.42124772071838\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 190.0317578315735\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 193.68393206596375\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 197.41098880767822\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 201.06689596176147\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 204.70211267471313\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 208.38349986076355\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 212.08820748329163\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 215.8100085258484\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 219.60514497756958\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 223.3724341392517\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 226.96014428138733\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 230.5663607120514\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 234.2151894569397\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 237.84297943115234\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 241.55717253684998\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 245.19907665252686\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 248.8208429813385\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 252.43240785598755\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 256.0848581790924\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 259.7722179889679\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 263.43068051338196\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 267.04133701324463\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 270.6947386264801\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 274.3177695274353\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 277.86144733428955\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 281.4991054534912\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 285.11874532699585\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 288.7331657409668\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 292.3445174694061\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 295.9746515750885\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 299.5582902431488\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 303.2184524536133\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 306.8375539779663\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 310.45868611335754\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 314.1225824356079\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 317.7923357486725\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 321.47816371917725\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 325.28077816963196\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 329.0123562812805\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 332.7259690761566\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 336.41330456733704\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 340.14023208618164\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 344.6652009487152\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 349.4119498729706\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 353.2036147117615\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 358.23824977874756\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 363.37879061698914\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 368.5037889480591\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 373.7023208141327\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf2057860>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "labels: tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "\n",
      "All activity accuracy: 80.00 (last), 80.00 (average), 80.00 (best)\n",
      "Proportion weighting accuracy: 80.00 (last), 80.00 (average), 80.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [8.1920e+03, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [20  0]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [20  0]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 4.774491548538208\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c903e9320>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [8.1920e+03, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [4.7989501953125]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "Training complete for index: 2\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.6644091606140137\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.343037843704224\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 11.013522148132324\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 14.678221940994263\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 18.42699956893921\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.101741552352905\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 25.841266632080078\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 29.52267026901245\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 33.12534999847412\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 37.755351066589355\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 42.79636287689209\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 47.72387957572937\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 52.60798382759094\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 57.52971172332764\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 62.463085412979126\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 67.46514701843262\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 71.36009645462036\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 74.88128566741943\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 78.42141699790955\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 82.69638657569885\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 86.43611431121826\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 90.16867208480835\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 93.8171923160553\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 97.48706793785095\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 101.14638423919678\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 104.81886410713196\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 108.5024926662445\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 112.25059795379639\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 115.91107869148254\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 119.58918070793152\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 123.28566884994507\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 126.98761034011841\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 130.62761425971985\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 134.38419032096863\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 138.0409641265869\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 141.70554375648499\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 145.43456768989563\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 149.15903639793396\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 152.85233545303345\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 156.51743054389954\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 160.12695574760437\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 163.71930265426636\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 167.29631328582764\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 170.89393210411072\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 174.49123096466064\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 178.21359491348267\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 181.86156105995178\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 185.5502233505249\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 189.22732710838318\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 192.96864819526672\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 196.61317324638367\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 200.16091799736023\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 203.70901942253113\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 207.26133251190186\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 210.7946901321411\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 214.3260486125946\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 217.9442915916443\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 221.4722204208374\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 225.06092739105225\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 228.75537252426147\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 232.37525510787964\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 236.0214171409607\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 239.72691440582275\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 243.38442397117615\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 247.00490069389343\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 250.61088871955872\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 254.27184915542603\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 257.95592188835144\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 261.70099449157715\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 265.4234890937805\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 269.297776222229\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 273.02443075180054\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 276.8059914112091\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 280.5050609111786\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 284.30313301086426\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 287.96172976493835\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 291.59583497047424\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 295.2209851741791\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 298.7959015369415\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 302.5937807559967\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 306.2650423049927\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 309.9224660396576\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 313.5714645385742\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 317.20545625686646\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 320.8182637691498\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 324.47623014450073\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 328.0629587173462\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 331.6741898059845\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 335.3035910129547\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 338.9377474784851\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 342.61473298072815\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 346.3546357154846\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 350.01624846458435\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 353.71435356140137\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 357.4211337566376\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 361.1164870262146\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 364.7999963760376\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 368.6969075202942\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 372.436461687088\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 376.20266699790955\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d2b0>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "labels: tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "\n",
      "All activity accuracy: 80.00 (last), 80.00 (average), 80.00 (best)\n",
      "Proportion weighting accuracy: 80.00 (last), 80.00 (average), 80.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.2288e+04, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [20  0]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [20  0]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 4.924862861633301\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2518>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 0.00 (last), 0.00 (average), 0.00 (best)\n",
      "Proportion weighting accuracy: 0.00 (last), 0.00 (average), 0.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.2288e+04, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [4.948291301727295]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "Training complete for index: 3\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.3973681926727295\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.009095191955566\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 10.510589122772217\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 13.99651837348938\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 17.54141354560852\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 21.83250665664673\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 25.510805368423462\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 29.219656467437744\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 32.84156084060669\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 36.46688890457153\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 40.100106716156006\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 43.84426212310791\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 47.490355253219604\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 51.58277988433838\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 56.70471382141113\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 60.45399785041809\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 64.13158106803894\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 67.82648801803589\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 71.46424508094788\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 75.15126252174377\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 78.77477622032166\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 82.36962485313416\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 86.4000723361969\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 90.06429505348206\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 93.66711401939392\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 97.34358263015747\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 100.94436883926392\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 104.5781078338623\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 108.22378468513489\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 112.4706962108612\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 117.50268316268921\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 122.48657584190369\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 127.445631980896\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 132.42453002929688\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 136.10979866981506\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 139.77594780921936\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 143.47882986068726\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 147.1022756099701\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 150.72577381134033\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 154.3070409297943\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 157.90501308441162\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 161.4694321155548\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 165.02527356147766\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 168.49063563346863\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 172.00420951843262\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 175.51204466819763\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 179.12465524673462\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 182.7921497821808\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 186.54363799095154\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 190.8749372959137\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 196.00235152244568\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 201.12539434432983\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 206.27337217330933\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 211.52658534049988\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 216.66151642799377\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 221.69080519676208\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 225.4883804321289\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 229.24304509162903\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 232.88833022117615\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 236.52740502357483\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 240.07770991325378\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 244.51648592948914\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 249.44041967391968\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 254.40020155906677\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 259.3987624645233\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 264.4180507659912\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 269.4139482975006\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 274.41644263267517\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 279.4479591846466\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 283.6836061477661\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 287.4519250392914\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 291.22520089149475\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 294.8628671169281\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 298.48624992370605\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 302.12334871292114\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 305.70965099334717\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 309.2813687324524\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 312.9847605228424\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 316.6429796218872\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 320.2863087654114\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 323.90733003616333\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 327.55466866493225\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 331.2588746547699\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 334.90254974365234\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 338.5385138988495\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 342.2158281803131\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 345.9005215167999\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 349.5186834335327\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 353.1899392604828\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 356.6846399307251\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 360.1821360588074\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 363.80457520484924\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 367.47177052497864\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 371.15179204940796\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 374.9001684188843\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 378.5865693092346\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 382.26705145835876\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 385.9856507778168\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 389.6853995323181\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 393.36378240585327\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d128>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "labels: tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "\n",
      "All activity accuracy: 89.00 (last), 89.00 (average), 89.00 (best)\n",
      "Proportion weighting accuracy: 89.00 (last), 89.00 (average), 89.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 1., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 1., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [1.0000e+00, 4.0960e+03],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [11  9]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [11  9]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 4.836103677749634\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bfcb50a58>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [1.0000e+00, 4.0960e+03],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [4.857656717300415]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "Training complete for index: 4\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.6708765029907227\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.41233491897583\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 11.197659254074097\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 14.843159675598145\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 18.498254776000977\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.091603755950928\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 25.730541467666626\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 29.378406524658203\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 33.01974868774414\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 36.62806963920593\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 40.27855134010315\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 43.89085364341736\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 47.471351861953735\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 51.079517126083374\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 54.70026659965515\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 58.30985116958618\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 61.96662449836731\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 65.57657480239868\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 69.1783332824707\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 72.79640054702759\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 76.4930374622345\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 80.27188992500305\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 84.05887079238892\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 87.78921246528625\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 91.52971506118774\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 95.26723837852478\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 98.98942017555237\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 102.7333779335022\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 106.51917243003845\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 110.2303147315979\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 113.92790484428406\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 117.67363238334656\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 121.38292646408081\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 125.1515281200409\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 128.86722254753113\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 132.62049317359924\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 136.37221336364746\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 140.09599113464355\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 143.85231971740723\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 147.63249230384827\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 151.36802124977112\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 155.08382391929626\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 158.83066320419312\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 162.55702471733093\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 166.2813482284546\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 170.0725028514862\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 173.8208405971527\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 177.57063603401184\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 181.3356990814209\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 185.0745086669922\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 188.83990001678467\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 192.6673083305359\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 196.32791113853455\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 200.00026297569275\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 203.67730498313904\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 207.35239124298096\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 211.0976710319519\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 214.78536200523376\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 218.40621733665466\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 222.0712730884552\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 225.72335362434387\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 229.36341428756714\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 233.07152915000916\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 237.30341911315918\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 242.06948590278625\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 245.74101400375366\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 249.37313842773438\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 252.9591703414917\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 256.6330955028534\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 260.20348501205444\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 263.7798082828522\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 267.3333418369293\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 270.8867871761322\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 274.41539669036865\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 278.0268819332123\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 281.58459734916687\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 285.15991854667664\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 288.7677221298218\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 292.3466057777405\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 295.93481492996216\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 299.58128213882446\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 303.17428255081177\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 306.79687547683716\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 310.3865478038788\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 314.014098405838\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 317.6842157840729\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 321.3078122138977\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 324.90869402885437\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 328.5632584095001\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 332.1800456047058\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 336.2030875682831\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 341.2675111293793\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 346.2880916595459\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 351.31359601020813\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 356.3463935852051\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 361.3986039161682\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 366.45341205596924\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 371.1209120750427\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 375.37541460990906\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 380.44678926467896\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "labels: tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "\n",
      "All activity accuracy: 87.00 (last), 87.00 (average), 87.00 (best)\n",
      "Proportion weighting accuracy: 87.00 (last), 87.00 (average), 87.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 1., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [1.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [13  7]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [13  7]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 4.966922760009766\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582358>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [1.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [4.990661382675171]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "Training complete for index: 5\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.793989658355713\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.575764179229736\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 11.417711734771729\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 15.19770622253418\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 18.974737644195557\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.730348348617554\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 26.50148892402649\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 30.297518968582153\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 34.00553870201111\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 37.73062467575073\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 41.428874254226685\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 45.172497510910034\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 48.869706869125366\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 52.6379668712616\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 56.36353373527527\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 60.11131954193115\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 63.76526355743408\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 67.42922186851501\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 71.06365323066711\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 74.74851703643799\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 78.37566208839417\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 82.0999321937561\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 85.71091604232788\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 89.35487961769104\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 93.05442404747009\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 96.8225245475769\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 100.54539132118225\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 104.25551533699036\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 107.99567770957947\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 111.7308623790741\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 115.47474694252014\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 119.24362397193909\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 122.92544174194336\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 126.618483543396\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 130.3740177154541\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 134.15914106369019\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 138.02098536491394\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 141.74553728103638\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 145.52264785766602\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 149.16228556632996\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 152.91885948181152\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 156.67902827262878\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 160.41233444213867\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 164.01256394386292\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 167.7362232208252\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 171.4706733226776\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 175.18136143684387\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 178.90116572380066\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 182.67374873161316\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 186.39614510536194\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 190.11510467529297\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 193.7922339439392\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 197.50780868530273\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 201.2291703224182\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 205.00662875175476\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 208.62388253211975\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 212.25026416778564\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 215.86854696273804\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 219.45177125930786\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 223.1404321193695\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 226.76571536064148\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 230.39202046394348\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 234.02115154266357\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 237.63543272018433\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 241.25956320762634\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 244.98536205291748\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 248.6779990196228\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 252.35696387290955\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 256.0469899177551\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 259.7273938655853\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 263.34938311576843\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 267.0441052913666\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 270.6537163257599\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 274.2919087409973\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 277.86145067214966\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 281.4063594341278\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 284.9658715724945\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 288.7017261981964\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 292.3996629714966\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 296.06298780441284\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 299.80800318717957\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 303.52193546295166\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 307.25044322013855\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 311.05458521842957\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 314.8693289756775\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 318.5982286930084\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 322.3562364578247\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 325.95652437210083\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 329.62837529182434\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 333.2734935283661\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 336.885840177536\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 340.5047414302826\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 344.252769947052\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 348.012179851532\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 351.71234488487244\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 355.36434984207153\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 359.06398606300354\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 362.871839761734\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 366.69420552253723\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 370.49131965637207\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d438>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "labels: tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "\n",
      "All activity accuracy: 88.00 (last), 88.00 (average), 88.00 (best)\n",
      "Proportion weighting accuracy: 88.00 (last), 88.00 (average), 88.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [1., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[4.0970e+03, 0.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [12  8]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [12  8]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 5.349783420562744\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d278>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[4.0970e+03, 0.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [5.373326539993286]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "Training complete for index: 6\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.741886854171753\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.562444686889648\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 11.355400562286377\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 15.10558009147644\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 18.901102542877197\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.76544499397278\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 26.494218826293945\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 30.243988275527954\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 34.02465057373047\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 37.789255142211914\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 41.637163162231445\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 45.36578941345215\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 49.02204608917236\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 52.55107092857361\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 56.153733253479004\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 59.87880897521973\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 63.6771399974823\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 67.38619470596313\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 71.13573265075684\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 74.68830060958862\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 78.33782982826233\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 82.02015280723572\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 86.95768928527832\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 91.69023132324219\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 95.2868664264679\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 98.9162027835846\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 102.54326677322388\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 106.17143106460571\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 109.86744499206543\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 113.48914003372192\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 117.11276531219482\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 120.73354077339172\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 124.33152556419373\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 127.96113276481628\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 131.65711498260498\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 135.28534722328186\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 138.90795969963074\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 142.51234078407288\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 146.08297395706177\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 149.70650219917297\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 153.28933262825012\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 156.88466882705688\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 160.4665822982788\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 164.08563375473022\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 167.66982769966125\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 171.457177400589\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 175.16795921325684\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 178.84033703804016\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 182.89225697517395\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 186.50889706611633\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 190.24445700645447\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 194.0732765197754\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 197.9015064239502\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 201.64892411231995\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 205.38021659851074\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 209.16248083114624\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 212.94786882400513\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 216.69268798828125\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 220.41063380241394\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 224.15232348442078\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 227.8695137500763\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 231.53292107582092\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 235.21295523643494\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 238.87972903251648\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 242.59389233589172\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 246.29051089286804\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 249.9892978668213\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 253.6894965171814\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 257.4324586391449\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 261.1594591140747\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 264.86742520332336\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 268.51263427734375\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 272.21945118904114\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 275.8398699760437\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 279.5691428184509\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 283.2233974933624\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 286.93881464004517\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 290.61435890197754\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 294.2919702529907\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 298.0320439338684\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 301.857950925827\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 305.6188943386078\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 309.4105706214905\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 313.2223470211029\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 317.02068972587585\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 320.7725074291229\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 324.60178303718567\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 328.3577015399933\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 332.08530855178833\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 335.82687187194824\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 339.4899432659149\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 343.1878252029419\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 346.87838983535767\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 350.5544195175171\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 354.25320315361023\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 357.96584248542786\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 361.6512837409973\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 365.3541941642761\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 368.9958984851837\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 372.73175072669983\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2208>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "labels: tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "\n",
      "All activity accuracy: 90.00 (last), 90.00 (average), 90.00 (best)\n",
      "Proportion weighting accuracy: 90.00 (last), 90.00 (average), 90.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[4.0980e+03, 0.0000e+00],\n",
      "        [1.6384e+04, 1.0000e+00],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [10 10]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [10 10]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [1]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 4.884694576263428\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d0f0>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 0.00 (last), 0.00 (average), 0.00 (best)\n",
      "Proportion weighting accuracy: 0.00 (last), 0.00 (average), 0.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[4.0980e+03, 0.0000e+00],\n",
      "        [1.6384e+04, 1.0000e+00],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [4.907188653945923]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "Training complete for index: 7\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.7794241905212402\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.539286136627197\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 11.274493932723999\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 15.020190238952637\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 18.83498477935791\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.65759778022766\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 26.438394784927368\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 30.249027729034424\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 34.13787770271301\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 37.97988772392273\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 41.71819877624512\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 45.46983003616333\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 49.182780504226685\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 52.91045904159546\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 56.5757794380188\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 60.25291132926941\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 63.961222887039185\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 67.7128689289093\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 71.42581605911255\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 75.16470551490784\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 78.83136034011841\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 82.49981832504272\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 86.1688506603241\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 89.84134554862976\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 93.48446488380432\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 97.1873037815094\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 100.81616115570068\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 104.45791220664978\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 108.10511112213135\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 111.80203294754028\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 115.52196002006531\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 119.31497478485107\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 123.01033282279968\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 126.81220078468323\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 130.65025734901428\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 134.3883285522461\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 138.09897923469543\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 141.89311981201172\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 145.68588995933533\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 149.45933938026428\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 153.23155999183655\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 156.97556591033936\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 160.8152129650116\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 164.62718963623047\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 168.37860369682312\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 172.1605188846588\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 175.90752792358398\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 179.62553191184998\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 183.46013045310974\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 187.27464938163757\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 191.05191588401794\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 194.72637128829956\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 198.31614565849304\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 201.86297869682312\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 205.42614912986755\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 209.0908818244934\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 212.76079630851746\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 216.45390820503235\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 220.09366083145142\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 223.76954436302185\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 227.51207947731018\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 231.19183111190796\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 234.85758781433105\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 238.54866862297058\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 242.25728368759155\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 245.8494589328766\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 249.55644941329956\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 253.16069388389587\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 256.9676148891449\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 260.68499755859375\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 264.3516757488251\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 268.1536509990692\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 271.86015939712524\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 275.62364530563354\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 279.3266634941101\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 282.95490431785583\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 286.60404682159424\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 290.31450033187866\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 294.02153182029724\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 297.6989698410034\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 301.36393880844116\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 305.0627884864807\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 308.8246886730194\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 312.6451270580292\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 316.40253019332886\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 320.0677320957184\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 323.7008788585663\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 327.2833881378174\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 330.88728046417236\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 334.53159379959106\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 338.13856291770935\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 341.6948845386505\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 345.3612413406372\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 349.0980644226074\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 352.8905839920044\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 356.62907814979553\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 360.36416268348694\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 364.0890588760376\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 367.88304924964905\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 371.63605093955994\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203d048>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "labels: tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 1., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 1., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[4.0980e+03, 0.0000e+00],\n",
      "        [1.6384e+04, 2.0000e+00],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 4.0960e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 5.009388446807861\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2518>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[4.0980e+03, 0.0000e+00],\n",
      "        [1.6384e+04, 2.0000e+00],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 4.0960e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [5.031744956970215]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "Training complete for index: 8\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.588435411453247\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.259258270263672\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 11.162117958068848\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 15.004584312438965\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 18.87609839439392\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.7767391204834\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 26.625459671020508\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 30.485252857208252\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 34.3392071723938\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 38.21412706375122\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 42.093300104141235\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 45.98264193534851\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 49.8129358291626\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 53.60191869735718\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 57.40397572517395\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 61.194706201553345\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 64.97134757041931\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 68.66996192932129\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 72.36325097084045\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 76.03403663635254\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 79.72276425361633\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 83.40931749343872\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 87.21514630317688\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 90.93034505844116\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 94.64975619316101\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 98.34536910057068\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 102.037606716156\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 105.7292013168335\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 109.46943020820618\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 113.16202092170715\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 116.87702655792236\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 120.5748553276062\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 124.26350545883179\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 127.95620012283325\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 131.71341395378113\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 135.41411113739014\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 139.10066556930542\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 142.81534004211426\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 146.58998942375183\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 150.39557433128357\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 154.19741821289062\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 157.9200246334076\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 161.63998198509216\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 165.31792211532593\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 169.0367796421051\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 172.77235078811646\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 176.44171667099\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 180.17752623558044\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 183.91540336608887\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 187.78978562355042\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 191.63289141654968\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 195.39929485321045\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 199.05962443351746\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 202.6935579776764\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 206.39830040931702\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 210.2078514099121\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 214.02616381645203\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 217.7916157245636\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 221.51600289344788\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 225.22975134849548\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 228.98651576042175\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 232.72148990631104\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 236.40643692016602\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 240.1214084625244\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 243.80868124961853\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 247.515531539917\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 251.25319051742554\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 254.9978964328766\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 258.7184205055237\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 262.4781391620636\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 266.166198015213\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 269.8874936103821\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 273.6432433128357\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 277.3770604133606\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 281.1746335029602\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 284.97274470329285\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 288.71499586105347\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 292.46531987190247\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 296.1911962032318\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 299.8585612773895\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 303.5671954154968\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 307.23828053474426\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 310.88696479797363\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 314.4892964363098\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 318.1928369998932\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 321.8129823207855\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 325.4407789707184\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 329.0461628437042\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 332.6672546863556\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 336.35069155693054\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 340.0125753879547\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 343.61892342567444\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 347.31025099754333\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 350.9707646369934\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 354.6254892349243\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 358.33891105651855\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 362.1644160747528\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 366.3178725242615\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 370.35758090019226\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 374.00966334342957\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf203da90>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "labels: tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[4.0980e+03, 0.0000e+00],\n",
      "        [2.0480e+04, 2.0000e+00],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [2.0000e+00, 4.0960e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 5.26152491569519\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf057fe48>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[4.0980e+03, 0.0000e+00],\n",
      "        [2.0480e+04, 2.0000e+00],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [2.0000e+00, 4.0960e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [5.287554025650024]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "Training complete for index: 9\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 4.256510019302368\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.961138010025024\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 11.74716305732727\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 15.4342942237854\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 19.58750319480896\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 24.701658964157104\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 29.15840244293213\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 32.96874475479126\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 36.80406355857849\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 40.46022367477417\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 44.1312198638916\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 47.77136206626892\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 51.28365182876587\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 54.89176058769226\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 58.571287631988525\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 62.16550946235657\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 65.76040077209473\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 69.3907082080841\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 73.02636861801147\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 76.66576719284058\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 80.39730882644653\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 84.01918625831604\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 87.66920280456543\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 91.31603932380676\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 94.854421377182\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 98.55370235443115\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 102.25572299957275\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 105.88438510894775\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 109.49428486824036\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 113.14481997489929\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 116.79421496391296\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 120.51868009567261\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 124.43951153755188\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 128.0980441570282\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 131.77080988883972\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 135.3954565525055\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 139.07896256446838\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 142.67322540283203\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 146.16691994667053\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 149.66907167434692\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 153.21901297569275\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 156.864319562912\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 160.44589495658875\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 165.0101659297943\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 168.67728972434998\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 172.30401825904846\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 175.91355776786804\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 179.51332306861877\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 183.19494891166687\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 186.85932302474976\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 190.57493710517883\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 194.27968835830688\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 197.96732878684998\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 201.66178488731384\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 205.48483228683472\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 209.26466751098633\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 213.092440366745\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 216.8156259059906\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 220.45353770256042\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 224.10098314285278\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 227.86434721946716\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 231.51286482810974\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 235.19256329536438\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 238.7802231311798\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 242.42207837104797\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 246.7250475883484\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 250.62367987632751\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 254.32621932029724\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 258.02440881729126\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 261.66655015945435\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 265.32918190956116\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 269.0560579299927\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 272.76100516319275\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 276.44273853302\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 280.0798420906067\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 283.6242718696594\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 287.45330119132996\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 292.416216135025\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 297.29767394065857\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 301.3232717514038\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 304.9862484931946\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 308.6332576274872\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 312.2612454891205\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 315.9374170303345\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 319.6045353412628\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 323.33525800704956\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 327.0788028240204\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 330.79777693748474\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 334.6498303413391\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 338.92691802978516\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 342.69842076301575\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 346.2519488334656\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 349.89832758903503\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 353.52801609039307\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 357.73058795928955\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 362.7748227119446\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 367.74273109436035\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 371.58767437934875\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 375.18967485427856\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 378.80595898628235\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "labels: tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[8.1940e+03, 0.0000e+00],\n",
      "        [2.0481e+04, 2.0000e+00],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [2.0000e+00, 4.0960e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 4.903956890106201\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582be0>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[8.1940e+03, 0.0000e+00],\n",
      "        [2.0481e+04, 2.0000e+00],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [2.0000e+00, 4.0960e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [4.93086051940918]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "Training complete for index: 10\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.644064426422119\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.236097574234009\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 10.802715301513672\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 14.895715236663818\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 18.560489654541016\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.239919662475586\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 25.82934308052063\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 29.46991467475891\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 33.10607123374939\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 36.72312784194946\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 40.3363938331604\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 43.98581910133362\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 47.597317934036255\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 51.263911962509155\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 54.95034193992615\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 58.60540699958801\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 62.27637052536011\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 65.96869277954102\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 69.62646269798279\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 73.28209066390991\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 76.87906575202942\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 80.47266268730164\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 84.13018941879272\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 87.92127728462219\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 91.61734914779663\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 95.3618438243866\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 99.10035252571106\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 102.84913611412048\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 106.56725096702576\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 110.18435502052307\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 113.84052515029907\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 117.51703262329102\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 121.1830689907074\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 124.8313250541687\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 128.5217845439911\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 132.16816234588623\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 135.8336946964264\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 139.50372982025146\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 143.1851978302002\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 146.96997141838074\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 150.77367639541626\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 154.42687845230103\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 158.57211923599243\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 163.63262510299683\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 168.65164852142334\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 173.61906838417053\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 178.70811820030212\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 182.84618496894836\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 186.592924118042\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 190.27799439430237\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 50\n",
      "update_interval: 100\n",
      "Test progress: (50 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 193.96631288528442\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 51\n",
      "update_interval: 100\n",
      "Test progress: (51 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 197.82139587402344\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 52\n",
      "update_interval: 100\n",
      "Test progress: (52 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 201.60086035728455\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 53\n",
      "update_interval: 100\n",
      "Test progress: (53 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 205.35584235191345\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 54\n",
      "update_interval: 100\n",
      "Test progress: (54 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 209.0724241733551\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 55\n",
      "update_interval: 100\n",
      "Test progress: (55 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 212.7896158695221\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 56\n",
      "update_interval: 100\n",
      "Test progress: (56 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 216.53816938400269\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 57\n",
      "update_interval: 100\n",
      "Test progress: (57 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 220.3784945011139\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 58\n",
      "update_interval: 100\n",
      "Test progress: (58 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 224.2551155090332\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 59\n",
      "update_interval: 100\n",
      "Test progress: (59 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 227.95189499855042\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 60\n",
      "update_interval: 100\n",
      "Test progress: (60 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 231.66155672073364\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 61\n",
      "update_interval: 100\n",
      "Test progress: (61 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 235.36796927452087\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 62\n",
      "update_interval: 100\n",
      "Test progress: (62 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 239.02809762954712\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 63\n",
      "update_interval: 100\n",
      "Test progress: (63 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 242.71041059494019\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 64\n",
      "update_interval: 100\n",
      "Test progress: (64 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 246.37058782577515\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 65\n",
      "update_interval: 100\n",
      "Test progress: (65 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 250.0700705051422\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 66\n",
      "update_interval: 100\n",
      "Test progress: (66 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 253.64379692077637\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 67\n",
      "update_interval: 100\n",
      "Test progress: (67 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 257.20082664489746\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 68\n",
      "update_interval: 100\n",
      "Test progress: (68 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 260.7953884601593\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 69\n",
      "update_interval: 100\n",
      "Test progress: (69 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 264.5608620643616\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 70\n",
      "update_interval: 100\n",
      "Test progress: (70 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 268.22287487983704\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 71\n",
      "update_interval: 100\n",
      "Test progress: (71 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 271.8710837364197\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 72\n",
      "update_interval: 100\n",
      "Test progress: (72 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 275.4406306743622\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 73\n",
      "update_interval: 100\n",
      "Test progress: (73 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 279.00009202957153\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 74\n",
      "update_interval: 100\n",
      "Test progress: (74 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 282.56205201148987\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 75\n",
      "update_interval: 100\n",
      "Test progress: (75 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 286.1818552017212\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 76\n",
      "update_interval: 100\n",
      "Test progress: (76 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 289.72925305366516\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 77\n",
      "update_interval: 100\n",
      "Test progress: (77 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 293.3002727031708\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 78\n",
      "update_interval: 100\n",
      "Test progress: (78 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 296.849839925766\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 79\n",
      "update_interval: 100\n",
      "Test progress: (79 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 300.4135465621948\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 80\n",
      "update_interval: 100\n",
      "Test progress: (80 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 304.05182003974915\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 81\n",
      "update_interval: 100\n",
      "Test progress: (81 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 307.6561346054077\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 82\n",
      "update_interval: 100\n",
      "Test progress: (82 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 311.3900890350342\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 83\n",
      "update_interval: 100\n",
      "Test progress: (83 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 315.1395626068115\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 84\n",
      "update_interval: 100\n",
      "Test progress: (84 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 318.94035363197327\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 85\n",
      "update_interval: 100\n",
      "Test progress: (85 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 322.5310037136078\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 86\n",
      "update_interval: 100\n",
      "Test progress: (86 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 326.1912398338318\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 87\n",
      "update_interval: 100\n",
      "Test progress: (87 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 329.7592990398407\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 88\n",
      "update_interval: 100\n",
      "Test progress: (88 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 333.31284761428833\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 89\n",
      "update_interval: 100\n",
      "Test progress: (89 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 336.9300947189331\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 90\n",
      "update_interval: 100\n",
      "Test progress: (90 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 340.64338397979736\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 91\n",
      "update_interval: 100\n",
      "Test progress: (91 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 344.3140366077423\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 92\n",
      "update_interval: 100\n",
      "Test progress: (92 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 348.07056975364685\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 93\n",
      "update_interval: 100\n",
      "Test progress: (93 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 351.77010464668274\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 94\n",
      "update_interval: 100\n",
      "Test progress: (94 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 355.41663885116577\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 95\n",
      "update_interval: 100\n",
      "Test progress: (95 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 359.10078167915344\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 96\n",
      "update_interval: 100\n",
      "Test progress: (96 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 362.7865948677063\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 97\n",
      "update_interval: 100\n",
      "Test progress: (97 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 366.4846661090851\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 98\n",
      "update_interval: 100\n",
      "Test progress: (98 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 370.2481167316437\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "n_examples: 100\n",
      "i: 99\n",
      "update_interval: 100\n",
      "Test progress: (99 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 373.9762153625488\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582898>\n",
      "(i) % update_interval: 99\n",
      "predictions: tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "labels: tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[8.1950e+03, 0.0000e+00],\n",
      "        [2.4577e+04, 2.0000e+00],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [2.0000e+00, 4.0960e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "Training complete.\n",
      "\n",
      "all confusion_matrix(labels, all_activity_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "prop confusion_matrix(labels, proportion_pred): [[80  0]\n",
      " [ 0 20]]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "n_train: 1\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "trainLabels: [0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1]\n",
      "trainLabels: [0]\n",
      "continuing training (loading network): \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 1\n",
      "n_examples: 1\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 1)\n",
      "len(images): 1\n",
      "(images).shape: torch.Size([1, 1, 4096])\n",
      "len(labels): 1\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 5.030533313751221\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7c0b8b2550>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[8.1950e+03, 0.0000e+00],\n",
      "        [2.4577e+04, 2.0000e+00],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [2.0000e+00, 4.0960e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [5.051621913909912]\n",
      "Training complete.\n",
      "\n",
      "saving model to: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "Training complete for index: 11\n",
      "\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 1]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting testing: \n",
      "loading model from: params/seizure_snn/diehl_and_cook_2015/0_5_5_5_0.1_0.1_4096_1.0_0.1_30_10_1.pt\n",
      "epoch: 0\n",
      "\n",
      "Begin testing.\n",
      "\n",
      "n_examples: 100\n",
      "n_examples: 100\n",
      "i: 0\n",
      "update_interval: 100\n",
      "Test progress: (0 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 3.6655142307281494\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 1\n",
      "update_interval: 100\n",
      "Test progress: (1 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 7.366887092590332\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 2\n",
      "update_interval: 100\n",
      "Test progress: (2 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 11.12416124343872\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 3\n",
      "update_interval: 100\n",
      "Test progress: (3 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 14.82807731628418\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 4\n",
      "update_interval: 100\n",
      "Test progress: (4 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 18.56747817993164\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 5\n",
      "update_interval: 100\n",
      "Test progress: (5 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 22.240694522857666\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 6\n",
      "update_interval: 100\n",
      "Test progress: (6 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 25.903700351715088\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 7\n",
      "update_interval: 100\n",
      "Test progress: (7 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 29.58467936515808\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 8\n",
      "update_interval: 100\n",
      "Test progress: (8 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 33.23578238487244\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 9\n",
      "update_interval: 100\n",
      "Test progress: (9 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 36.81608057022095\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 10\n",
      "update_interval: 100\n",
      "Test progress: (10 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 40.409459829330444\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 11\n",
      "update_interval: 100\n",
      "Test progress: (11 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 43.999754428863525\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 12\n",
      "update_interval: 100\n",
      "Test progress: (12 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 47.61439228057861\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 13\n",
      "update_interval: 100\n",
      "Test progress: (13 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 51.24528479576111\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 14\n",
      "update_interval: 100\n",
      "Test progress: (14 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 54.918612480163574\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 15\n",
      "update_interval: 100\n",
      "Test progress: (15 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 58.53804922103882\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 16\n",
      "update_interval: 100\n",
      "Test progress: (16 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 62.2363178730011\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 17\n",
      "update_interval: 100\n",
      "Test progress: (17 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 65.90981721878052\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 18\n",
      "update_interval: 100\n",
      "Test progress: (18 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 69.59953212738037\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 19\n",
      "update_interval: 100\n",
      "Test progress: (19 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 73.25516390800476\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 20\n",
      "update_interval: 100\n",
      "Test progress: (20 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 76.95040726661682\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 21\n",
      "update_interval: 100\n",
      "Test progress: (21 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 80.59470176696777\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 22\n",
      "update_interval: 100\n",
      "Test progress: (22 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Time Elapsed (secs): 84.27139902114868\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 23\n",
      "update_interval: 100\n",
      "Test progress: (23 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 87.98870277404785\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 24\n",
      "update_interval: 100\n",
      "Test progress: (24 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 91.69243454933167\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 25\n",
      "update_interval: 100\n",
      "Test progress: (25 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 95.35317802429199\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 26\n",
      "update_interval: 100\n",
      "Test progress: (26 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 99.08164525032043\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 27\n",
      "update_interval: 100\n",
      "Test progress: (27 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 102.72099256515503\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 28\n",
      "update_interval: 100\n",
      "Test progress: (28 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 106.38417315483093\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 29\n",
      "update_interval: 100\n",
      "Test progress: (29 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 110.06707262992859\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 30\n",
      "update_interval: 100\n",
      "Test progress: (30 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 113.76421594619751\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 31\n",
      "update_interval: 100\n",
      "Test progress: (31 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 117.47410416603088\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 32\n",
      "update_interval: 100\n",
      "Test progress: (32 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 121.0852358341217\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 33\n",
      "update_interval: 100\n",
      "Test progress: (33 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 124.79997515678406\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 34\n",
      "update_interval: 100\n",
      "Test progress: (34 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 128.52490615844727\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 35\n",
      "update_interval: 100\n",
      "Test progress: (35 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 132.23711705207825\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 36\n",
      "update_interval: 100\n",
      "Test progress: (36 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 135.9586730003357\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 37\n",
      "update_interval: 100\n",
      "Test progress: (37 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 139.7048101425171\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 38\n",
      "update_interval: 100\n",
      "Test progress: (38 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 143.41693019866943\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 39\n",
      "update_interval: 100\n",
      "Test progress: (39 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 147.07693243026733\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 40\n",
      "update_interval: 100\n",
      "Test progress: (40 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 150.7628312110901\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 41\n",
      "update_interval: 100\n",
      "Test progress: (41 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 154.5232617855072\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 42\n",
      "update_interval: 100\n",
      "Test progress: (42 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 158.2781171798706\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 43\n",
      "update_interval: 100\n",
      "Test progress: (43 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 162.10416531562805\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 44\n",
      "update_interval: 100\n",
      "Test progress: (44 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 165.88966178894043\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 45\n",
      "update_interval: 100\n",
      "Test progress: (45 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 169.71631383895874\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 46\n",
      "update_interval: 100\n",
      "Test progress: (46 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 173.53496980667114\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 47\n",
      "update_interval: 100\n",
      "Test progress: (47 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 177.19777727127075\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 48\n",
      "update_interval: 100\n",
      "Test progress: (48 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(1., dtype=torch.float64)\n",
      "Model Time Elapsed (secs): 180.98655557632446\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7f7bf0582630>\n",
      "n_examples: 100\n",
      "i: 49\n",
      "update_interval: 100\n",
      "Test progress: (49 / 100)\n",
      "len(images): 100\n",
      "(images).shape: torch.Size([100, 1, 4096])\n",
      "len(labels): 100\n",
      "current label: tensor(0., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#FINAL MODEL (EVALUATE AFTER EVERY TRAINING INSTANCE)\n",
    "n_train_full=dataset.get_data()[0]['X_train'].shape[0]\n",
    "n_test_full=dataset.get_data()[0]['X_test'].shape[0]\n",
    "size_of_train_set = 1\n",
    "train_set_update_interval = 1\n",
    "resultsFilename = str(data)+\"_results_data_OPTIMAL_FINAL.txt\"\n",
    "if os.path.isfile(resultsFilename):\n",
    "    print (\"Results file exists\")\n",
    "else:\n",
    "    print (\"Results file doesn't exist, creating new file...\")\n",
    "starting_point=0\n",
    "for i, params in enumerate(grid):\n",
    "    if(i>=starting_point):\n",
    "        overallPrecisionListAll = list()\n",
    "        overallRecallListAll = list()\n",
    "        overallAccuracyListAll = list()\n",
    "        overallF1ListAll = list()\n",
    "        overallTPListAll = list()\n",
    "        overallTNListAll = list()\n",
    "        overallFPListAll = list()\n",
    "        overallFNListAll = list()\n",
    "        overallConvergenceEpochAll = list()\n",
    "\n",
    "        overallPrecisionListProp = list()\n",
    "        overallRecallListProp = list()\n",
    "        overallAccuracyListProp = list()\n",
    "        overallF1ListProp = list()\n",
    "        overallTPListProp = list()\n",
    "        overallTNListProp = list()\n",
    "        overallFPListProp = list()\n",
    "        overallFNListProp = list()\n",
    "        overallConvergenceEpochProp = list()\n",
    "\n",
    "\n",
    "        trainingTimeList = list()\n",
    "        with open(resultsFilename, \"a\") as text_file:\n",
    "            print(f\"\\nResults for : {str(params)}\\n\\n\", file=text_file)\n",
    "        confusionMatricesList = list()\n",
    "        for fold in np.arange(n_folds):\n",
    "            currentFold = fold\n",
    "            # Train the network.\n",
    "            with open(resultsFilename, \"a\") as text_file:\n",
    "                print(f\"\\nFold : {str(currentFold)}\\n\", file=text_file)\n",
    "                print(f\"Size of Total Training Set : {str(n_train_full)}\\n\", file=text_file)\n",
    "                print(f\"Eval every {str(size_of_train_set)} observations.\\n\", file=text_file)\n",
    "            print(\"Begin training for fold \" + str(currentFold) + \"\\n\")\n",
    "            start = t()\n",
    "\n",
    "            foldEpochAccuracyAll = list()\n",
    "            foldEpochPrecisionAll = list()\n",
    "            foldEpochRecallAll = list()\n",
    "            foldEpochF1scoreAll = list()\n",
    "            foldEpochTPAll = list()\n",
    "            foldEpochTNAll = list()\n",
    "            foldEpochFPAll = list()\n",
    "            foldEpochFNAll = list()\n",
    "\n",
    "            foldEpochAccuracyProp = list()\n",
    "            foldEpochPrecisionProp = list()\n",
    "            foldEpochRecallProp = list()\n",
    "            foldEpochF1scoreProp = list()\n",
    "            foldEpochTPProp = list()\n",
    "            foldEpochTNProp = list()\n",
    "            foldEpochFPProp = list()\n",
    "            foldEpochFNProp = list()\n",
    "            totalTrainingTimeSecs = list()\n",
    "\n",
    "            for index in range(int(n_train_full/size_of_train_set)):\n",
    "                if(index>=15):\n",
    "                    break\n",
    "                with open(resultsFilename, \"a\") as text_file:\n",
    "                    print(f\"Current Training Index : {str(index)}/{str(int(n_train_full/size_of_train_set))}\\n\", file=text_file)\n",
    "                dataset = EEGSeizureDatasetBalanced(testingByDatapoint=True, returnObservation=index, observationsSize=size_of_train_set)\n",
    "                n_train=dataset.get_data()[0]['X_train'].shape[0]\n",
    "                print('n_train: '+str(n_train))\n",
    "                n_test=dataset.get_data()[0]['X_test'].shape[0]\n",
    "\n",
    "                # Create a dataloader to iterate and batch data\n",
    "                dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=0, pin_memory=gpu)\n",
    "                result, trainingTime = createSNN(train=True, singleSample=True, n_neurons=params['n_neurons'],\n",
    "                                                 lr_pre=params['lr_pre'],\n",
    "                                                 inh=params['inh'], lr_post=params['lr_post'], exc=params['exc'],\n",
    "                                                 update_interval=train_set_update_interval, current_fold=currentFold,\n",
    "                                                 current_epoch=index, n_train=size_of_train_set)\n",
    "                print(\"Training complete for index: \" + str(index) + \"\\n\")\n",
    "                testResult, testingTime = createSNN(train=False, singleSample=False, n_neurons=params['n_neurons'],\n",
    "                                                    lr_pre=params['lr_pre'],\n",
    "                                                    inh=params['inh'], lr_post=params['lr_post'], exc=params['exc'],\n",
    "                                                    update_interval=params['update_interval'], current_fold=currentFold,\n",
    "                                                    current_epoch=index)\n",
    "\n",
    "                TPAll = testResult['all'][0][0]\n",
    "                FPAll = testResult['all'][0][1]\n",
    "                FNAll = testResult['all'][1][0]\n",
    "                TNAll = testResult['all'][1][1]\n",
    "                TPProp = testResult['prop'][0][0]\n",
    "                FPProp = testResult['prop'][0][1]\n",
    "                FNProp = testResult['prop'][1][0]\n",
    "                TNProp = testResult['prop'][1][1]\n",
    "\n",
    "                precisionAll = (TPAll / (TPAll + FPAll))\n",
    "                recallAll = (TPAll / (TPAll + FNAll))\n",
    "                accuracyAll = (TPAll + TNAll) / (TPAll + FPAll + FNAll + TNAll)\n",
    "                f1scoreAll = 2 * ((precisionAll * recallAll) / (precisionAll + recallAll))\n",
    "                precisionProp = (TPProp / (TPProp + FPProp))\n",
    "                recallProp = (TPProp / (TPProp + FNProp))\n",
    "                accuracyProp = (TPProp + TNProp) / (TPProp + FPProp + FNProp + TNProp)\n",
    "                f1scoreProp = 2 * ((precisionProp * recallProp) / (precisionProp + recallProp))\n",
    "\n",
    "                foldEpochAccuracyAll.append(accuracyAll)\n",
    "                foldEpochPrecisionAll.append(precisionAll)\n",
    "                foldEpochRecallAll.append(recallAll)\n",
    "                foldEpochF1scoreAll.append(f1scoreAll)\n",
    "                foldEpochTPAll.append(TPAll)\n",
    "                foldEpochTNAll.append(TNAll)\n",
    "                foldEpochFPAll.append(FPAll)\n",
    "                foldEpochFNAll.append(FNAll)\n",
    "\n",
    "                foldEpochAccuracyProp.append(accuracyProp)\n",
    "                foldEpochPrecisionProp.append(precisionProp)\n",
    "                foldEpochRecallProp.append(recallProp)\n",
    "                foldEpochF1scoreProp.append(f1scoreProp)\n",
    "                foldEpochTPProp.append(TPProp)\n",
    "                foldEpochTNProp.append(TNProp)\n",
    "                foldEpochFPProp.append(FPProp)\n",
    "                foldEpochFNProp.append(FNProp)\n",
    "\n",
    "            convergenceObservationAccuracyAll=str(foldEpochAccuracyAll.index(max(foldEpochAccuracyAll)))\n",
    "            convergenceObservationAccuracyProp=str(foldEpochAccuracyProp.index(max(foldEpochAccuracyProp)))\n",
    "\n",
    "            with open(resultsFilename, \"a\") as text_file:\n",
    "                print(f\"Training complete for fold {str(currentFold)}\\n\", file=text_file)\n",
    "                print(f\"Total Training Time: {str(sum(trainingTime))}\", file=text_file)\n",
    "                print(f\"Number of Epochs: {str(len(trainingTime))}\\n\", file=text_file)\n",
    "                print(f\"trainingTime: {str((trainingTime))}\\n\", file=text_file)\n",
    "                print(f\"Fold {str(currentFold)} Test Metrics:\\n\", file=text_file)\n",
    "                print(f\"All Spikes:\\n\", file=text_file)\n",
    "                print(f\"TP: {str(foldEpochTPAll)}\\nTN: {str(foldEpochTNAll)}\\nFP: {str(foldEpochFPAll)}\\nFN: {str(foldEpochFNAll)}\\n\", file=text_file)\n",
    "                print(f\"Accuracy: {str(foldEpochAccuracyAll)}\\nPrecision: {str(foldEpochPrecisionAll)}\\nRecall: {str(foldEpochRecallAll)}\\nF1: {str(foldEpochF1scoreAll)}\\n\", file=text_file)\n",
    "                print(f\"Accuracy Maxes at Epoch: {str(convergenceObservationAccuracyAll)}\\n\", file=text_file)\n",
    "                print(f\"Prop Spikes:\\n\", file=text_file)\n",
    "                print(f\"TP: {str(foldEpochTPProp)}\\nTN: {str(foldEpochTNProp)}\\nFP: {str(foldEpochFPProp)}\\nFN: {str(foldEpochFNProp)}\\n\",\n",
    "                      file=text_file)\n",
    "                print(f\"Accuracy: {str(foldEpochAccuracyProp)}\\nPrecision: {str(foldEpochPrecisionProp)}\\nRecall: {str(foldEpochRecallProp)}\\nF1: {str(foldEpochF1scoreProp)}\\n\", file=text_file)\n",
    "                print(f\"Accuracy Maxes at Epoch: {convergenceObservationAccuracyProp}\\n\", file=text_file)\n",
    "\n",
    "            overallPrecisionListAll.append(foldEpochPrecisionAll)\n",
    "            overallRecallListAll.append(foldEpochRecallAll)\n",
    "            overallAccuracyListAll.append(foldEpochAccuracyAll)\n",
    "            overallF1ListAll.append(foldEpochF1scoreAll)\n",
    "            overallTPListAll.append(foldEpochTPAll)\n",
    "            overallTNListAll.append(foldEpochTNAll)\n",
    "            overallFPListAll.append(foldEpochFPAll)\n",
    "            overallFNListAll.append(foldEpochFNAll)\n",
    "            overallConvergenceEpochAll.append(convergenceObservationAccuracyAll)\n",
    "\n",
    "            overallPrecisionListProp.append(foldEpochPrecisionProp)\n",
    "            overallRecallListProp.append(foldEpochRecallProp)\n",
    "            overallAccuracyListProp.append(foldEpochAccuracyProp)\n",
    "            overallF1ListProp.append(foldEpochF1scoreProp)\n",
    "            overallTPListProp.append(foldEpochTPProp)\n",
    "            overallTNListProp.append(foldEpochTNProp)\n",
    "            overallFPListProp.append(foldEpochFPProp)\n",
    "            overallFNListProp.append(foldEpochFNProp)\n",
    "            overallConvergenceEpochAll.append(convergenceObservationAccuracyProp)\n",
    "\n",
    "        precisionAllMeanOverFolds=np.average(np.array(overallPrecisionListAll), axis=0)\n",
    "        recallAllMeanOverFolds=np.average(np.array(overallRecallListAll), axis=0)\n",
    "        accuracyAllMeanOverFolds=np.average(np.array(overallAccuracyListAll), axis=0)\n",
    "        F1AllMeanOverFolds=np.average(np.array(overallF1ListAll), axis=0)\n",
    "        TPAllMeanOverFolds = np.average(np.array(overallTPListAll), axis=0)\n",
    "        TNAllMeanOverFolds = np.average(np.array(overallTNListAll), axis=0)\n",
    "        FPAllMeanOverFolds = np.average(np.array(overallFPListAll), axis=0)\n",
    "        FNAllMeanOverFolds = np.average(np.array(overallFNListAll), axis=0)\n",
    "        convergenceAllMeanOverFolds = np.mean(np.array(overallConvergenceEpochAll).astype(np.float))+1\n",
    "\n",
    "        precisionPropMeanOverFolds = np.average(np.array(overallPrecisionListProp), axis=0)\n",
    "        recallPropMeanOverFolds = np.average(np.array(overallRecallListProp), axis=0)\n",
    "        accuracyPropMeanOverFolds = np.average(np.array(overallAccuracyListProp), axis=0)\n",
    "        F1PropMeanOverFolds = np.average(np.array(overallF1ListProp), axis=0)\n",
    "        TPPropMeanOverFolds = np.average(np.array(overallTPListProp), axis=0)\n",
    "        TNPropMeanOverFolds = np.average(np.array(overallTNListProp), axis=0)\n",
    "        FPPropMeanOverFolds = np.average(np.array(overallFPListProp), axis=0)\n",
    "        FNPropMeanOverFolds = np.average(np.array(overallFNListProp), axis=0)\n",
    "        convergencePropMeanOverFolds = np.mean(np.array(overallConvergenceEpochProp).astype(np.float))+1\n",
    "\n",
    "        with open(resultsFilename, \"a\") as text_file:\n",
    "            print(f\"Training complete for all folds for params: {str(params)}\", file=text_file)\n",
    "            print(f\"Mean Test Metrics Over All Folds:\\n\", file=text_file)\n",
    "            print(f\"All Spikes:\\n\", file=text_file)\n",
    "            print(f\"Final Accuracy: {str(accuracyAllMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final Precision: {str(precisionAllMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final Recall: {str(recallAllMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final F1: {str(F1AllMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final TP: {str(TPAllMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final FP: {str(FPAllMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final TN: {str(TNAllMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final FN: {str(FNAllMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Obs. Until Max Accuracy: {str(convergenceAllMeanOverFolds)}\\n\", file=text_file)\n",
    "            print(\n",
    "                f\"TP: {str(list(TPAllMeanOverFolds))}\\nTN: {str(list(TNAllMeanOverFolds))}\\nFP: {str(list(FPAllMeanOverFolds))}\\nFN: {str(list(FNAllMeanOverFolds))}\\n\",\n",
    "                file=text_file)\n",
    "            print(\n",
    "                f\"Accuracy: {str(list(accuracyAllMeanOverFolds))}\\nPrecision: {str(list(precisionAllMeanOverFolds))}\\nRecall: {str(list(recallAllMeanOverFolds))}\\nF1: {str(list(F1AllMeanOverFolds))}\\n\",\n",
    "                file=text_file)\n",
    "\n",
    "            print(f\"Prop Spikes:\\n\", file=text_file)\n",
    "            print(f\"Final Accuracy: {str(accuracyPropMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final Precision: {str(precisionPropMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final Recall: {str(recallPropMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final F1: {str(F1PropMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final TP: {str(TPPropMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final FP: {str(FPPropMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final TN: {str(TNPropMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final FN: {str(FNPropMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Obs. Until Max Accuracy: {str(convergencePropMeanOverFolds)}\\n\", file=text_file)\n",
    "            print(\n",
    "                f\"TP: {str(list(TPPropMeanOverFolds))}\\nTN: {str(list(TNPropMeanOverFolds))}\\nFP: {str(list(FPPropMeanOverFolds))}\\nFN: {str(list(FNPropMeanOverFolds))}\\n\",\n",
    "                file=text_file)\n",
    "            print(\n",
    "                f\"Accuracy: {str(list(accuracyPropMeanOverFolds))}\\nPrecision: {str(list(precisionPropMeanOverFolds))}\\nRecall: {str(list(recallPropMeanOverFolds))}\\nF1: {str(list(F1PropMeanOverFolds))}\\n\",\n",
    "                file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "Results file exists\n",
      "Begin training for fold 0\n",
      "\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "n_train: 160\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "params: [0, 5, 5, 5, 0.1, 0.1, 4096, 1.0, 0.1, 30, 10, 0]\n",
      "100.0/500\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "positiveEEGs: 80\n",
      "negativeEEGs: 320\n",
      "80\n",
      "starting training (new network): \n",
      "NewNetwork: NewNetwork(\n",
      "  (X): Input()\n",
      "  (Ae): DiehlAndCookNodes()\n",
      "  (Ai): LIFNodes()\n",
      "  (X_to_Ae): Connection(\n",
      "    (source): Input()\n",
      "    (target): DiehlAndCookNodes()\n",
      "  )\n",
      "  (Ae_to_Ai): Connection(\n",
      "    (source): DiehlAndCookNodes()\n",
      "    (target): LIFNodes()\n",
      "  )\n",
      "  (Ai_to_Ae): Connection(\n",
      "    (source): LIFNodes()\n",
      "    (target): DiehlAndCookNodes()\n",
      "  )\n",
      ")\n",
      "epoch: 0\n",
      "\n",
      "Begin training.\n",
      "\n",
      "n_examples: 160\n",
      "n_examples: 160\n",
      "i: 0\n",
      "update_interval: 1\n",
      "Train progress: (0 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 31.070761680603027\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 0\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045]\n",
      "n_examples: 160\n",
      "i: 1\n",
      "update_interval: 1\n",
      "Train progress: (1 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 48.45834398269653\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 1\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [4.0960e+03, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296]\n",
      "n_examples: 160\n",
      "i: 2\n",
      "update_interval: 1\n",
      "Train progress: (2 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 79.55932974815369\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 2\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 100.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [8.1920e+03, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786]\n",
      "n_examples: 160\n",
      "i: 3\n",
      "update_interval: 1\n",
      "Train progress: (3 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 110.89363837242126\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 3\n",
      "predictions: tensor([0])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 0.00 (last), 75.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 0.00 (last), 75.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.2288e+04, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609]\n",
      "n_examples: 160\n",
      "i: 4\n",
      "update_interval: 1\n",
      "Train progress: (4 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 142.13429999351501\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 4\n",
      "predictions: tensor([0])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 0.00 (last), 60.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 0.00 (last), 60.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 4.0960e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256]\n",
      "n_examples: 160\n",
      "i: 5\n",
      "update_interval: 1\n",
      "Train progress: (5 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 173.40173935890198\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 5\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 66.67 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 66.67 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.2288e+04, 1.0000e+00],\n",
      "        [1.0000e+00, 4.0960e+03],\n",
      "        [1.0000e+00, 4.0970e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492]\n",
      "n_examples: 160\n",
      "i: 6\n",
      "update_interval: 1\n",
      "Train progress: (6 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 204.616224527359\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 6\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 71.43 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 71.43 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.6384e+04, 1.0000e+00],\n",
      "        [2.0000e+00, 4.0960e+03],\n",
      "        [1.0000e+00, 4.0970e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517]\n",
      "n_examples: 160\n",
      "i: 7\n",
      "update_interval: 1\n",
      "Train progress: (7 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Time Elapsed (secs): 235.80464720726013\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 7\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 75.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 75.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [2.0480e+04, 1.0000e+00],\n",
      "        [2.0000e+00, 4.0960e+03],\n",
      "        [1.0000e+00, 4.0970e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616]\n",
      "n_examples: 160\n",
      "i: 8\n",
      "update_interval: 1\n",
      "Train progress: (8 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 266.9372305870056\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 8\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 77.78 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 77.78 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [2.0480e+04, 2.0000e+00],\n",
      "        [2.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 4.0970e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928]\n",
      "n_examples: 160\n",
      "i: 9\n",
      "update_interval: 1\n",
      "Train progress: (9 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 298.01874828338623\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 9\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 80.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 80.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[4.0970e+03, 0.0000e+00],\n",
      "        [2.0480e+04, 2.0000e+00],\n",
      "        [3.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 4.0970e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058]\n",
      "n_examples: 160\n",
      "i: 10\n",
      "update_interval: 1\n",
      "Train progress: (10 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 329.20786023139954\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 10\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 81.82 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 81.82 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[4.0980e+03, 0.0000e+00],\n",
      "        [2.4576e+04, 2.0000e+00],\n",
      "        [3.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 4.0970e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767]\n",
      "n_examples: 160\n",
      "i: 11\n",
      "update_interval: 1\n",
      "Train progress: (11 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 360.40411615371704\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 11\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 83.33 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 83.33 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[4.0980e+03, 0.0000e+00],\n",
      "        [2.8672e+04, 2.0000e+00],\n",
      "        [3.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 4.0970e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912]\n",
      "n_examples: 160\n",
      "i: 12\n",
      "update_interval: 1\n",
      "Train progress: (12 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 391.67816400527954\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 12\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 84.62 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 84.62 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[4.0980e+03, 0.0000e+00],\n",
      "        [3.2768e+04, 2.0000e+00],\n",
      "        [3.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 4.0970e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875]\n",
      "n_examples: 160\n",
      "i: 13\n",
      "update_interval: 1\n",
      "Train progress: (13 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 422.92795395851135\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 13\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 85.71 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 85.71 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[4.0980e+03, 0.0000e+00],\n",
      "        [3.2768e+04, 3.0000e+00],\n",
      "        [3.0000e+00, 8.1920e+03],\n",
      "        [1.0000e+00, 8.1930e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776]\n",
      "n_examples: 160\n",
      "i: 14\n",
      "update_interval: 1\n",
      "Train progress: (14 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Time Elapsed (secs): 454.10868525505066\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 14\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 86.67 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 86.67 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[8.1940e+03, 0.0000e+00],\n",
      "        [3.2768e+04, 3.0000e+00],\n",
      "        [3.0000e+00, 8.1920e+03],\n",
      "        [2.0000e+00, 8.1930e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343]\n",
      "n_examples: 160\n",
      "i: 15\n",
      "update_interval: 1\n",
      "Train progress: (15 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 462.97973895072937\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 15\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 87.50 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 87.50 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[1.2290e+04, 0.0000e+00],\n",
      "        [3.2768e+04, 3.0000e+00],\n",
      "        [3.0000e+00, 8.1920e+03],\n",
      "        [2.0000e+00, 8.1930e+03],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646]\n",
      "n_examples: 160\n",
      "i: 16\n",
      "update_interval: 1\n",
      "Train progress: (16 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 468.14528703689575\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 16\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 88.24 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 88.24 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[1.2290e+04, 1.0000e+00],\n",
      "        [3.2768e+04, 3.0000e+00],\n",
      "        [3.0000e+00, 8.1920e+03],\n",
      "        [2.0000e+00, 1.2289e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426]\n",
      "n_examples: 160\n",
      "i: 17\n",
      "update_interval: 1\n",
      "Train progress: (17 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 473.5463364124298\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 17\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 88.89 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 88.89 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[1.2290e+04, 1.0000e+00],\n",
      "        [3.2768e+04, 3.0000e+00],\n",
      "        [3.0000e+00, 8.1920e+03],\n",
      "        [2.0000e+00, 1.6385e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073]\n",
      "n_examples: 160\n",
      "i: 18\n",
      "update_interval: 1\n",
      "Train progress: (18 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 478.57937026023865\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 18\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 89.47 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 89.47 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[1.2290e+04, 1.0000e+00],\n",
      "        [3.6864e+04, 3.0000e+00],\n",
      "        [3.0000e+00, 8.1920e+03],\n",
      "        [3.0000e+00, 1.6385e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885]\n",
      "n_examples: 160\n",
      "i: 19\n",
      "update_interval: 1\n",
      "Train progress: (19 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 483.5973205566406\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 19\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 90.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 90.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[1.6386e+04, 1.0000e+00],\n",
      "        [3.6865e+04, 3.0000e+00],\n",
      "        [3.0000e+00, 8.1920e+03],\n",
      "        [3.0000e+00, 1.6385e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918]\n",
      "n_examples: 160\n",
      "i: 20\n",
      "update_interval: 1\n",
      "Train progress: (20 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 488.5734987258911\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 20\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 90.48 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 90.48 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "rates: tensor([[2.0482e+04, 1.0000e+00],\n",
      "        [3.6865e+04, 3.0000e+00],\n",
      "        [3.0000e+00, 8.1920e+03],\n",
      "        [3.0000e+00, 1.6385e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542]\n",
      "n_examples: 160\n",
      "i: 21\n",
      "update_interval: 1\n",
      "Train progress: (21 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Time Elapsed (secs): 494.33873200416565\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 21\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 90.91 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 90.91 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[2.0482e+04, 2.0000e+00],\n",
      "        [3.6865e+04, 3.0000e+00],\n",
      "        [3.0000e+00, 1.2288e+04],\n",
      "        [3.0000e+00, 1.6385e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914]\n",
      "n_examples: 160\n",
      "i: 22\n",
      "update_interval: 1\n",
      "Train progress: (22 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 499.6328902244568\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 22\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 91.30 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 91.30 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[2.0482e+04, 2.0000e+00],\n",
      "        [3.6865e+04, 3.0000e+00],\n",
      "        [3.0000e+00, 1.2289e+04],\n",
      "        [3.0000e+00, 2.0481e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026]\n",
      "n_examples: 160\n",
      "i: 23\n",
      "update_interval: 1\n",
      "Train progress: (23 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 504.8216247558594\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 23\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 91.67 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 91.67 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "rates: tensor([[2.0482e+04, 2.0000e+00],\n",
      "        [3.6865e+04, 3.0000e+00],\n",
      "        [3.0000e+00, 1.2289e+04],\n",
      "        [3.0000e+00, 2.4577e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423]\n",
      "n_examples: 160\n",
      "i: 24\n",
      "update_interval: 1\n",
      "Train progress: (24 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 509.8802697658539\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 24\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 92.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 92.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[2.0482e+04, 2.0000e+00],\n",
      "        [3.6865e+04, 3.0000e+00],\n",
      "        [3.0000e+00, 1.6385e+04],\n",
      "        [3.0000e+00, 2.4578e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646]\n",
      "n_examples: 160\n",
      "i: 25\n",
      "update_interval: 1\n",
      "Train progress: (25 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 514.8531222343445\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 25\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 92.31 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 92.31 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[2.0482e+04, 2.0000e+00],\n",
      "        [3.6865e+04, 3.0000e+00],\n",
      "        [3.0000e+00, 1.6386e+04],\n",
      "        [3.0000e+00, 2.8674e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455]\n",
      "n_examples: 160\n",
      "i: 26\n",
      "update_interval: 1\n",
      "Train progress: (26 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 519.772382736206\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 26\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 92.59 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 92.59 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[2.0482e+04, 2.0000e+00],\n",
      "        [3.6865e+04, 3.0000e+00],\n",
      "        [3.0000e+00, 1.6386e+04],\n",
      "        [3.0000e+00, 3.2770e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947]\n",
      "n_examples: 160\n",
      "i: 27\n",
      "update_interval: 1\n",
      "Train progress: (27 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Time Elapsed (secs): 524.7391288280487\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 27\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 92.86 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 92.86 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[2.4578e+04, 2.0000e+00],\n",
      "        [3.6865e+04, 3.0000e+00],\n",
      "        [3.0000e+00, 1.6386e+04],\n",
      "        [4.0000e+00, 3.2770e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737]\n",
      "n_examples: 160\n",
      "i: 28\n",
      "update_interval: 1\n",
      "Train progress: (28 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 529.8383700847626\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 28\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 93.10 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 93.10 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[2.4578e+04, 3.0000e+00],\n",
      "        [3.6865e+04, 3.0000e+00],\n",
      "        [3.0000e+00, 1.6386e+04],\n",
      "        [4.0000e+00, 3.6866e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212]\n",
      "n_examples: 160\n",
      "i: 29\n",
      "update_interval: 1\n",
      "Train progress: (29 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 534.8464748859406\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 29\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 93.33 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 93.33 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[2.8674e+04, 3.0000e+00],\n",
      "        [3.6865e+04, 3.0000e+00],\n",
      "        [3.0000e+00, 1.6386e+04],\n",
      "        [5.0000e+00, 3.6866e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927]\n",
      "n_examples: 160\n",
      "i: 30\n",
      "update_interval: 1\n",
      "Train progress: (30 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 539.8494284152985\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 30\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 93.55 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 93.55 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[3.2770e+04, 3.0000e+00],\n",
      "        [3.6865e+04, 3.0000e+00],\n",
      "        [3.0000e+00, 1.6386e+04],\n",
      "        [5.0000e+00, 3.6866e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591]\n",
      "n_examples: 160\n",
      "i: 31\n",
      "update_interval: 1\n",
      "Train progress: (31 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 544.8436863422394\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 31\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 93.75 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 93.75 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "rates: tensor([[3.2771e+04, 3.0000e+00],\n",
      "        [4.0961e+04, 3.0000e+00],\n",
      "        [3.0000e+00, 1.6386e+04],\n",
      "        [5.0000e+00, 3.6866e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395]\n",
      "n_examples: 160\n",
      "i: 32\n",
      "update_interval: 1\n",
      "Train progress: (32 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 549.9216001033783\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 32\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 93.94 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 93.94 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "rates: tensor([[3.2771e+04, 3.0000e+00],\n",
      "        [4.0961e+04, 4.0000e+00],\n",
      "        [3.0000e+00, 2.0482e+04],\n",
      "        [5.0000e+00, 3.6866e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886]\n",
      "n_examples: 160\n",
      "i: 33\n",
      "update_interval: 1\n",
      "Train progress: (33 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Time Elapsed (secs): 554.9001564979553\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 33\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 94.12 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 94.12 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[3.2771e+04, 3.0000e+00],\n",
      "        [4.0961e+04, 4.0000e+00],\n",
      "        [3.0000e+00, 2.4578e+04],\n",
      "        [5.0000e+00, 3.6866e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336]\n",
      "n_examples: 160\n",
      "i: 34\n",
      "update_interval: 1\n",
      "Train progress: (34 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 559.982705116272\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 34\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 94.29 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 94.29 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[3.6867e+04, 3.0000e+00],\n",
      "        [4.0961e+04, 4.0000e+00],\n",
      "        [4.0000e+00, 2.4578e+04],\n",
      "        [5.0000e+00, 3.6866e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932]\n",
      "n_examples: 160\n",
      "i: 35\n",
      "update_interval: 1\n",
      "Train progress: (35 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 564.9772987365723\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 35\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 94.44 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 94.44 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[3.6867e+04, 4.0000e+00],\n",
      "        [4.0961e+04, 4.0000e+00],\n",
      "        [4.0000e+00, 2.4578e+04],\n",
      "        [5.0000e+00, 4.0962e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496]\n",
      "n_examples: 160\n",
      "i: 36\n",
      "update_interval: 1\n",
      "Train progress: (36 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 570.0216202735901\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 36\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 94.59 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 94.59 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[3.6867e+04, 4.0000e+00],\n",
      "        [4.0961e+04, 4.0000e+00],\n",
      "        [4.0000e+00, 2.4578e+04],\n",
      "        [5.0000e+00, 4.5058e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246]\n",
      "n_examples: 160\n",
      "i: 37\n",
      "update_interval: 1\n",
      "Train progress: (37 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 575.0541236400604\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 37\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 94.74 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 94.74 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "rates: tensor([[3.6867e+04, 4.0000e+00],\n",
      "        [4.5057e+04, 4.0000e+00],\n",
      "        [4.0000e+00, 2.4578e+04],\n",
      "        [6.0000e+00, 4.5058e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002]\n",
      "n_examples: 160\n",
      "i: 38\n",
      "update_interval: 1\n",
      "Train progress: (38 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Time Elapsed (secs): 580.0685260295868\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 38\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 94.87 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 94.87 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[3.6867e+04, 4.0000e+00],\n",
      "        [4.5057e+04, 5.0000e+00],\n",
      "        [4.0000e+00, 2.8674e+04],\n",
      "        [6.0000e+00, 4.5058e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023]\n",
      "n_examples: 160\n",
      "i: 39\n",
      "update_interval: 1\n",
      "Train progress: (39 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 585.0799036026001\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 39\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 95.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 95.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[3.6867e+04, 4.0000e+00],\n",
      "        [4.5057e+04, 5.0000e+00],\n",
      "        [4.0000e+00, 2.8675e+04],\n",
      "        [6.0000e+00, 4.9154e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087]\n",
      "n_examples: 160\n",
      "i: 40\n",
      "update_interval: 1\n",
      "Train progress: (40 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 590.2034223079681\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 40\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 95.12 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 95.12 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[4.0963e+04, 4.0000e+00],\n",
      "        [4.5057e+04, 5.0000e+00],\n",
      "        [4.0000e+00, 2.8675e+04],\n",
      "        [7.0000e+00, 4.9154e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142]\n",
      "n_examples: 160\n",
      "i: 41\n",
      "update_interval: 1\n",
      "Train progress: (41 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 595.1896452903748\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 41\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 95.24 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 95.24 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "rates: tensor([[4.0963e+04, 5.0000e+00],\n",
      "        [4.5057e+04, 5.0000e+00],\n",
      "        [4.0000e+00, 2.8675e+04],\n",
      "        [7.0000e+00, 5.3250e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876]\n",
      "n_examples: 160\n",
      "i: 42\n",
      "update_interval: 1\n",
      "Train progress: (42 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 600.1784110069275\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 42\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 95.35 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 95.35 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "rates: tensor([[4.0963e+04, 5.0000e+00],\n",
      "        [4.5057e+04, 5.0000e+00],\n",
      "        [4.0000e+00, 3.2771e+04],\n",
      "        [7.0000e+00, 5.3251e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793]\n",
      "n_examples: 160\n",
      "i: 43\n",
      "update_interval: 1\n",
      "Train progress: (43 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Time Elapsed (secs): 605.1632328033447\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 43\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 95.45 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 95.45 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[4.0963e+04, 5.0000e+00],\n",
      "        [4.5057e+04, 5.0000e+00],\n",
      "        [4.0000e+00, 3.6867e+04],\n",
      "        [7.0000e+00, 5.3251e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228]\n",
      "n_examples: 160\n",
      "i: 44\n",
      "update_interval: 1\n",
      "Train progress: (44 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 610.2254769802094\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 44\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 95.56 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 95.56 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[4.0963e+04, 5.0000e+00],\n",
      "        [4.9153e+04, 5.0000e+00],\n",
      "        [5.0000e+00, 3.6867e+04],\n",
      "        [7.0000e+00, 5.3251e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338]\n",
      "n_examples: 160\n",
      "i: 45\n",
      "update_interval: 1\n",
      "Train progress: (45 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 615.2005794048309\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 45\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 95.65 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 95.65 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[4.0963e+04, 5.0000e+00],\n",
      "        [5.3249e+04, 5.0000e+00],\n",
      "        [5.0000e+00, 3.6867e+04],\n",
      "        [7.0000e+00, 5.3251e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933]\n",
      "n_examples: 160\n",
      "i: 46\n",
      "update_interval: 1\n",
      "Train progress: (46 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 620.2917711734772\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 46\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 95.74 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 95.74 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[4.0963e+04, 5.0000e+00],\n",
      "        [5.7345e+04, 5.0000e+00],\n",
      "        [5.0000e+00, 3.6867e+04],\n",
      "        [7.0000e+00, 5.3251e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208]\n",
      "n_examples: 160\n",
      "i: 47\n",
      "update_interval: 1\n",
      "Train progress: (47 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 625.2150309085846\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 47\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 95.83 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 95.83 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[4.5059e+04, 5.0000e+00],\n",
      "        [5.7346e+04, 5.0000e+00],\n",
      "        [5.0000e+00, 3.6867e+04],\n",
      "        [7.0000e+00, 5.3251e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562]\n",
      "n_examples: 160\n",
      "i: 48\n",
      "update_interval: 1\n",
      "Train progress: (48 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Time Elapsed (secs): 630.3411936759949\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 48\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 95.92 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 95.92 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[4.5059e+04, 6.0000e+00],\n",
      "        [5.7346e+04, 5.0000e+00],\n",
      "        [5.0000e+00, 3.6867e+04],\n",
      "        [7.0000e+00, 5.7347e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215]\n",
      "n_examples: 160\n",
      "i: 49\n",
      "update_interval: 1\n",
      "Train progress: (49 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 635.5384316444397\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 49\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 96.00 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 96.00 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[4.9155e+04, 6.0000e+00],\n",
      "        [5.7346e+04, 5.0000e+00],\n",
      "        [5.0000e+00, 3.6867e+04],\n",
      "        [8.0000e+00, 5.7347e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274]\n",
      "n_examples: 160\n",
      "i: 50\n",
      "update_interval: 1\n",
      "Train progress: (50 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 640.5686013698578\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 50\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 96.08 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 96.08 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "rates: tensor([[4.9156e+04, 6.0000e+00],\n",
      "        [6.1442e+04, 5.0000e+00],\n",
      "        [5.0000e+00, 3.6867e+04],\n",
      "        [8.0000e+00, 5.7347e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441]\n",
      "n_examples: 160\n",
      "i: 51\n",
      "update_interval: 1\n",
      "Train progress: (51 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 645.6297249794006\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 51\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 96.15 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 96.15 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[4.9156e+04, 6.0000e+00],\n",
      "        [6.1442e+04, 6.0000e+00],\n",
      "        [5.0000e+00, 4.0963e+04],\n",
      "        [8.0000e+00, 5.7347e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328]\n",
      "n_examples: 160\n",
      "i: 52\n",
      "update_interval: 1\n",
      "Train progress: (52 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 650.6544439792633\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 52\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 96.23 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 96.23 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[5.3252e+04, 6.0000e+00],\n",
      "        [6.1442e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 4.0963e+04],\n",
      "        [8.0000e+00, 5.7347e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715]\n",
      "n_examples: 160\n",
      "i: 53\n",
      "update_interval: 1\n",
      "Train progress: (53 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Time Elapsed (secs): 655.7119786739349\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 53\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 96.30 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 96.30 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[5.3252e+04, 7.0000e+00],\n",
      "        [6.1442e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 4.0963e+04],\n",
      "        [8.0000e+00, 6.1443e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515]\n",
      "n_examples: 160\n",
      "i: 54\n",
      "update_interval: 1\n",
      "Train progress: (54 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 660.7371413707733\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 54\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 96.36 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 96.36 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[5.7348e+04, 7.0000e+00],\n",
      "        [6.1442e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 4.0963e+04],\n",
      "        [9.0000e+00, 6.1443e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788]\n",
      "n_examples: 160\n",
      "i: 55\n",
      "update_interval: 1\n",
      "Train progress: (55 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 665.7623953819275\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 55\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 96.43 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 96.43 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[5.7348e+04, 8.0000e+00],\n",
      "        [6.1442e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 4.0963e+04],\n",
      "        [9.0000e+00, 6.5539e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686]\n",
      "n_examples: 160\n",
      "i: 56\n",
      "update_interval: 1\n",
      "Train progress: (56 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 670.775719165802\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 56\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 96.49 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 96.49 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[6.1444e+04, 8.0000e+00],\n",
      "        [6.1442e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 4.0963e+04],\n",
      "        [1.0000e+01, 6.5539e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041]\n",
      "n_examples: 160\n",
      "i: 57\n",
      "update_interval: 1\n",
      "Train progress: (57 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 675.8111655712128\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 57\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 96.55 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 96.55 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[6.1444e+04, 9.0000e+00],\n",
      "        [6.1442e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 4.0963e+04],\n",
      "        [1.0000e+01, 6.9635e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244]\n",
      "n_examples: 160\n",
      "i: 58\n",
      "update_interval: 1\n",
      "Train progress: (58 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Time Elapsed (secs): 680.8391926288605\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 58\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 96.61 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 96.61 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[6.5540e+04, 9.0000e+00],\n",
      "        [6.1442e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 4.0963e+04],\n",
      "        [1.1000e+01, 6.9635e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568]\n",
      "n_examples: 160\n",
      "i: 59\n",
      "update_interval: 1\n",
      "Train progress: (59 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 685.7723457813263\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 59\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 96.67 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 96.67 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[6.5540e+04, 1.0000e+01],\n",
      "        [6.1442e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 4.0963e+04],\n",
      "        [1.1000e+01, 7.3731e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305]\n",
      "n_examples: 160\n",
      "i: 60\n",
      "update_interval: 1\n",
      "Train progress: (60 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 690.7680907249451\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 60\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 96.72 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 96.72 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[6.5540e+04, 1.0000e+01],\n",
      "        [6.5538e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 4.0963e+04],\n",
      "        [1.2000e+01, 7.3731e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868]\n",
      "n_examples: 160\n",
      "i: 61\n",
      "update_interval: 1\n",
      "Train progress: (61 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 695.8088700771332\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 61\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 96.77 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 96.77 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "rates: tensor([[6.9636e+04, 1.0000e+01],\n",
      "        [6.5539e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 4.0963e+04],\n",
      "        [1.2000e+01, 7.3731e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995]\n",
      "n_examples: 160\n",
      "i: 62\n",
      "update_interval: 1\n",
      "Train progress: (62 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Time Elapsed (secs): 700.7876882553101\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 62\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 96.83 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 96.83 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "rates: tensor([[6.9636e+04, 1.1000e+01],\n",
      "        [6.5539e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 4.5059e+04],\n",
      "        [1.2000e+01, 7.3731e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545]\n",
      "n_examples: 160\n",
      "i: 63\n",
      "update_interval: 1\n",
      "Train progress: (63 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 706.0011231899261\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 63\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 96.88 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 96.88 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[6.9636e+04, 1.1000e+01],\n",
      "        [6.5539e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 4.9155e+04],\n",
      "        [1.2000e+01, 7.3731e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412]\n",
      "n_examples: 160\n",
      "i: 64\n",
      "update_interval: 1\n",
      "Train progress: (64 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 711.0142986774445\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 64\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 96.92 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 96.92 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[6.9636e+04, 1.1000e+01],\n",
      "        [6.5539e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 4.9156e+04],\n",
      "        [1.2000e+01, 7.7827e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412, 5.011859893798828]\n",
      "n_examples: 160\n",
      "i: 65\n",
      "update_interval: 1\n",
      "Train progress: (65 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 716.0242297649384\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 65\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 96.97 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 96.97 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[6.9636e+04, 1.1000e+01],\n",
      "        [6.9635e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 4.9156e+04],\n",
      "        [1.3000e+01, 7.7827e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412, 5.011859893798828, 5.009141683578491]\n",
      "n_examples: 160\n",
      "i: 66\n",
      "update_interval: 1\n",
      "Train progress: (66 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Time Elapsed (secs): 721.0497233867645\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 66\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 97.01 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 97.01 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[7.3732e+04, 1.1000e+01],\n",
      "        [6.9636e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 4.9156e+04],\n",
      "        [1.3000e+01, 7.7827e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412, 5.011859893798828, 5.009141683578491, 5.0269858837127686]\n",
      "n_examples: 160\n",
      "i: 67\n",
      "update_interval: 1\n",
      "Train progress: (67 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 726.0579051971436\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 67\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 97.06 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 97.06 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[7.3733e+04, 1.1000e+01],\n",
      "        [7.3732e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 4.9156e+04],\n",
      "        [1.3000e+01, 7.7827e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412, 5.011859893798828, 5.009141683578491, 5.0269858837127686, 5.008853435516357]\n",
      "n_examples: 160\n",
      "i: 68\n",
      "update_interval: 1\n",
      "Train progress: (68 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 731.034378528595\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 68\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 97.10 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 97.10 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[7.7829e+04, 1.1000e+01],\n",
      "        [7.3733e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 4.9156e+04],\n",
      "        [1.3000e+01, 7.7827e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412, 5.011859893798828, 5.009141683578491, 5.0269858837127686, 5.008853435516357, 4.975781679153442]\n",
      "n_examples: 160\n",
      "i: 69\n",
      "update_interval: 1\n",
      "Train progress: (69 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 737.0474636554718\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 69\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 97.14 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 97.14 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[8.1925e+04, 1.1000e+01],\n",
      "        [7.3733e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 4.9156e+04],\n",
      "        [1.3000e+01, 7.7827e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412, 5.011859893798828, 5.009141683578491, 5.0269858837127686, 5.008853435516357, 4.975781679153442, 6.010336875915527]\n",
      "n_examples: 160\n",
      "i: 70\n",
      "update_interval: 1\n",
      "Train progress: (70 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Time Elapsed (secs): 742.1854290962219\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 70\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 97.18 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 97.18 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[8.6021e+04, 1.1000e+01],\n",
      "        [7.3733e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 4.9156e+04],\n",
      "        [1.3000e+01, 7.7827e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412, 5.011859893798828, 5.009141683578491, 5.0269858837127686, 5.008853435516357, 4.975781679153442, 6.010336875915527, 5.140491247177124]\n",
      "n_examples: 160\n",
      "i: 71\n",
      "update_interval: 1\n",
      "Train progress: (71 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 747.2226974964142\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 71\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 97.22 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 97.22 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "rates: tensor([[9.0117e+04, 1.1000e+01],\n",
      "        [7.3733e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 4.9156e+04],\n",
      "        [1.3000e+01, 7.7827e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412, 5.011859893798828, 5.009141683578491, 5.0269858837127686, 5.008853435516357, 4.975781679153442, 6.010336875915527, 5.140491247177124, 5.034527540206909]\n",
      "n_examples: 160\n",
      "i: 72\n",
      "update_interval: 1\n",
      "Train progress: (72 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 753.4373323917389\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 72\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 97.26 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 97.26 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[9.0117e+04, 1.1000e+01],\n",
      "        [7.3733e+04, 6.0000e+00],\n",
      "        [6.0000e+00, 5.3252e+04],\n",
      "        [1.3000e+01, 7.7827e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412, 5.011859893798828, 5.009141683578491, 5.0269858837127686, 5.008853435516357, 4.975781679153442, 6.010336875915527, 5.140491247177124, 5.034527540206909, 6.216099262237549]\n",
      "n_examples: 160\n",
      "i: 73\n",
      "update_interval: 1\n",
      "Train progress: (73 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 758.5396332740784\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 73\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 97.30 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 97.30 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[9.0118e+04, 1.1000e+01],\n",
      "        [7.7829e+04, 6.0000e+00],\n",
      "        [7.0000e+00, 5.3252e+04],\n",
      "        [1.3000e+01, 7.7827e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412, 5.011859893798828, 5.009141683578491, 5.0269858837127686, 5.008853435516357, 4.975781679153442, 6.010336875915527, 5.140491247177124, 5.034527540206909, 6.216099262237549, 5.103572130203247]\n",
      "n_examples: 160\n",
      "i: 74\n",
      "update_interval: 1\n",
      "Train progress: (74 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Time Elapsed (secs): 763.5696423053741\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 74\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 97.33 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 97.33 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[9.0118e+04, 1.1000e+01],\n",
      "        [8.1925e+04, 6.0000e+00],\n",
      "        [7.0000e+00, 5.3252e+04],\n",
      "        [1.3000e+01, 7.7827e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412, 5.011859893798828, 5.009141683578491, 5.0269858837127686, 5.008853435516357, 4.975781679153442, 6.010336875915527, 5.140491247177124, 5.034527540206909, 6.216099262237549, 5.103572130203247, 5.0268988609313965]\n",
      "n_examples: 160\n",
      "i: 75\n",
      "update_interval: 1\n",
      "Train progress: (75 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 768.7786588668823\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 75\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 97.37 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 97.37 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[9.0118e+04, 1.1000e+01],\n",
      "        [8.1925e+04, 7.0000e+00],\n",
      "        [7.0000e+00, 5.3252e+04],\n",
      "        [1.3000e+01, 8.1923e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412, 5.011859893798828, 5.009141683578491, 5.0269858837127686, 5.008853435516357, 4.975781679153442, 6.010336875915527, 5.140491247177124, 5.034527540206909, 6.216099262237549, 5.103572130203247, 5.0268988609313965, 5.208434581756592]\n",
      "n_examples: 160\n",
      "i: 76\n",
      "update_interval: 1\n",
      "Train progress: (76 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 773.9102892875671\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 76\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 97.40 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 97.40 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[9.4214e+04, 1.1000e+01],\n",
      "        [8.1925e+04, 7.0000e+00],\n",
      "        [7.0000e+00, 5.3252e+04],\n",
      "        [1.4000e+01, 8.1923e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412, 5.011859893798828, 5.009141683578491, 5.0269858837127686, 5.008853435516357, 4.975781679153442, 6.010336875915527, 5.140491247177124, 5.034527540206909, 6.216099262237549, 5.103572130203247, 5.0268988609313965, 5.208434581756592, 5.132238388061523]\n",
      "n_examples: 160\n",
      "i: 77\n",
      "update_interval: 1\n",
      "Train progress: (77 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 778.8935015201569\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 77\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 97.44 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 97.44 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "rates: tensor([[9.8310e+04, 1.1000e+01],\n",
      "        [8.1925e+04, 7.0000e+00],\n",
      "        [7.0000e+00, 5.3252e+04],\n",
      "        [1.4000e+01, 8.1923e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412, 5.011859893798828, 5.009141683578491, 5.0269858837127686, 5.008853435516357, 4.975781679153442, 6.010336875915527, 5.140491247177124, 5.034527540206909, 6.216099262237549, 5.103572130203247, 5.0268988609313965, 5.208434581756592, 5.132238388061523, 4.982847452163696]\n",
      "n_examples: 160\n",
      "i: 78\n",
      "update_interval: 1\n",
      "Train progress: (78 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Time Elapsed (secs): 784.2567570209503\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 78\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 97.47 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 97.47 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[9.8310e+04, 1.2000e+01],\n",
      "        [8.1925e+04, 7.0000e+00],\n",
      "        [7.0000e+00, 5.7348e+04],\n",
      "        [1.4000e+01, 8.1923e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412, 5.011859893798828, 5.009141683578491, 5.0269858837127686, 5.008853435516357, 4.975781679153442, 6.010336875915527, 5.140491247177124, 5.034527540206909, 6.216099262237549, 5.103572130203247, 5.0268988609313965, 5.208434581756592, 5.132238388061523, 4.982847452163696, 5.363225698471069]\n",
      "n_examples: 160\n",
      "i: 79\n",
      "update_interval: 1\n",
      "Train progress: (79 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 789.2571682929993\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 79\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 97.50 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 97.50 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "rates: tensor([[9.8310e+04, 1.2000e+01],\n",
      "        [8.1925e+04, 7.0000e+00],\n",
      "        [7.0000e+00, 5.7349e+04],\n",
      "        [1.4000e+01, 8.6019e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412, 5.011859893798828, 5.009141683578491, 5.0269858837127686, 5.008853435516357, 4.975781679153442, 6.010336875915527, 5.140491247177124, 5.034527540206909, 6.216099262237549, 5.103572130203247, 5.0268988609313965, 5.208434581756592, 5.132238388061523, 4.982847452163696, 5.363225698471069, 4.99975848197937]\n",
      "n_examples: 160\n",
      "i: 80\n",
      "update_interval: 1\n",
      "Train progress: (80 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n",
      "Batch Time Elapsed (secs): 794.5598192214966\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 80\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 97.53 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 97.53 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "rates: tensor([[9.8310e+04, 1.2000e+01],\n",
      "        [8.1925e+04, 7.0000e+00],\n",
      "        [7.0000e+00, 6.1445e+04],\n",
      "        [1.4000e+01, 8.6020e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412, 5.011859893798828, 5.009141683578491, 5.0269858837127686, 5.008853435516357, 4.975781679153442, 6.010336875915527, 5.140491247177124, 5.034527540206909, 6.216099262237549, 5.103572130203247, 5.0268988609313965, 5.208434581756592, 5.132238388061523, 4.982847452163696, 5.363225698471069, 4.99975848197937, 5.304046392440796]\n",
      "n_examples: 160\n",
      "i: 81\n",
      "update_interval: 1\n",
      "Train progress: (81 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 800.2023229598999\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 81\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 97.56 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 97.56 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0.]]])\n",
      "rates: tensor([[9.8310e+04, 1.2000e+01],\n",
      "        [8.1925e+04, 7.0000e+00],\n",
      "        [7.0000e+00, 6.1446e+04],\n",
      "        [1.4000e+01, 9.0116e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412, 5.011859893798828, 5.009141683578491, 5.0269858837127686, 5.008853435516357, 4.975781679153442, 6.010336875915527, 5.140491247177124, 5.034527540206909, 6.216099262237549, 5.103572130203247, 5.0268988609313965, 5.208434581756592, 5.132238388061523, 4.982847452163696, 5.363225698471069, 4.99975848197937, 5.304046392440796, 5.642414331436157]\n",
      "n_examples: 160\n",
      "i: 82\n",
      "update_interval: 1\n",
      "Train progress: (82 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Time Elapsed (secs): 805.3602209091187\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 82\n",
      "predictions: tensor([1])\n",
      "labels: tensor(1)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 97.59 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 97.59 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "rates: tensor([[9.8310e+04, 1.2000e+01],\n",
      "        [8.6021e+04, 7.0000e+00],\n",
      "        [7.0000e+00, 6.1446e+04],\n",
      "        [1.5000e+01, 9.0116e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412, 5.011859893798828, 5.009141683578491, 5.0269858837127686, 5.008853435516357, 4.975781679153442, 6.010336875915527, 5.140491247177124, 5.034527540206909, 6.216099262237549, 5.103572130203247, 5.0268988609313965, 5.208434581756592, 5.132238388061523, 4.982847452163696, 5.363225698471069, 4.99975848197937, 5.304046392440796, 5.642414331436157, 5.1580071449279785]\n",
      "n_examples: 160\n",
      "i: 83\n",
      "update_interval: 1\n",
      "Train progress: (83 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(0)\n",
      "Batch Time Elapsed (secs): 810.4208664894104\n",
      "spikes[\"Ae\"]: <bindsnet.network.monitors.Monitor object at 0x7ff819f1b2e8>\n",
      "(i) % update_interval: 83\n",
      "predictions: tensor([0])\n",
      "labels: tensor(0)\n",
      "\n",
      "All activity accuracy: 100.00 (last), 97.62 (average), 100.00 (best)\n",
      "Proportion weighting accuracy: 100.00 (last), 97.62 (average), 100.00 (best)\n",
      "\n",
      "updating assignments: \n",
      "spike_record: tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]]])\n",
      "rates: tensor([[9.8310e+04, 1.2000e+01],\n",
      "        [8.6021e+04, 8.0000e+00],\n",
      "        [7.0000e+00, 6.5542e+04],\n",
      "        [1.5000e+01, 9.0116e+04],\n",
      "        [1.0000e+00, 0.0000e+00]])\n",
      "appending time...\n",
      "totalTrainingTimeSecs: [31.099109172821045, 17.384490728378296, 31.103184938430786, 31.33355212211609, 31.240060329437256, 31.268095016479492, 31.213363885879517, 31.187150716781616, 31.131642818450928, 31.08187174797058, 31.187546014785767, 31.19639492034912, 31.274169921875, 31.249003171920776, 31.182414770126343, 8.86911940574646, 5.162930488586426, 5.401480436325073, 5.0330469608306885, 5.017695426940918, 4.97615385055542, 5.765573501586914, 5.293009519577026, 5.189293146133423, 5.0574049949646, 4.973034381866455, 4.919840335845947, 4.966553449630737, 5.099855661392212, 5.007455110549927, 5.003436326980591, 4.9951863288879395, 5.079169034957886, 4.975454330444336, 5.082006931304932, 4.994338035583496, 5.044814109802246, 5.031822681427002, 5.015417098999023, 5.010225534439087, 5.123672723770142, 4.98620080947876, 4.988612174987793, 4.98440146446228, 5.062208652496338, 4.975970029830933, 5.09013032913208, 4.92413592338562, 5.1247076988220215, 5.197527170181274, 5.030793190002441, 5.061298370361328, 5.026251792907715, 5.054588079452515, 5.026365041732788, 5.0240561962127686, 5.012514591217041, 5.035452365875244, 5.028466701507568, 4.9336652755737305, 4.995401620864868, 5.039950132369995, 4.9772326946258545, 5.215806484222412, 5.011859893798828, 5.009141683578491, 5.0269858837127686, 5.008853435516357, 4.975781679153442, 6.010336875915527, 5.140491247177124, 5.034527540206909, 6.216099262237549, 5.103572130203247, 5.0268988609313965, 5.208434581756592, 5.132238388061523, 4.982847452163696, 5.363225698471069, 4.99975848197937, 5.304046392440796, 5.642414331436157, 5.1580071449279785, 5.060960531234741]\n",
      "n_examples: 160\n",
      "i: 84\n",
      "update_interval: 1\n",
      "Train progress: (84 / 160)\n",
      "len(images): 160\n",
      "(images).shape: torch.Size([160, 1, 4096])\n",
      "len(labels): 160\n",
      "current label: tensor(1)\n"
     ]
    }
   ],
   "source": [
    "#FINAL MODEL (EVALUATE AFTER 1 EPOCH)\n",
    "n_train_full=dataset.get_data()[0]['X_train'].shape[0]\n",
    "n_test_full=dataset.get_data()[0]['X_test'].shape[0]\n",
    "size_of_train_set = n_train_full\n",
    "train_set_update_interval = 1\n",
    "resultsFilename = str(data)+\"_results_data_OPTIMAL_FINAL_FULL.txt\"\n",
    "if os.path.isfile(resultsFilename):\n",
    "    print (\"Results file exists\")\n",
    "else:\n",
    "    print (\"Results file doesn't exist, creating new file...\")\n",
    "starting_point=0\n",
    "for i, params in enumerate(grid):\n",
    "    if(i>=starting_point):\n",
    "        overallPrecisionListAll = list()\n",
    "        overallRecallListAll = list()\n",
    "        overallAccuracyListAll = list()\n",
    "        overallF1ListAll = list()\n",
    "        overallTPListAll = list()\n",
    "        overallTNListAll = list()\n",
    "        overallFPListAll = list()\n",
    "        overallFNListAll = list()\n",
    "        overallConvergenceEpochAll = list()\n",
    "\n",
    "        overallPrecisionListProp = list()\n",
    "        overallRecallListProp = list()\n",
    "        overallAccuracyListProp = list()\n",
    "        overallF1ListProp = list()\n",
    "        overallTPListProp = list()\n",
    "        overallTNListProp = list()\n",
    "        overallFPListProp = list()\n",
    "        overallFNListProp = list()\n",
    "        overallConvergenceEpochProp = list()\n",
    "\n",
    "\n",
    "        trainingTimeList = list()\n",
    "        with open(resultsFilename, \"a\") as text_file:\n",
    "            print(f\"\\nResults for : {str(params)}\\n\\n\", file=text_file)\n",
    "        confusionMatricesList = list()\n",
    "        for fold in np.arange(n_folds):\n",
    "            currentFold = fold\n",
    "            # Train the network.\n",
    "            with open(resultsFilename, \"a\") as text_file:\n",
    "                print(f\"\\nFold : {str(currentFold)}\\n\", file=text_file)\n",
    "                print(f\"Size of Total Training Set : {str(n_train_full)}\\n\", file=text_file)\n",
    "                print(f\"Eval every {str(size_of_train_set)} observations.\\n\", file=text_file)\n",
    "            print(\"Begin training for fold \" + str(currentFold) + \"\\n\")\n",
    "            start = t()\n",
    "\n",
    "            foldEpochAccuracyAll = list()\n",
    "            foldEpochPrecisionAll = list()\n",
    "            foldEpochRecallAll = list()\n",
    "            foldEpochF1scoreAll = list()\n",
    "            foldEpochTPAll = list()\n",
    "            foldEpochTNAll = list()\n",
    "            foldEpochFPAll = list()\n",
    "            foldEpochFNAll = list()\n",
    "\n",
    "            foldEpochAccuracyProp = list()\n",
    "            foldEpochPrecisionProp = list()\n",
    "            foldEpochRecallProp = list()\n",
    "            foldEpochF1scoreProp = list()\n",
    "            foldEpochTPProp = list()\n",
    "            foldEpochTNProp = list()\n",
    "            foldEpochFPProp = list()\n",
    "            foldEpochFNProp = list()\n",
    "            totalTrainingTimeSecs = list()\n",
    "\n",
    "\n",
    "            for index in range(int(n_train_full/size_of_train_set)):\n",
    "                if(index>=8):\n",
    "                    break\n",
    "                with open(resultsFilename, \"a\") as text_file:\n",
    "                    print(f\"Current Training Index : {str(index)}/{str(int(n_train_full/size_of_train_set))}\\n\", file=text_file)\n",
    "                dataset = EEGSeizureDatasetBalanced(testingByDatapoint=False)\n",
    "                n_train=dataset.get_data()[0]['X_train'].shape[0]\n",
    "                print('n_train: '+str(n_train))\n",
    "                n_test=dataset.get_data()[0]['X_test'].shape[0]\n",
    "\n",
    "                # Create a dataloader to iterate and batch data\n",
    "                dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=0, pin_memory=gpu)\n",
    "                result, trainingTime = createSNN(train=True, singleSample=False, n_neurons=params['n_neurons'],\n",
    "                                                 lr_pre=params['lr_pre'],\n",
    "                                                 inh=params['inh'], lr_post=params['lr_post'], exc=params['exc'],\n",
    "                                                 update_interval=train_set_update_interval, current_fold=currentFold,\n",
    "                                                 current_epoch=index, n_train=size_of_train_set)\n",
    "                print(\"Training complete for index: \" + str(index) + \"\\n\")\n",
    "                testResult, testingTime = createSNN(train=False, singleSample=False, n_neurons=params['n_neurons'],\n",
    "                                                    lr_pre=params['lr_pre'],\n",
    "                                                    inh=params['inh'], lr_post=params['lr_post'], exc=params['exc'],\n",
    "                                                    update_interval=params['update_interval'], current_fold=currentFold,\n",
    "                                                    current_epoch=index)\n",
    "\n",
    "                TPAll = testResult['all'][0][0]\n",
    "                FPAll = testResult['all'][0][1]\n",
    "                FNAll = testResult['all'][1][0]\n",
    "                TNAll = testResult['all'][1][1]\n",
    "                TPProp = testResult['prop'][0][0]\n",
    "                FPProp = testResult['prop'][0][1]\n",
    "                FNProp = testResult['prop'][1][0]\n",
    "                TNProp = testResult['prop'][1][1]\n",
    "\n",
    "                precisionAll = (TPAll / (TPAll + FPAll))\n",
    "                recallAll = (TPAll / (TPAll + FNAll))\n",
    "                accuracyAll = (TPAll + TNAll) / (TPAll + FPAll + FNAll + TNAll)\n",
    "                f1scoreAll = 2 * ((precisionAll * recallAll) / (precisionAll + recallAll))\n",
    "                precisionProp = (TPProp / (TPProp + FPProp))\n",
    "                recallProp = (TPProp / (TPProp + FNProp))\n",
    "                accuracyProp = (TPProp + TNProp) / (TPProp + FPProp + FNProp + TNProp)\n",
    "                f1scoreProp = 2 * ((precisionProp * recallProp) / (precisionProp + recallProp))\n",
    "\n",
    "                foldEpochAccuracyAll.append(accuracyAll)\n",
    "                foldEpochPrecisionAll.append(precisionAll)\n",
    "                foldEpochRecallAll.append(recallAll)\n",
    "                foldEpochF1scoreAll.append(f1scoreAll)\n",
    "                foldEpochTPAll.append(TPAll)\n",
    "                foldEpochTNAll.append(TNAll)\n",
    "                foldEpochFPAll.append(FPAll)\n",
    "                foldEpochFNAll.append(FNAll)\n",
    "\n",
    "                foldEpochAccuracyProp.append(accuracyProp)\n",
    "                foldEpochPrecisionProp.append(precisionProp)\n",
    "                foldEpochRecallProp.append(recallProp)\n",
    "                foldEpochF1scoreProp.append(f1scoreProp)\n",
    "                foldEpochTPProp.append(TPProp)\n",
    "                foldEpochTNProp.append(TNProp)\n",
    "                foldEpochFPProp.append(FPProp)\n",
    "                foldEpochFNProp.append(FNProp)\n",
    "\n",
    "            convergenceObservationAccuracyAll=str(foldEpochAccuracyAll.index(max(foldEpochAccuracyAll)))\n",
    "            convergenceObservationAccuracyProp=str(foldEpochAccuracyProp.index(max(foldEpochAccuracyProp)))\n",
    "\n",
    "            with open(resultsFilename, \"a\") as text_file:\n",
    "                print(f\"Training complete for fold {str(currentFold)}\\n\", file=text_file)\n",
    "                print(f\"Total Training Time: {str(sum(trainingTime))}\", file=text_file)\n",
    "                print(f\"Number of Epochs: {str(len(trainingTime))}\\n\", file=text_file)\n",
    "                print(f\"trainingTime: {str((trainingTime))}\\n\", file=text_file)\n",
    "\n",
    "                print(f\"Fold {str(currentFold)} Test Metrics:\\n\", file=text_file)\n",
    "                print(f\"All Spikes:\\n\", file=text_file)\n",
    "                print(f\"TP: {str(foldEpochTPAll)}\\nTN: {str(foldEpochTNAll)}\\nFP: {str(foldEpochFPAll)}\\nFN: {str(foldEpochFNAll)}\\n\", file=text_file)\n",
    "                print(f\"Accuracy: {str(foldEpochAccuracyAll)}\\nPrecision: {str(foldEpochPrecisionAll)}\\nRecall: {str(foldEpochRecallAll)}\\nF1: {str(foldEpochF1scoreAll)}\\n\", file=text_file)\n",
    "                print(f\"Accuracy Maxes at Epoch: {str(convergenceObservationAccuracyAll)}\\n\", file=text_file)\n",
    "                print(f\"Prop Spikes:\\n\", file=text_file)\n",
    "                print(f\"TP: {str(foldEpochTPProp)}\\nTN: {str(foldEpochTNProp)}\\nFP: {str(foldEpochFPProp)}\\nFN: {str(foldEpochFNProp)}\\n\",\n",
    "                      file=text_file)\n",
    "                print(f\"Accuracy: {str(foldEpochAccuracyProp)}\\nPrecision: {str(foldEpochPrecisionProp)}\\nRecall: {str(foldEpochRecallProp)}\\nF1: {str(foldEpochF1scoreProp)}\\n\", file=text_file)\n",
    "                print(f\"Accuracy Maxes at Epoch: {convergenceObservationAccuracyProp}\\n\", file=text_file)\n",
    "\n",
    "            overallPrecisionListAll.append(foldEpochPrecisionAll)\n",
    "            overallRecallListAll.append(foldEpochRecallAll)\n",
    "            overallAccuracyListAll.append(foldEpochAccuracyAll)\n",
    "            overallF1ListAll.append(foldEpochF1scoreAll)\n",
    "            overallTPListAll.append(foldEpochTPAll)\n",
    "            overallTNListAll.append(foldEpochTNAll)\n",
    "            overallFPListAll.append(foldEpochFPAll)\n",
    "            overallFNListAll.append(foldEpochFNAll)\n",
    "            overallConvergenceEpochAll.append(convergenceObservationAccuracyAll)\n",
    "\n",
    "            overallPrecisionListProp.append(foldEpochPrecisionProp)\n",
    "            overallRecallListProp.append(foldEpochRecallProp)\n",
    "            overallAccuracyListProp.append(foldEpochAccuracyProp)\n",
    "            overallF1ListProp.append(foldEpochF1scoreProp)\n",
    "            overallTPListProp.append(foldEpochTPProp)\n",
    "            overallTNListProp.append(foldEpochTNProp)\n",
    "            overallFPListProp.append(foldEpochFPProp)\n",
    "            overallFNListProp.append(foldEpochFNProp)\n",
    "            overallConvergenceEpochAll.append(convergenceObservationAccuracyProp)\n",
    "\n",
    "        precisionAllMeanOverFolds=np.average(np.array(overallPrecisionListAll), axis=0)\n",
    "        recallAllMeanOverFolds=np.average(np.array(overallRecallListAll), axis=0)\n",
    "        accuracyAllMeanOverFolds=np.average(np.array(overallAccuracyListAll), axis=0)\n",
    "        F1AllMeanOverFolds=np.average(np.array(overallF1ListAll), axis=0)\n",
    "        TPAllMeanOverFolds = np.average(np.array(overallTPListAll), axis=0)\n",
    "        TNAllMeanOverFolds = np.average(np.array(overallTNListAll), axis=0)\n",
    "        FPAllMeanOverFolds = np.average(np.array(overallFPListAll), axis=0)\n",
    "        FNAllMeanOverFolds = np.average(np.array(overallFNListAll), axis=0)\n",
    "        convergenceAllMeanOverFolds = np.mean(np.array(overallConvergenceEpochAll).astype(np.float))+1\n",
    "\n",
    "        precisionPropMeanOverFolds = np.average(np.array(overallPrecisionListProp), axis=0)\n",
    "        recallPropMeanOverFolds = np.average(np.array(overallRecallListProp), axis=0)\n",
    "        accuracyPropMeanOverFolds = np.average(np.array(overallAccuracyListProp), axis=0)\n",
    "        F1PropMeanOverFolds = np.average(np.array(overallF1ListProp), axis=0)\n",
    "        TPPropMeanOverFolds = np.average(np.array(overallTPListProp), axis=0)\n",
    "        TNPropMeanOverFolds = np.average(np.array(overallTNListProp), axis=0)\n",
    "        FPPropMeanOverFolds = np.average(np.array(overallFPListProp), axis=0)\n",
    "        FNPropMeanOverFolds = np.average(np.array(overallFNListProp), axis=0)\n",
    "        convergencePropMeanOverFolds = np.mean(np.array(overallConvergenceEpochProp).astype(np.float))+1\n",
    "\n",
    "        with open(resultsFilename, \"a\") as text_file:\n",
    "            print(f\"Training complete for all folds for params: {str(params)}\", file=text_file)\n",
    "            print(f\"Mean Test Metrics Over All Folds:\\n\", file=text_file)\n",
    "            print(f\"All Spikes:\\n\", file=text_file)\n",
    "            print(f\"Final Accuracy: {str(accuracyAllMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final Precision: {str(precisionAllMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final Recall: {str(recallAllMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final F1: {str(F1AllMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final TP: {str(TPAllMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final FP: {str(FPAllMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final TN: {str(TNAllMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final FN: {str(FNAllMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Obs. Until Max Accuracy: {str(convergenceAllMeanOverFolds)}\\n\", file=text_file)\n",
    "            print(\n",
    "                f\"TP: {str(list(TPAllMeanOverFolds))}\\nTN: {str(list(TNAllMeanOverFolds))}\\nFP: {str(list(FPAllMeanOverFolds))}\\nFN: {str(list(FNAllMeanOverFolds))}\\n\",\n",
    "                file=text_file)\n",
    "            print(\n",
    "                f\"Accuracy: {str(list(accuracyAllMeanOverFolds))}\\nPrecision: {str(list(precisionAllMeanOverFolds))}\\nRecall: {str(list(recallAllMeanOverFolds))}\\nF1: {str(list(F1AllMeanOverFolds))}\\n\",\n",
    "                file=text_file)\n",
    "\n",
    "            print(f\"Prop Spikes:\\n\", file=text_file)\n",
    "            print(f\"Final Accuracy: {str(accuracyPropMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final Precision: {str(precisionPropMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final Recall: {str(recallPropMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final F1: {str(F1PropMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final TP: {str(TPPropMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final FP: {str(FPPropMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final TN: {str(TNPropMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Final FN: {str(FNPropMeanOverFolds[-1])}\\n\", file=text_file)\n",
    "            print(f\"Obs. Until Max Accuracy: {str(convergencePropMeanOverFolds)}\\n\", file=text_file)\n",
    "            print(\n",
    "                f\"TP: {str(list(TPPropMeanOverFolds))}\\nTN: {str(list(TNPropMeanOverFolds))}\\nFP: {str(list(FPPropMeanOverFolds))}\\nFN: {str(list(FNPropMeanOverFolds))}\\n\",\n",
    "                file=text_file)\n",
    "            print(\n",
    "                f\"Accuracy: {str(list(accuracyPropMeanOverFolds))}\\nPrecision: {str(list(precisionPropMeanOverFolds))}\\nRecall: {str(list(recallPropMeanOverFolds))}\\nF1: {str(list(F1PropMeanOverFolds))}\\n\",\n",
    "                file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
